  小林coding--计网
基础知识
网络模型
OSI网络模型共有七层，分别是应用层、表示层、会话岑、传输层、网络层、数据链路层以及物理层，负责职能如下：
● 应用层，负责给应用程序提供统一的接口；
● 表示层，负责把数据格式转换，压缩加密功能；
● 会话层，负责控制应用程序间的会话能力，如不同软件数据分发给不同软件；
● 传输层，负责端到端的数据传输，如TCP、UDP；
● 网络层，负责数据的IP路由、转发、分片，如不同设备间的数据转发；
● 数据链路层，负责定义数据的基本格式，如何传输，如网卡MAC 寻址；
● 物理层，负责底层传输数据，如网线；
TCP/IP网络模型共有四层，应用层，传输层，网络层和网络接口层，每一层负责的职能如下：
● 应用层，负责向用户提供一组应用程序，比如HTTP、DNS、FTP等；
● 传输层，负责端到端的同学，比如TCP、UDP等；
● 网络层，负责网络包的封装、分片、路由、转发，比如IP、ICMP等；
● 网络接口层，负责网络包在物理网络中的传输，比如网络包的封帧、MAC寻址、差错检测，以及通过网卡传输网络帧等；
网络接口层的传输单位是帧 (frame)，IP层是包 (packet)，TCP层是段 (segment)，HTTP是消息或报文 (message)。
键入URL到网页显示经历了什么
1. 解析URL：浏览器会解析出协议、主机、端口、路径等信息，构建一个HTTP请求（会判断是否有HTTP缓存）
2. 域名解析DNS：查询URL对应的IP地址域名层级类似一个树桩结构：
  ○ 根服务器 (.)
  ○ 顶级服务器 (.com)
  ○ 权威服务器 (server.com)
3. TCP三次握手
4. 浏览器发送HTTP/HTTPS到web服务器
5. 服务器处理并返回HTTP报文，包含请求网页以及状态码，设置的cookie等
6. 浏览器渲染界面
7. TCP四次挥手
HTTP
HTTP常见状态码
常见状态码：
● 1xx 提示信息，处于中间状态
● 2xx 成功，200OK 
● 3xx 重定向，资源发送变动，需要重新发请求 301：永久重定向 304 Not Modified：配合协商缓存使用
● 4xx 客户端发送报文有误 400 Bad Request：笼统错误 404 Not Found：资源不存在
● 5xx 服务端处理请求错误
HTTP常见字段
Host字段：客户端发送请求，用来制定服务器域名
Content-Length字段：服务器返回数据，表面本次数据长度
Connection字段：客户端要求服务器使用「HTTP长链接」
Content-Type：服务器告诉客户端本次数据格式，发送的是网页，编码是UTF-8
COntent-Encoding：数据压缩方法
GET和POST区别
概念
GET是请求资源，请求参数写在URL中，不会对服务器产生影响，GET方法是安全、幂等的，GET请求会被浏览器缓存，下一次传输数据相同就会返回缓存内容，GET 产生一个TCP数据包
POST是客户端向服务器提交数据，请求参数放在请求体，PSOST方法是不安全、非幂等的，POST请求不会被浏览器缓存，POST产生两个TCP数据包，先发送header等服务端返回100后再发送body
HTTP缓存技术
强制缓存：浏览器判断缓存没过期，直接使用浏览器的本地缓存，决定权在浏览器
协商缓存：服务端在响应中提供了一些标识，与服务端协商后，通过协商结果判断是否使用本地缓存，返回304 Not Modified则表示不会返回资源
HTTP与HTTPS
● HTTP是超文本传输协议，信息是明文传输。HTTPS在TCP和HTTP网络层直接加入了SSL/TLS安全协议，使得报文能够加密传输。
● HTTP默认端口80，HTTPS默认端口443
● HTTPS需要申请证书，来保证服务器身份是可信的。
HTTPS建立连接流程
1. 客户端发起请求，向服务器发送支持的TLS版本，加密算法，生成一个随机数
2. 服务器收到请求后，向客户端发出响应，发送数字证书，确认TLS版本，加密算法，生成一个随机数
3. 客户端收到回应后，确认数字证书的真实性。从数字证书中取出服务器RSA公钥加密一个随机数并发送，双方用这三个随机数和协商的加密算法生成会话密钥（（ECDHE）会发送椭圆曲线，椭圆曲线公钥）
4. 服务器收到后，用RAS私钥揭秘出第三个随机数，计算出会话密钥，发送握手结束通知。
常用的密钥交换算法有两种：RSA算法和ECDHE（基于ECC椭圆曲线）算法
HTTP/1.1、HTTP/2、HTTP/3演变
HTTP/1.1
● 长连接：支持长链接，Connect字段默认开启keep-alive
● 管道化：支持管道网络传输
● 缓存：加入了多种缓存控制头Etag
● 新增六种请求方法，如DELETE、CONNECT等
问题：服务器按请求顺序响应，响应慢有队头阻塞问题
HTTP/2
基于HTTPS，有安全性保障
● 头部压缩：使用HPACK算法压缩头部，消除重复请求头。
● 二进制格式：报文不像HTTP/1.1采用纯文本形式，改用二进制格式
● 并发传输：通过STREAM，多个Stream复用一条TCP连接，达到并发效果
问题：所有的Stream跑在一条TCP连接上，共享一个滑动窗口，Stream A被阻塞后，其他Stream必须等待，这是由于TCP需要保证数据完整连续，前一个数据没到达，后收到的数据存在内核缓冲区，产生队头阻塞
HTTP/3
改为UDP的QUIC协议
1. 无队头阻塞：当某个流丢包，只会阻塞这个流，其他流不受影响，不存在队头阻塞问题
2. 更快的连接建立：QUIC内部包含TLS，可以同时完成QUIC三次握手和TLS握手
3. 不像TCP采用四元组（源IP、源端口、目的IP、目的端口）确定一条TCP连接，采用连接ID标记通信
HTTP/1.1优化
● 尽量避免发送HTTP请求：通过缓存技术。
● 减少HTTP请求次数
  a. 多个小资源合并成大资源再传输，减少HTTP请求次数以及头部重复传输，来减少TCP连接数量
  b. 按需访问资源，只访问当前用户看的到/用得到的资源，减少同一时间的HTTP请求次数，减少QPS
● 压缩响应资源，选择更好的压缩算法
HTTP和RPC
● HTTP和各类RPC是TCP之上定义的应用层协议
● RPC本质上是一种调用方式，类似Thrift这种具体实现才是协议，RPC不一定基于TCP协议
● 一般对外用HTTP协议，内部集群微服务之间用RPC
HTTP和WebSocket
● HTTP/1.1是半双工，需要服务器主动推数据到客户端
● 客户端和服务端需要频繁交互的场景需要使用WebSocket协议
● WebSocket会先利用HTTP协议加上一些请求头进行握手升级，握手成功后用WebSocket数据格式进行收发数据
1.强制缓存，协商缓存的字段与http版本的对应？
1.只有在强制缓存未命中时才会进行协商缓存。
强制：相对时间Cache-Control优先级更高，Expires绝对时间
协商：Last-Modified最后修改时间,Etag唯一标识响应资源(优先级更高）
2.为什么ETag的优先级更高？这是因为 ETag 主要能解决 Last-Modified 几个比较难以解决的问题
1.文件内容没变情况下最后修改时间可能也会改变（如备份、同步，日志记录等
2.可能有些文件是在秒级以内修改的，If-Modified-Since 能检查到的粒度是秒级的，Etag就能够保证这种需求下客户端在 1 秒内能刷新多次；
3.有些服务器不能精确获取文件的最后修改时间（如分布式系统、云存储）
HPACK和QPACK
HTTP/2.0 在同一个 TCP 连接上多路复用多个流（Stream），TCP 是字节流协议，丢包会导致所有后续流被塞。
如果动态表的更新数据（如新的头部字段）因丢包而延迟到达，后续依赖该动态表的头部压缩流也会被阻塞，即使这些流本身没有丢包。
● QPACK 的独立设计：
  ○ QPACK 使用独立的控制流（静态表和动态表更新）来管理头部压缩，而不是像 HPACK 那样直接依赖数据流的顺序。
  ○ 动态表的更新（如插入新头部字段）通过专门的指令（如 Insert 和 Duplicate）发送，这些指令可以独立传输，不依赖其他流的顺序。
● 避免队头阻塞：
  ○ QUIC 在UDP上运行，每个流（Stream）是独立的，丢包只会影响当前流，不会阻塞其他流。
  ○ 即使动态表的更新因丢包延迟到达，其他流仍然可以继续使用已有的动态表信息，不会被阻塞。
3.https如何解决风险
1.信息加密：交互信息无法被窃取，
——>混合加密的方式实现信息的机密性，解决了窃听的风险
2.校验机制：无法篡改通信内容，篡改了就不能正常显示，但垃圾广告
——>摘要算法的方式来实现完整性，它能够为数据生成独一无二的「指纹」，指纹用于校验数据的完整性，解决了篡改的风险
3.身份证书：证明淘宝是真的淘宝网，但你的钱还是会因为「剁手」而没
——>将服务器公钥放入到数字证书中，解决了冒充的风险

RSA不具备前向安全性（现在用ECDHE)
会话秘钥会每次变化，并且第三次捂手就能传数据
TCP
TCP头格式
1. 序列号：在建立连接时由计算机生成的随机数作为初始值，发送一次数据就累加一次大小。用来解决网络包乱序问题
2. 确认应答号：指下一次期望收到的数据的序列号，发送端收到这个确认应答后认为在这个序号以前的数据被正常接收。用来解决丢包问题
3. 控制位：
  ○ ACK：为1时，确认应答字段有效，除了最初建立时的SYN包之外必须设置为1。
  ○ RST：为1时，表示出现异常必须强制断开连接。
  ○ SYN：为1时，表示希望建立连接，设定序列号初始值。
  ○ FIN：为1时，表示不会再用数据发送，希望断开连接，双方主席呼唤FIN为1的TCP段。
唯一确定一个TCP
TCP四元组可以唯一确定一个连接：源地址、目标地址、源端口、目标端口。
源地址和目标地址的字段（32位）在IP头部中，作用是通过IP协议发送报文给对方主机。
源端口和目标端口的字段（16位）在TCP头部中，作用是告诉TCP协议应该把报文发给哪个进程。
TCP和UDP
1. 连接
  ○ TCP是面向连接的、可靠的、基于字节流的传输层通信协议。
  ○ UDP不需要连接，支持一对多，不保证可靠交付数据。
2. 控制
  ○ TCP有拥塞控制和流量控制，保证数据传输的安全性
  ○ UDP则没有，网络拥堵不影响UDP发送速率
3. 首部开销
  ○ TCP首部一般是20字节，如果使用「选项」字段会变长
  ○ UPD首部只有8个字节，开端较小
4. 传输方式
  ○ TCP流式传输，没有边界，但保证顺序和可靠
  ○ UDP一个包一个包发送，有边界，但可能会丢包乱序
5. 分片不同
  ○ TCP数据大于MSS（MTU取出IP头部和TCP头部，TCP数据最大长度），在传输层分片，因为TCP的超时重传机制重传整个IP分片的效率太低，进行重发以MSS为单位，不用重传所有分片
  ○ UDP数据大于MTU（网络包长度1500字节），在IP层分片
TCP建立连接
TCP三次握手
1. 一开始，客户端和服务端处于CLOSE状态，服务的主动监听某个端口，处于LISTEN状态
2. 客户端随机初始化序号，向服务端发送一个SYN包，表示客户端希望建立连接，客户端处于SYN-SENT状态
3. 服务端收到之后，也初始化自己的序号，并把确认序列号填入SYN序列号 + 1，发送SYN、ACK包，服务端处于SYN-RCVD状态
4. 客户端收到后，发送ACK包，序列号会+1，发送给客户端，也可以携带数据，之后客户端处于已连接状态
5. 服务器接收到ACK报文后，也进入已连接状态
为什么是三次握手
1. 避免历史连接：在网络拥堵的情况，一个旧的SYN报文比新报文更早到达服务端，服务端发送错误的确认号给客户端，客户端收到后发现不对，回RST报文，等待新的SYN抵达服务端就可以正确的完成三次握手。在两次握手的情况下，客户端无法阻止历史连接，造成资源浪费。
2. 同步初始序列号：客户端发送SYN，服务端回一个ACK代表客户端报文被接收，服务端发送SYN也需要客户端回应ACK，这样一来一回才能确保双方初始序列号被可靠同步。
3. 避免资源浪费：当客户端发送的SYN报文网络阻塞，客户端没有接收到ACK会重新发送SYN，如果没第三次握手，服务端会建立多个冗余的无效连接，会造成资源浪费
为什么初始化序列号要求不一样
● 为了防止历史报文被下一个相同四元组连接所接收：客户端发送数据包被网络阻塞，触发超时重传，服务端重启，重建连接，完成相同四元组连接，上一个数据包抵达服务端，正常接收后会数据错乱
握手失败怎么办
SYN报文没收到ACK会触发超时重传机制
SYN攻击
攻击者发送不同IP地址的SYN报文，服务端不断发送SYN-ACK报文，会占满半连接队列（SYN队列），无法为正常用户服务。
解决方法：开启syncookies
半连接队列和全连接队列
● 半连接队列（SYN队列）：服务端收到第一次握手，会将socket加入到队列，都处于SYN_RECv状态。是哈希表，为了查询方便。半连接队列满了，可能是收到SYN攻击，可以开启synccookies，绕开半连接队列。
● 全连接队列（ACCEPT队列）：服务端收到第三次握手，将半连接队列的socket取出，放进全连接队列，都处于ESTABLISHED状态，等待服务端执行accept()后取出。全连接队列满了，会放弃第三次握手。
TCP断开连接
四次挥手过程
1. 客户端发送FIN 报文，客户端进入FIN_WAIT_1状态
2. 服务端收到后，发送ACK报文，服务端进入CLOSE_WAIT状态
3. 客户端接收到ACK，进入FIN_WAIT_2状态
4. 服务端处理完数据，发送FIN报文，服务端进入LAST_ACK状态
5. 客户端收到后，发送ACK报文，进入TIME_WAIT状态
6. 服务端收到ACK后，进入CLOSE
7. 客户端经过2MSL后，进入CLOSE
为什么是四次挥手
客户端发送FIN表示客户端不再发送数据，服务端可能还有数据处理，服务端发送FIN才表示同意关闭连接，一般FIN和ACK会分开发送，所以是四次。如果开启TCP延迟确认机制，当没有响应数据发送是，ACK会延迟一段时间，ACK和FIN会合并传输，就是三次挥手，
挥手丢失怎么办
● 第一次挥手丢失：客户端超时重传失败后，进入CLOSE状态，断开连接
● 第二次挥手丢失：客户端超时重传失败后，进入CLOSE状态，断开连接
● 第三次挥手丢失：服务端超时重传失败后，进入CLOSE状态，断开连接，客户端FIN_WAIT_2时间60秒超时，断开连接
● 第四次挥手丢失：服务端超时重传失败后，进入CLOSE状态，客户端处于TIME_WAIT，超过2MSL60秒后，断开连接
TIME_WAIT状态
TIME_WAIT等待时间2MSL，MSL是报文最大生存时间，客户端接收到FIN发送ACK开始，服务端超时重传FIN，一来一回两个MSL
原因：
● 防止历史连接数据，被后面相同四元组的连接接收，让两个方向上的历史数据包都被丢弃。
● 保证被动关闭的一方能正确关闭。
TCP重传机制
● 超时重传：在超时重传时间（略大于RTT）内没有收到ACK，发送方触发重传，超时间隔加倍
● 快速重传：接收方连续收到相同ACK，会重传丢失的报文
滑动窗口和流量控制
● TCP头有一个「窗口」字段，接受端告诉发送端自己还有多少缓冲区可以接受数据
● 流量控制是确保发送方不要发送超过接收方缓冲区容量的数据，会动态调整窗口大小
拥塞控制
拥塞控制是在网络出现拥塞时动态调整数据传输速率，防止网络过载
1. 慢启动：TCP发送端会以较小的发送窗口开始传输数据，以指数级增加发送窗口的大小
2. 拥塞避免：达到慢启动阈值后，进入拥塞避免状态，以线性增加发送窗口的大小，避免网络堵塞
3. 快速重传：当网络拥塞，发送方连续收到相同的确认，触发快速重传，不必等待超时重传
4. 快速恢复，发送方将慢启动阈值设为当前窗口的一半，拥塞窗口设置为慢启动阈值加上还未重传的数据的大小。
如何优化TCP
三次握手
● 客户端优化：根据网络稳定性和服务器的繁忙程度修改SYN的重传次数，比如内网通信调低重试次数，将错误暴露给应用程序
● 服务端优化：调整半连接队列（哈希表）和全连接队列（链表）的长度，调整SYN-ACK重传次数
● 绕过三次握手：开启TCP Fast Open，第一次发起请求的时候需要三次握手，后续通过Fast Open Cookie优化
四次挥手
● 主动方：调整FIN报文重传次数，调整FIN_WAIT2状态的时间，调整TIME_WAIT状态上限个数防止占用太多资源
● 被动方：调整FIN报文重传次数
TCP字节流和粘包问题
TCP是以字节流的方式传输数据，当数据大于MSS（最大报文段长度，一般为1460bit），会分成多个报文段。发送端会将需要发送的数据发到缓冲区，缓冲区满了以后再发送到接收方。当两个消息的某一部分合并到同一个TCP报文，会产生粘包问题。
TCP有一个negal算法，多个小数据包会组合成一个大包发送，这就会产生粘包问题。
处理粘包问题：
● 发送方：关闭negal算法
● 接收方，只能通过应用层处理。a. 格式化数据：每条数据有固定的开始符结束符 b. 自定义消息结构，将数据长度和数据一起发送
TCP Keepalive和HTTP Keepalive
● TCP保活机制由「内核」实现，可以在双方没有数据交互的情况下，通过探测报文，来确定对方的TCP连接是否存活
● HTTP长连接由「应用程序」实现，同一个TCP连接发送接收多个HTTP请求，减少了HTTP短连接带来的多次TCP建立和释放的开销
QUIC协议实现可靠传输
● 可靠传输：有单向递增的Packet Number，配合Stream ID （类似HTTP/2）+ Offset（类似Seq序号）字段信息支持乱序确认而不允许数据包的组装，不必像TCP按顺序确认应答ACK
● 队头阻塞：一条QUIC连接发送多个HTTP请求（Stream），每个Stream都有一个滑动窗口，互相独立
● 流量控制：每个Stream流有独立的滑动窗口，做单独的流量控制，所有Stram流加起来的总字节数小于缓冲区大小。
TCP细节问题
SYN报文什么时候会被丢弃
● 半连接队列满了：当服务器收到SYN攻击，TCP半连接队列满了，后面来的SYN包都被丢弃，如果开启了syncookies功能，即使半连接队列满了，也不会丢弃SYN包
● 全连接队列满了：当服务端并发处理大量请求，TCP全连接队列满了，后续连接就会被丢弃
已建立连接的TCP，收到SYN发生什么
● SYN报文端口号不同：通过新的三次握手建立连接。如果旧连接服务端发送了数据包，客户端由于已经关闭，发送RST报文，如果未发送数据包，通过保活机制释放连接。
● SYN报文端口号相同：客户端发送SYN报文的序列号是乱序，服务端回复正确的ACK，客户端发现确认好部署自己想要的，发送RST报文。
四次挥手收到乱序FIN怎么办
在FIN_WAIT_2状态时，如果收到乱序的FIN报文，会被加入到乱序队列，并不会进入到TIME_WAIT，再收到前面被网络延迟的数据包时，会从乱序队列找可用数据，再进入TIME_WAIT状态。
在TIME_WAIT状态的TCP连接，收到SYN会发生什么
● 合法SYN：会重启四元组连接，跳过@MSL转变为SYN_RECV状态，开始第二次握手
● 非法SYN：会再回复一个第四次挥手的ACK报文，客户端收到后发现不是自己期望的确认号，发送RST报文
TCP连接，一端断电和进程崩溃的区别
● 主机崩溃：如果服务端会发送数据，超时重传一定次数后，断开TCP连接。如果不发送数据，通过TCP保活机制释放连接。
● 进程崩溃：内核会发送FIN报文，与服务端四次挥手
拔掉网线后，TCP连接还存在吗
● 有数据传输：1. 在超时重传次数没有达到上限前重连，能正常存在 2. 超时重传上限，断开TCP连接，客户端重连后发送数据服务端回复RST报文
● 无数据传输：1. 如果开启TCP保活，在探测期间插回重连之后，能正常存在 2. 未开启则一直存在
TLS同时进行三次握手
当满足一下条件，TLS1.3版本会话恢复机制，重连只需0RTT
● 开启TCP Fast Open功能，TLS版本为1.3
● 客户端与服务端已经完成过一次通信
TCP协议缺陷
● TCP队头阻塞问题，TCP是字节流协议，保证收到的字节顺序是完整有序的，前一个数据没到达，后收到的数据存在内核缓冲区，产生队头阻塞
● TCP建立连接的延迟：TCP三次握手和TLS四次握手后才能进行数据传输，还有TCP慢启动的减速过程，比如HTTP 1.0/1.1、HTTP/2、HTTPS
● IP地址变更后需要重新建立连接
TCP和UDP公用一个端口
TCP和UDP在内核是两个独立的软件模块实现，主机通过协议号确定传给哪个模块，因此相互独立不受影响
服务端没有listen，客户端发起连接会发生什么
客户端对服务端发起SYN报文，服务端回RST报文
用了TCP一定不会丢吗
● 建立连接丢包：半连接队列和全连接队列丢包，连接失败
● 流量控制丢包：当数据发送过快，流量控制窗口溢出
● 接收缓冲区丢包：接收缓冲区满了，会变成零窗口，这时候如果发送端再发数据，会丢包
1.为什么要time_wait状态
1.防止历史的连接数据被后面相同的四元组连接，错误的接收
序列号是一个 32 位的无符号数，因此在到达 4G 之后再循环回到 0，循环一次需要4.5个小时（可以利用时间戳防止回绕）
2.等待足够的时间，保证能够正常的关闭连接
2.为什么要先+1后收到新数据的ack才将cwnd设为1/2的门限阈值？

1.首先是优化慢启动，减小cwnd，来减缓拥塞。
2.cwnd逐渐加1是为了尽快将丢失的数据包发给目标，从而解决拥塞的根本问题（三次相同的 ACK 导致的快速重传），所以这一过程中 cwnd 反而是逐渐增大的
3.TCP如何解决粘包？（如何理解字节流协议）
1.固定长度消息
2.特殊字符定义边界
3.自定义消息体结构（头部包含消息体大小）
4.已建立的TCP收到syn会怎么样？
客户端宕机重启后的情况：1.端口号变了，则为新连接，之前的连接时间到了会触发保活机制。
2.都相同，syn又是一个新的随机序列号服务器会ack回复之前的正确的序列和确认号，客户端发现不是自己想要的确认号，会回复rst，关闭连接。
5.如何关闭一个TCP连接？
1.tcpkill 工具是 TCP 通信时，拿到下一次期望收到的序列号，然后填充到伪造的 RST 报文，发送给对方，达到关闭 TCP 
（需要活跃的TCP）
2.killcx 工具是主动发送一个 SYN 报文，对方会回复一个正确序列号和确认号ACK 报文，拿到正确序列号，然后发rst。
6.TCP四次挥手的二三次，在没有数据要发送的情况下，能否和并为一次？
报文捎带的方法，目前广泛应用，但也算是四次挥手
TCP三次捂手是否携带数据？为什么？
https://blog.csdn.net/weixin_40582034/article/details/148795428
总结：1.前两次不携带，处于安全性和协议的稳定性
2.第三可带，但实际用的较少
3.先建立连接再传数据，保证TCP的可靠性吧
TCP FAST OPEN 捂手阶段就发，需要双方支持，cookie
ACK丢了后续数据也能正常被接收，因为第一次发送的数据会带跟ack相同的标志位和seq
7.TCP时间戳怎么解决2mls和序列回绕等问题？
定义：TCP 时间戳是 TCP 协议的一个可选字段，用于记录发送该报文时的时间值（通常是一个单调递增的计数器，单位可能是毫秒或更小）。
作用：它的主要用途是帮助 TCP 协议更高效地处理网络中的重复数据包、乱序数据包，以及解决一些历史遗留问题（如 2MSL 问题、序列号绕回问题）。
2. 时间戳如何解决 2MSL 问题？
（1）什么是 2MSL 问题？
在 TCP 连接关闭时，主动关闭方（通常是客户端）会进入 TIME_WAIT 状态，并等待 2 倍的最大报文生存时间（2MSL） 后才彻底关闭连接。
这样做的目的是确保网络中所有延迟的数据包都能被丢弃，避免它们干扰后续的新连接。
（2）时间戳如何解决 2MSL 问题？
如果启用了时间戳选项，TCP 会记录每个报文的发送时间。
当重复的数据包（可能是由于网络延迟）到达时，接收方可以通过时间戳判断该报文是否过期：
如果时间戳比当前时间旧（即超过了某个阈值），接收方会直接丢弃该报文，而不会误认为是新数据。
这样，即使没有等待 2MSL，也能确保旧数据包不会干扰新连接，从而减少 TIME_WAIT 状态的等待
3. 时间戳如何防止序列号绕回？
（1）什么是序列号绕回？
TCP 的序列号是一个 32 位无符号整数，范围是 0 ~ 2^32 - 1。
如果 TCP 连接持续运行很长时间，发送的数据量可能会超过 2^32 字节，导致序列号从最大值回绕到 0。
如果此时网络中有一个旧的重复数据包（它的序列号恰好和新数据包的序列号相同），接收方可能会误判这个旧包是新数据，导致数据混乱。
（2）时间戳如何防止序列号绕回？
时间戳提供了一种绝对时间参考，即使序列号回绕，接收方仍然可以通过时间戳判断：
如果一个数据包的序列号和新数据包相同，但时间戳更旧，说明它是重复的旧数据包，应该丢弃。
如果时间戳更新，说明它是真正的新数据包，可以正常处理。
这样，即使序列号回绕，TCP 仍然能正确区分新旧数据包，避免数据错误。
4. 时间戳在 TCP 报文中的实际应用
发送方：在 TCP 报文的 选项字段 中加入时间戳值（通常是一个单调递增的计数器）。
接收方：
收到报文后，检查时间戳是否比之前记录的时间戳更新。
如果时间戳更旧，说明可能是重复或延迟的数据包，直接丢弃。
如果时间戳更新，正常处理报文，并更新本地记录的时间戳。
8.KCP可靠传输的实际使用？
KCP 的核心设计思想就是：应用层把数据交给 KCP，由 KCP 控制何时调用 UDP 发送函数（通过 kcp->output 回调）。下面我会用更清晰的逻辑总结整个过程：
1. 数据流动的正确流程
(1) 应用层 → KCP
应用层调用ikcp_send(kcp, data, len) 发送数据。
KCP 会将数据封装成带 序列号 的包，存入 发送缓冲区（snd_buf），并根据拥塞控制、重传机制等决定是否立即发送。
(2) KCP → 底层传输（UDP）
KCP 根据内部状态（如定时器、拥塞窗口）调用用户注册的 kcp->output(buf, len) 回调函数。
**kcp->output 是用户实现的函数**，通常内部调用 sendto(sockfd, buf, len, ...) 通过 UDP Socket 发送数据。
(3) 底层传输 → 网络
sendto 将数据包通过 UDP 发送到对端。
(4) 对端接收 → KCP
对端的UDP Socket 接收到数据后，调用 ikcp_input(kcp, buf, len) 将数据交给 KCP 处理。
KCP 解析数据包，检查序列号，发送 ACK 给发送方，并将数据存入 接收缓冲区（rcv_buf）。
(5) KCP → 应用层
应用层调用ikcp_recv(kcp, buf, len) 从接收缓冲区读取数据。
环节	谁控制？	具体行为
何时发送数据	KCP 控制	KCP 根据拥塞窗口、定时器等决定是否调用 kcp->output
。
如何发送数据	用户实现	kcp->output
 是用户定义的函数，内部调用 sendto
 发送 UDP 数据包。
底层传输	UDP Socket	最终由 sendto
 完成物理发包。
KCP 不直接操作网卡，而是通过回调函数 kcp->output 委托底层（如 UDP）发送数据。

IP
基本认识
IP处在网络层，作用是在复杂的网络环境中将数据包发送给目标主机（非直连，直连为数据链路层MAC），源IP地址和目标IP地址在传输过程不会变化（没使用NAT网络），只有源MAC地址和目标MAC地址一直在变化。、
IP地址分类

计算最大主机个数为2^8 - 2=254
● 主机号全1指定某个网络下的所有主机，用于广播，在同一个链路互相连接的主机之间发送数据
● 主机号为0指定某个网络
CIDR
无分类地址，表示形式 a. b. c. d/x, /x表示前x位上网络号
IP分片与重组
以太网的最大传输单元MTU是1500字节，当IP数据包大小大于MTU，IP数据包会被分片，一旦某个分片丢失，会造成整个IP数据包作废。
IP相关协议
DNS
DNS可以将域名网址自动转换为具体的IP地址，客户端发出一个DNS请求，发给本地DNS服务器，如果缓存中能找到就直接返回IP地址。如果没有，则按照根服务器、顶级域服务器、权威服务器的顺序查找IP地址。
场景	协议	原因	性能特点
标准查询	UDP	快速、轻量	低延迟，高吞吐
大响应	TCP	突破 512 字节限制	可靠传输
区域传输	TCP	大量数据传输	保证完整性
CDN
CDN（Content Delivery Network，内容分发网络） 是一种分布式服务器网络，通过将内容缓存到全球多个节点，使用户从最近的服务器获取数据，从而加速访问、降低延迟，并减轻源站压力。
当用户请求资源时，CDN的DNS解析会返回用户最近的CDN节点的IP地址，CDN会检查是否已经缓存，该资源若CDN节点已缓存资源，直接返回。若未缓存，回源服务器拉取并缓存
ARP
ARP通过ARP请求和ARP响应两种类型的包确定MAC地址
● 主机通过广播发送ARP请求，这个包中包含了想要知道的MAC地址的主机IP地址
● 同一个链路的所有设备收到ARP请求时，回去拆开ARP请求包里的内容，如果IP地址和自己的IP地址一致，那么就会将自己的MAC地址塞入ARP响应包返回给主机
RARP是已知MAC地址求IP地址
DHCP
DHCP用来动态获取IP地址，有DHCP中继代理，对不同网段的IP地址分配也可以由一个DHCP服务器统一管理
● 客户端发起DHCP发送报文，传递给链路层，链路层广播到所有网络设备中
● DHCP服务器接收到报文，响应DHCP提供报文，提供可租约的IP地址
● 客户端收到后，从中选择一个服务器发送DHCP请求报文进行响应
● 最后服务端用DHCP ACK报文进行应答
● 客户端收到DHCP ACK后，就可以在租用期内使用DHCP服务器分配的IP地址
NAT
NAT网络地址转换，把同一个公司的主机对外部通信，把私有地址转换为公有地址
ICMP
互联网控制报文协议，主要功能包括：确认IP包是否成功送达、报告发送过程中IP包被废弃的原因和改善网络设置等。ping命令基于ICMP协议实现
ICMP类型：1. 用于诊断等查询消息，也就是查询报文类型 2. 通知出错原因的错误消息，也就是差错报文类型

断网了还能ping通127.0.0.1吗
127.0.0.1是回环地址，有网的情况下是通过网卡发送数据，当发现目标IP是回环地址，会选择lo0假网卡，在快出网卡前，将数据插入到一个链表后通过软中断通知接受数据，不出网络，所以断网也能ping通。
ping的核心原理？
发送 ICMP 回显请求 → 2. 目标主机返回 ICMP 回显应答 → 3. 计算延迟和丢包率。
它是网络故障排查的第一步，适用于测试 连通性、延迟、丢包 等基础网络状态，但需注意防火墙可能拦截 ICMP 导致误判。
网络抓包
所以tcpdump来抓https的包，也能抓，只不过数据无法破解，对吗？
你的理解完全正确！用 tcpdump 抓取 HTTPS 流量时，确实可以抓到数据包，但 无法直接解密其中的明文内容（如 HTTP 请求、响应体等），只能看到加密后的密文。以下是详细解释：
1. tcpdump 抓 HTTPS 包的实际情况
(1) 能抓到什么？
● 能捕获到数据包：
tcpdump 可以抓取所有经过网卡的 原始网络流量，包括 HTTPS 的加密数据包（如 TCP 握手、TLS 记录层数据）。
  ○ 例如：能看到 Client Hello、Server Hello 等 TLS 握手过程，但无法看到其中的 HTTP 请求（如 GET /index.html）。
(2) 不能解密的原因
● TLS/SSL 加密：
HTTPS 在传输层对 HTTP 数据加密，tcpdump 无法直接获取明文，因为： 
  a. 对称加密：TLS 握手后，客户端和服务端协商出一个 会话密钥（Session Key），后续通信用此密钥加密。
  b. 密钥不公开：会话密钥仅存在于客户端和服务端的内存中，tcpdump 无法直接获取。

2. 为什么 tcpdump 无法解密 HTTPS？
(1) 缺乏解密所需的密钥
● 会话密钥（Session Key） 是动态生成的，且仅由客户端和服务端共享。
● tcpdump 运行在网络层，无法访问客户端或服务端的密钥存储（如浏览器的 SSL 密钥库）。
(2) TLS 的设计目标就是防窃听
● HTTPS 的核心目的就是防止中间人（如 tcpdump）解密流量，即使攻击者能抓包，也无法直接读取内容。

3. 如何让 tcpdump 解密 HTTPS？（合法场景）
虽然默认无法解密，但在以下 合法且需主动配合 的场景下，可以间接实现解密：
(1) 客户端导出会话密钥（如浏览器调试）
● 原理：
让客户端（如 Chrome/Firefox）在 TLS 握手时记录会话密钥，并保存到文件（如 SSLKEYLOGFILE），然后用 Wireshark 或 tcpdump 结合密钥文件解密。
● 步骤： 
  a. 设置环境变量导出密钥： 
  b. 用浏览器访问 HTTPS 网站，密钥会自动保存到 keys.log。
  c. 用 Wireshark 配置密钥文件路径，即可解密抓到的 HTTPS 流量。
● 适用场景：
开发调试、安全分析（需用户主动配合）。
(2) 服务端解密（如代理服务器）
● 原理：
在客户端和服务端之间部署 透明代理（如 Nginx），代理服务器持有真实证书，解密流量后再转发给客户端或服务端。
● 适用场景：
企业内网审计、CDN 调试（需客户端信任代理证书）。
小林coding--操作系统
硬件结构
寄存器常见种类：
1.通用寄存器：用来存放需要进行运算的数据，比如需要进行加和运算的两个数据。
2.程序计数器：用来存储 CPU 要执行下一条指令「所在的内存地址」（是地址！）
3.指令寄存器：用来存放当前正在执行的指令，也就是指令本身
CPU程序执行的基本过程
1.cpu读取程序计数器的值，也就是指令内存的地址，从内存里面把需要执行的指令读取到指令寄存器里面执行，然后根据指令长度自增，开始顺序读取下一条指令。
（涉及到三个总线：地址，数据，控制总线）

CPU位宽是什么
CPU ⼀次能处理多少字节的数据，寻址能力 or 计算能力
CPU内部组件：
控制单元： 控制CPU⼯作； 
逻辑运算单元： 负责计算； 
寄存器： 在 CPU 中，计算速度快，临时存放数据的空间
寄存器常见类型及总线
通⽤寄存器：放运算数据 
程序记数器（PC）：⽤来存放 CPU 下⼀条要执⾏指令的 内存地址； 
指令寄存器：⽤来存放 PC 执⾏的指令，即 指令本身（取值后放⼊到 指令寄存器中）
地址总线： 
⽤于指定CPU将要操作的内存地址; 
数据总线： 
⽤于读写内存的数据; 
控制总线： 
⽤于发送和接收信号
程序执行的过程
1.取指，cpu向地址总线发送PC中的地址，从内存找到待执行的指令：
2.通过数据总线将指令传入CPU的指令寄存器中
3.自动更新PC，指向下一条指令地址
4.译指，计算型给逻辑运算单元运算;存储型给控制单元执行；进行执行
5.写回，将数据存回寄存器或者从寄存器存到内存
内存管理
1.为什么要有虚拟内存？
CPU->虚拟地址通过MMU->物理地址
分段：外部碎片+内存交换效率低（因为内存交换的是一个占用空间很大的程序，无内部碎片（因为可以按实际需求分配），
分页：无外部碎片，有内部碎片（固定为4KB为一页，并且紧密排列），换出效率高（因为内存交换时一次性写入磁盘只有少数几个页）
答：1.每个进程有自己的页表，并且虚拟地址空间之间相互独立，无法访问其他进程的页表，解决了多进程的地址冲突问题。
2.虚拟内存可以使得运行超过物理内存大小的程序，因为符合局部性原理，对于不常访问的到的内存可以暂时swap到磁盘中。
3.可以添加一些标志为来增加页一些读写权限（缺页，脏页等）。
4.方便程序员开发。
2.为什么不全部使用mmap（）或者brk（）来分配内存？
答：1.mmap每次会归还系统，虚拟地址一直处于缺页状态，每次发生缺页中断（第一次访问时），导致CPU消耗大。2.每次都要系统调用，开销大。
而brk（）在堆上分配，连续的，可以预分配作为内存池，减少了系统调用，以及放回内存池时，他的虚拟与物理地址的映射关系还存在，减少了缺页中断的次数，降低CPU消耗。
1.只用brk（）频繁的开辟，内存碎片会越来越多，会导致“内存泄漏”，valgrind是检测不出来的。
3.free（）函数只传入要释放的地址，怎么知道释放多大内存？
答：会有内存块头信息，每次free会自动偏移16字节去访问头部记录的信息。
4.swap()换入换出的是什么类型的文件？
1.文件页：因为有对应的磁盘文件，swap时，只需要判断是否为脏页进行回收就行了。
2.匿名页：像堆栈的数据等，没有实际的载体。但可能还会再次被访问，所以要有磁盘载体swap分区。
5.如何改进LRU算法？（缓存污染和预读失效）redis的LFU？
Linux活跃非活跃链表：
Mysql有young和old区域：
1.预读失效：因局部性原理被加载进来的页没有被访问，采用冷热数据，实现两个LRU
2.缓存污染：访问两次并且设定间隔时间阈值才加入到头部LRU链表
3.Redis的LFU：一种基于访问频率的缓存淘汰策略。随机选取一定数量数据，淘汰频率最小的几个，相同的话则根据时间戳，删除最久的
6.4GB怎么运行100GB游戏的？
问题	答案
为什么 4GB 内存可以运行 100GB 的游戏？	游戏并不会一次性加载所有资源，而是按需动态加载；操作系统提供虚拟内存机制作为扩展；游戏资源通常会被压缩存储；现代游戏引擎有强大的内存管理优化技术。
虚拟内存的作用是什么？	当物理内存不足时，虚拟内存通过硬盘作为扩展内存，允许程序使用更大的地址空间，但可能会因为硬盘速度较慢而导致卡顿。
游戏资源是如何管理的？	游戏采用动态加载机制，只加载当前需要的资源，并通过压缩、LOD、流式加载等技术减少内存占用。
如果内存不足会发生什么？	游戏可能会频繁卡顿、加载时间变长，甚至出现崩溃，建议配备足够的内存以获得更好的体验。
这是因为我们的程序是运行在虚拟地址空间中的，在这个空间中，只有正在运行的程序才会放到主存中运行，并且每个应用程序都会认为自己独享整个处理器的所有地址空间，因此程序可以任意的使用处理器的地址资源，这样编写程序的时候不需要考虑地址的限制。而当这些程序真正的放在处理器中运行的时候，就由操作系统负责调度，将物理存储器动态的分配给各个程序，将每个程序的虚拟地址转化为物理地址，使程序正常运行。
使用虚拟地址的好处还有 保护（protect） 和 共享（share），即使两个应用程序使用同一个虚拟地址，它们也会对应到不同的物理地址，因此可以保证不被其他程序任意改写，这就是保护。如果两个程序都是printf函数，并且使用了不同的虚拟地址空间，操作系统在地址转换的时候，会将不同的虚拟地址转换为同样的物理地址，大大节省了空间，这就是共享。
7.缺页中断的流程？

8.有TLB快表和无TLB块表？

9.栈溢出程序终止？MMU的作用？
● 当栈指针（SP）向下增长（x86/x86_64 架构）时，如果访问了未映射的物理页（即超出栈的虚拟地址范围）：
  a. MMU 发现该虚拟地址没有对应的物理页映射。
  b. 触发 缺页异常（Page Fault），CPU 跳转到操作系统的异常处理程序。
  c. 操作系统检查发现这是栈溢出（而非正常的缺页），直接终止进程（发送 SIGSEGV 信号）。
10.简单分页的缺陷？
空间上的缺陷：32位，单进程一个页4KB，虚拟内存4GB，就有2^20个页，一个页表项4字节，结果是4GB空间映射需要4*2^20=4MB存储页表。多进程100，需要400MB.以页表一定要覆盖全部虚拟地址空间，不分级的页表就需要有100多万个页表项来映射，二级分页则只需要1024个页表项(此时一级页表覆盖到了全部虚拟地址空间，二级页表在需要时创建)。
地址结构就由段号、段内⻚号和⻚内位移三部分组成。 
1. 第⼀次访问段表，得到⻚表起始地址 
2. 第⼆次访问⻚表，从对应的页表项中得到物理⻚号 
3. 第三次将物理⻚号与⻚内位移组合，得到物理地址
11.软链接和硬链接？
硬链接：是文件是文件的另一个名字（额外目录项），和原文件共享数据块（指向相同的物理内存），删除原文件不影响链接。
软链接：是一个指向目标文件路径的独立文件，可以跨文件系统，原文件删除后会失效。

12.虚拟内存分段和分页
操作系统将不同进程的虚拟地址和不同内存的物理地址映射起来
分段：
● 虚拟地址由段号和段内偏移量组成。
● 地址空间被划分为不同逻辑段，如代码段、数据段等
● 段长度可以动态变化，产生多个不连续的小物理内存，会出现外部内存碎片的问题
● 交换时需要找到更大的空闲内存来加载段，内存交换效率低
分页：
● 虚拟地址由页号和页内偏移组成。
● 地址空间被划分为固定大小的页面
● 页面长度固定，会导致页面内部有未使用空间，出现内部内存碎片的问题。
13.内存满了会发生什么
内核在分配物理内存的时候，如果空闲物理内存不够，那么就会进行内存回收的工作：
● 后台内存回收：幻想kswapd内核线程挥手内存，异步的，不会阻塞进程的执行
● 直接内存回收：如果后台回收跟不上申请速度，就会开始直接回收，同步的，会阻塞进程执行
可被回收的内存类型有文件页和匿名页，基于LRU方法，优先回收不常访问的内存。
swap机制是把一块磁盘空间或者本地文件，当成内存使用：
● 换出（Swap Out），把进程暂时不用的内存数据存到磁盘中，并释放这些数据占用的内存
● 换入（Swap In），在进程再次访问这些内存时，把他们从磁盘读到内存中
当同一页面频繁换入换出，叫做抖动，原因是进程频繁访问的页面数目高于可用的物理块数目（分配给进程的物理块不够）

进程线程
1.互斥锁与自旋锁的使用场景？
互斥锁：因为加锁与解锁，内核会令CPU睡眠或者就绪，涉及两次上下文切换。
自旋锁：在用户态完成加锁与解锁
所以当被锁的代码执行时间很短(小于上下文切换时间），用自旋锁，否则用互斥锁

2.CAS（原子操作）是乐观锁？
CAS（Compare-And-Swap，比较并交换）的核心思想是：先比较目标值是否符合预期，符合则修改；否则不做任何操作
CAS 是乐观锁的核心实现技术，是一种原子性操作，包含三个参数：
● 内存地址（V）：要修改的数据位置（如数据库表的某一行）。
● 预期原值（A）：操作前预期的值（如读取时的 version=1）。
● 新值（B）：要更新的新值（如 version=2 和修改后的数据）。
乐观锁通常通过版本号（Version）实现，具体流程如下：
1. 读取数据时：同时获取数据的当前值 和 版本号（如 version=1）。
2. 修改数据时：
  ○ 检查当前数据库中的版本号是否与读取时的版本号一致（即是否被其他事务修改过）。
  ○ 若一致，则更新数据并递增版本号（如 version=2）。
  ○ 若不一致，说明数据已被其他事务修改，当前操作失败（需重试或报错）。
CAS(比较并交换）ABA问题怎么解决？
● 场景：CAS操作期间值从A→B→A，误判为未变化。
● 解决：版本号（如AtomicStampedReference）。
3.共享内存和内存映射？
共享内存：进程间的“高速通道”，直接操作同一块内存，需自己管同步。
内存映射：把文件或内存“映射”到进程地址空间，既能读文件，也能当共享内存用。

4.如何避免僵尸进程？
● 僵尸进程：进程使用fork创建子进程，如果子进程退出，父进程没有调用wait获取子进程状态信息，那么子进程的进程描述符仍然存在。
● 孤儿进程：一个父进程退出，而子进程还在运行，那么子进程为孤儿进程，被init进程所收养，并对他们完成状态手机工作。
(1) 最简单的方法：
父进程通过 wait和 waitpid函数等待子进程结束，这会导致父进程挂起；
(2)如果父进程要处理的事情很多，不能够挂起，通过 signal函数人为处理信号:通过回调的方式，回调函数，因为子进程结束后，父进程会收到该信号，可以在其回调函数里调用 wait或 waitpid回收；
(3)如果父进程不关心子进程什么时候结束，那么可以用signal(SIGCHLD,SIG_IGN)通知内核：子进程结束后，内核会回收，并不再给父进程发送信号；
5.如何创建一个守护进程？
精灵进程，后台服务进程
1.创建子进程，然后父进程退出。这样子进程会被init进程接管，称为孤儿进程，在后台运行。
2.创建一个会话setid，并成为会话组长，从而脱离原来的终端控制。
3.然后重新设置文件目录，以及文件权限
4.删除一些不相关的文件描述符
5.开始执行守护进程处理程序
6.实战中如何避免死锁？
1. 固定锁的获取顺序：所有线程按相同顺序请求多个锁，避免循环等待。
2. lock（），用RAII机制，unique_lock或者lock_guard
3. lock（mtx1，mtx2，mtx3....),获取多把锁，失败时释放全部的锁
4. 尽量减少锁的使用：通过无锁数据结构、原子操作、线程本地存储等方式降低同步需求。
5. 缩小临界区：只锁必要的代码段，尽快释放锁。
6. 避免嵌套锁：尽量不要在一个锁的保护范围内再去获取另一个锁。
7. 使用高级并发工具：如线程池、消息队列、并发容器等，减少手动管理锁。
8. 加入超时机制：尝试获取锁时设置超时，超时后放弃或重试，避免无限等待。
目的破坏四个条件中的一个。
7.Linux多线程怎么GDB调式死锁？
info threads（查看所有线程）
thread <PID> 切换到对应线程
bt 打印调用栈，查看是否处于死锁状态
8.GDB调试core dump文件？
1.先系统限制开启，以及设置生成文件的对应路径
2.gdb <可执行程序路径> <core文件路径>
3.进入GDB后使用相关命令 bt（常用）print打印某个变量等
如果是多线程，如上info thread 选择线程
9.僵尸和孤儿进程？
1．孤儿进程：一个父进程退出，而它的一个或多个子进程还在运行，那么那些子进程将成为孤儿进程。孤儿进程将被init进程(进程号为1)所收养，并由init进程对它们完成状态收集工作。
2．僵尸进程：一个进程使用fork创建子进程，如果子进程退出，而父进程并没有调用wait或waitpid获取子进程的状态信息，那么子进程的进程描述符仍然保存在系统中。这种进程称之为僵户进程。
10.线程同步方式
1. 互斥锁：允许一个线程访问共享资源
2. 条件变量：用于线程间通信，线程等待某个条件满足，其他线程发送信号通知等待线程。
3. 读写锁：多个线程读资源，一个线程写资源
4. 信号量：控制多个线程多共享资源访问
锁
基础的锁
● 互斥锁：互斥访问共享资源，同一时间只有一个线程访问被保护资源
● 自旋锁：线程在尝试获取锁会不断轮询，直到锁释放，不会系统调用
● 读写锁：多个线程同时读共享资源，只允许一个线程写操作
● 悲观锁：认为同时修改共享资源概率高，所以访问共享资源要先上锁
● 乐观锁：先修改共享资源，如果出现同时修改的情况再放弃操作
● 分布式锁：
11.死锁
● 互斥条件：多个线程不能同时使用同一个资源
● 保持并等待条件：一个线程因为请求资源而阻塞时，不会释放自己的资源
● 不可剥夺条件：资源在自己使用完之前不能被其他线程获取
● 环路等待条件：每个线程都在等待下一个进程占用的资源，形成循环等待资源的环形链
破坏死锁：
● 破坏保持并等待条件：一次性申请所有资源
● 破坏不可剥夺条件：申请不到资源时，主动释放资源
● 破坏循环等待条件：所有进程按照相同顺序请求资源
12.中断和异常
中断和异常都会导致处理器暂停当前正在执行的任务，并转向一个特定的处理程序。
● 中断是由计算机系统外部事件触发，通常与硬件设备相关，包括时钟中断、I/O设备中断等。
● 异常是由计算机系统内部事件触发，通过与正在执行的程序或指令有关；
13.用户态和内核态
用户态和内核态是操作系统为了保护系统资源和实现权限控制而设计的两种CPU运行类别，可以控制进程或程序对计算机硬件资源的访问权限和操作范围。当系统调用、中断、异常时会发生内核态和用户态切换，需要操作系统提供服务。
● 用户态：在用户态下，进程或程序只能访问受限的资源和执行受限的指令集，不能之间访问操作系统核心部分和硬件资源。
● 内核态：操作系统的权限级别，允许进程或程序执行特权指令和访问操作系统的核心部分。
14.进程和线程
进程是系统进行资源分配基本单位。线程是CPU调度的最小单位。一个进程至少有一个进程，这些线程共享一块内存。
资源开销：
● 进程有独立的内存空间，创建和销毁进程的开销较大。进程间切换需要保存整个进程状态，上下文切换开销大
● 线程共享内存空间，创建和销毁线程的开销较小。线程间切换只需要保存少量的寄存器和栈内容，不需要切换页表，上下文切换开销较小
通信和同步：
● 进程间相互隔离，需要用管道、消息队列等方式通信
● 线程共享内存空间，可以直接访问共享数据
安全性：
● 进程相互隔离，一个进程崩溃不会直接影响其他进程稳定性
● 线程共享内存空间，一个线程错误影响整个进程稳定性
协程：用户态的轻量级线程，线程内部调度的基本单位，只在用户态调用，同一时间只能执行一个协程
15.进程的状态
● 运行状态：进程占用CPU正在运行的状态
● 就绪状态：进程获得除CPU外所有资源，等待进入运行状态
● 阻塞状态：进程等待某一事件发生而暂时停止运行
● 创建状态：进程申请一个空白进程控制块（PCB），进行资源分配，正在被创建的状态
● 结束状态：进程正在从系统消失的状态，无法再执行
● 挂起状态：阻塞的进程被换出到硬盘，阻塞挂起（等待事件发生）和就绪挂起（进入内存立刻运行）
16.进程间通信方式
● 管道：半双工通信方式，数据单向流动，只能父子进程使用
int pipe(int pipefd[2])  fd[0]为读，fd[1]为写
● 命名管道：允许无亲缘关系进程通信
fifo：int mkfifo(char* filename,mode_t mode)管道名称和权限 
● 信号量：控制多个进程对共享资源的访问，一种同步手段，使用P、V操作

● 消息队列：消息的链表
● 共享内存：最快的通信方式，一般配合信号量使用，实现进程间同步和通信
● socket套接字：客户端和服务器之间通信
17.进程调度算法
1. 先来先服务：从就绪队列选择最先进入队列的进程，一直运行直到退出或被阻塞，才会继续选择下一个，不利于短作业，适合CPU繁忙型系统
2. 最短作业优先：选择运行事件最短的进程来运行，对长作业不利，容易造成长作业长期不被运行
3. 高响应比优先调度算法：计算响应优先级，响应优先级最高的投入运行（优先权 = 等待时间 + 要求服务时间 /要求服务时间），理想型调度算法，要求服务时间不可预知
4. 时间片轮转：每个进程分配一个时间段20ms～50ms，用完或阻塞就分配给另一个进程
5. 多级队列：多个队列每个队列设置不同大小时间片，每个队列优先权不同，新进程放在第一级队列末尾，没运行完成转入第二级队列末尾，上一个队列没有进程才会调度到当前队列。

18.如何避免多线程的饥饿？
1.公平锁：公平策略
2.优先级继承：解决优先级翻转问题
3.避免长时间持有锁：缩短临界区、减少等待时间
4.带超时机制
网络系统
1.什么是一致性哈希？
因为普通轮询，只适于各个节点（服务器）存的数据相同的情况，而分布式系统中数据被水平切分到不同的节点上，实际我需要访问数据的时候，一定要去存这个数据的节点上！
不再使用简单的对数量进行取模哈希，而是模2^32-1,映射到首尾相连的圆环上。如果增加或者移除一个节点，只影响该节点在哈希环顺时针相邻的后继节点。节点少，不均匀的情况下则采用虚拟节点的方式。
2.什么是IO复用？
IO多路复用是单线程或进程处理多个输入输出操作的机制。他允许单个进程同时监听多个文件描述符，当发生可读可写的时候他就会响应。 通常通过select，poll，epoll等系统调用来实现。
总结：select 是最早的I/O多路复用技术，但受到文件描述符数量和效率方面的限制。poll克服了文件描述符数量的限制，但仍然存在一定的效率问题。epoll是一种高效的I/O多路复用技术，尤其适用于高并发场景，但它仅在Linux平台上可用。
一般来说，epoll的效率是要比select和poll高的，但是对于活动连接较多的时候，由于回调函数触发的很频繁，其效率不一定比select和poll高。所以epoll在连接数量很多，但活动连接较小的情况性能体现的比较明显。
3.阻塞与非阻塞I/O
● 阻塞I/O：当程序执行read，线程被阻塞，一直等到内核数据准备好，等待的是数据准备好和数据拷贝这两个过程
● 非阻塞I/O：数据未准备好立即返回，可以继续往下执行，应用程序不断轮询，直到数据准备好。
● I/O多路复用：通过I/O事件分发，当内核数据准备好，再通知应用程序，用户可以在一个线程同时处理多个socket的I/O请求/
阻塞I/O、非阻塞I/O、基于非阻塞的多路复用都是同步调用，数据从内核空间拷贝到应用程序空间都需要等待，这个过程是同步的。
异步I/O是aio_read，数据准备好会自动拷贝到应用进程。
4.PageCache
文件传输过程第一步是把磁盘文件数据拷贝到内核缓冲区，这个内核缓冲区就是磁盘高速缓存（PageCache）。
程序运行的时候具有「局部性」，用PageCache来缓存最近被访问的数据。PageCache使用了预读功能，比如read只读32KB的字节，内核会把后面32～64KB的字节也读到PageCache。
针对大文件传输，PageCache会不起作用，PageCache会很快被大文件展满，其他的热点小文件就无法被充分使用，性能下降。
5.I/O多路复用
● select/poll：使用线性结构存储Socket集合，需要遍历文件描述符集合来找到Socket，时间复杂度为O(n)，需要在用户态和内核态之间拷贝文件描述符集合。只支持水平触发
  ○ selece：将已知的Socket都放进一个文件描述符集合，再调用select函数拷贝到内核，通过遍历文件描述符方式检测是否有事件发生，再把整个文件描述符拷贝回用户态，用户态再通过遍历找到Socket，才进行处理。使用BitsMap表示文件描述符集合，所支持的个数有限。
  ○ poll：不再用BitsMap来存储所关注的文件描述符，改为动态数组，突破了描述符个数限制。
● epoll：linux独有，支持水平触发和边缘触发。
  ○ 在内核使用红黑树来跟踪带检测的文件描述符，只需要传入带检测的socket，减少了大量内核态和用户态的数据拷贝
  ○ 采用事件驱动机制，内核维护文件描述符列表，只有文件描述符就绪才会通知应用程序，不需要应用程序去遍历
6.Reactor模式
I/O多路复用监听事件，收到事件后，根据事件类型分配给某个进程/线程。
Rector模式由Reactor和处理资源池组成，Reactor负责监听和分发，处理资源池负责处理事件
7.异步和同步的区别，各有什么应用场景 ?阻塞和非阻塞，各有什么应用场景?
● 同步/异步：关注任务完成的通知机制（如何知道任务完成）。
● 阻塞/非阻塞：关注任务等待时的状态（等待时是否能做其他事）。
同步：调用者发起一个操作后，必须等待该操作完成并拿到结果，才能继续执行后续代码
异步：调用者发起一个操作后，不必等待其完成，可以继续执行其他代码，操作完成后会通过回调、信号、消息等方式通知调用者
阻塞：当一个操作不能立即完成时，调用者线程/进程会被挂起（阻塞），直到操作完成。
非阻塞：当一个操作不能立即完成时，调用者不会被挂起，而是立即得到一个“未就绪”或“忙”的返回值，可以继续做其他事情

常用命令
显示文件内容：cat
查看日志1000行：tail -n 1000 jf.log
列出运行中的进程：ps（静态） 、top（动态刷新）
找某个进程：ps aux | grep <进程名或关键字>
grep：查找文件符合条件的字符串
查看ip地址：ifconfig
查看网络：netstat -tuln
测试网络连接：ping



 
 
小林coding--Mysql
1.什么时候需要/不需要建立索引？
需要：1.字段有唯一性限制的
2.经常用于 WHERE 查询条件的字段，或者联合索引
3.经常用于GROUP BY和ORDER By的字段，不需要再排序
不需要：1.where，group by等用不到的字段
2.字段中存在大量重复数据   3.表数据较少时  
4.经常更新的字段不用创建索引
2.主键索引最好是自增的
如果我们使用自增主键，那么每次插入的新数据就会按顺序添加到当前索引节点的位置，不需要移动已有的数据，当页面写满，就会自动开辟一个新页面。因为每次插入一条新记录，都是追加操作，不需要重新移动数据，
如果我们使用非自增主键，由于每次插入主键的索引值都是随机的，因此每次插入新的数据时，就可能会插入到现有数据页中间的某个位置，这将不得不移动其它数据来满足新数据的插入，甚至需要从一个页面复制数据到另外一个页面，我们通常将这种情况称为页分裂。页分裂还有可能会造成大量的内存碎片，导致索引结构不紧凑，从而影响查询效率
3.索引优化方法

4.索引失效的情况
1.左右模糊匹配  2.查询条件中对索引使用了函数
3.查询条件中索引进行了表达式计算
4.MySQL会字符串转int当索引为int查询时用string会失效
5.联合索引需要遵循最左侧匹配原则
6.or的后面也需要是索引，不能是普通列
事务的隔离级别
特点：原子性（日志回滚）、一致性（共同控制）、隔离性（锁或者mvcc）、持久性（日志重做）
问题：脏读>不可重复读>幻读
脏读：读到其他事务未提交的数据
不可重复读：前后读取的数据不一致
幻读：前后读取的记录数量不一致
4个级别：
1.读未提交：事务还没提交时，做的变更就能被其他事务看到
2.读提交：事务提交之后，它做的变更才能被其他事务看到
3.可重复读：事务执行过程中看到的数据，跟启动时读的一样
MySQL InnoDB 引擎的默认隔离级别
4.串行化：对记录加上读写锁，多个事务进行读写操作时发生了冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行
三范式是什么？

InnoDB用的可重复读是怎么解决幻读的？
1.对于快照读，通过MVCC解决。它通过 版本链 + ReadView 让事务读取历史数据快照，从而避免幻读
(1) 快照读（普通 SELECT）：通过 MVCC 避免幻读
MVCC（Multi-Version Concurrency Control，多版本并发控制） 是 InnoDB 实现隔离级别的核心机制之一，它通过 版本链 + ReadView 让事务读取历史数据快照，从而避免幻读。
MVCC 的工作原理
1. 每行记录包含隐藏字段：
  ○ DB_TRX_ID：最近修改该行的事务 ID。
  ○ DB_ROLL_PTR：指向 undo log 的指针（用于回滚到旧版本）。
  ○ DB_ROW_ID：行 ID（如果没有主键，InnoDB 会自动生成）。
2. ReadView（读视图）：
  ○ 事务在第一次执行查询时，会生成一个 ReadView，记录当前活跃事务的 ID 列表（m_ids）和最小/最大事务 ID（min_trx_id、max_trx_id）。
  ○ 通过比较 DB_TRX_ID 和 ReadView 的规则，决定该行是否可见：
    ■ 如果 DB_TRX_ID < min_trx_id：可见（已提交的事务）。
    ■ 如果 DB_TRX_ID 在 m_ids 中：不可见（当前事务未提交）。
    ■ 如果 DB_TRX_ID > max_trx_id：不可见（未来事务）。
3. 快照读的隔离性：
  ○ 普通 SELECT 语句会基于 ReadView 读取历史数据快照，即使其他事务插入了新行，当前事务也看不到这些新行，从而避免幻读。
MVCC 的局限性
● MVCC 只能保证“历史快照”的一致性，但如果事务执行 当前读（如 SELECT ... FOR UPDATE），MVCC 就无法避免幻读，因为当前读需要读取最新数据。
(2) 当前读（SELECT ... FOR UPDATE 等）：通过 Next-Key Lock 避免幻读
Next-Key Lock 是 InnoDB 在可重复读隔离级别下解决幻读的关键机制，它结合了 记录锁（Record Lock） 和 间隙锁（Gap Lock），锁定索引记录及其之间的间隙，防止其他事务插入新数据。
Next-Key Lock 的组成
1. 记录锁（Record Lock）：
  ○ 锁定索引中的某一条记录（如 id=5 的行）。
2. 间隙锁（Gap Lock）：
  ○ 锁定索引记录之间的间隙（如 id>5 且 id<10 的范围）。
3. Next-Key Lock = 记录锁 + 间隙锁：
  ○ 例如，锁定 id>=5 且 id<10 的范围（包括 id=5 的记录和 5<id<10 的间隙）。
Next-Key Lock 如何避免幻读？
● 当执行 SELECT ... FOR UPDATE 时，InnoDB 会对查询条件涉及的索引范围加 Next-Key Lock：
  ○ 如果其他事务尝试在锁范围内插入新数据，会被阻塞，直到当前事务提交或回滚。
  ○ 这样，当前事务的两次查询结果一定一致，避免了幻读。
场景	机制	原理
快照读	MVCC	通过 ReadView 读取历史数据快照，避免看到其他事务插入的新行。
当前读	Next-Key Lock	锁定索引记录及其间隙，阻止其他事务插入新数据，保证两次查询结果一致。
InnoDB 的可重复读隔离级别之所以能避免幻读，是因为：
1. 普通 SELECT 通过 MVCC 读取快照，不受其他事务影响。
2. SELECT ... FOR UPDATE 等当前读操作通过 Next-Key Lock 锁定范围，防止新数据插入。
说一下多表查询
https://blog.csdn.net/m0_53022813/article/details/123972438?ops_request_misc=elastic_search_misc&request_id=7dace3f650831f4c153c42adc20411bb&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~top_positive~default-1-123972438-null-null.142^v102^pc_search_result_base9&utm_term=mysql%E5%A4%9A%E8%A1%A8%E6%9F%A5%E8%AF%A2&spm=1018.2226.3001.4187
SQL优化器是怎么知道该咋优化的？
优化器如何优化？
首先基于预定义的代价模型，通过统计信息（如表/索引的行数、数据分布、选择性等，这些数据通过ANALYZE命令定期收集）精确计算不同执行计划的I/O、CPU等资源消耗成本；接着应用固定规则（如优先使用索引、谓词下推等）对查询进行逻辑重写；最后在充分掌握表结构、索引等元数据的基础上，从多种可能的执行路径中筛选出综合成本最低的执行方案，从而实现查询性能的最优化
表级统计	- 总行数
● 数据页数
● 平均行长度
● 最后分析时间
列级统计	- 不同值的数量(基数)
● 最小值/最大值
● 数据分布直方图
● NULL值比例
索引统计	- 索引页数
● 索引高度
● 索引选择性
● 索引更新时间
什么是两阶段提交？


索引分类
按数据结构分类
● B+ Tree索引：
● HASH索引：
按字段特性分类
● 主键索引：主键索引是主键字段上的索引，索引列不能有空值
● 唯一索引：建立在UNIQUE字段上的索引，索引列值唯一，单可以有空值
● 普通索引：普通字段的索引
按物理存储
● 聚簇索引：放的是实际数据
● 二级索引：B+树叶子节点放的是主键值
索引
索引下推
在联合索引遍历过程中，对联合索引中包含的字段先做判断，直接过滤，减少回表次数
最左匹配
查询应该canoe索引最左边的列开始，不能跳过中间的列，不能使用范围查询，如（<, >）
为什么要采用B+树
● B+树非叶子节点不存实际数据，只存索引，数据了相同的情况下，相对于存索引和数据的B树，非叶子节点能存更多索引，B+树更加矮胖，查询叶子节点的磁盘I/O次数更少
● B+树有大量冗余节点，B+树插入、删除的效率都更高，不会像B树一样发生复杂的树变化
● B+树叶子节点之间用双链表连接，有利于范围查询
事务ACID四大特性
● 原子性：事务的所有操作要么全部成功，要么全部失败回滚（undo log回滚日志）
● 一致性：事务在执行前后，数据库从一个一致性状态转变到另一个一致性状态
● 隔离性：一个事务的执行不会影响其他事务的执行（MVCC或者锁）
● 持久性：事务处理结束后，对数据的修改是永久性的，系统故障也不会丢失（redo log重做日志）
数据库三大范式
● 第一范式：字段不可分，即原子性，字段不能再分
● 第二范式：有主键，非主键字段依赖主键
● 第三范式：非主键字段不能相互依赖，每列都与主键有直接关系
事务隔离级别
● 读未提交：允许事务读取另一个事务未提交的数据修改
● 读已提交：事务只能读取已经提交的数据
● 可重复读：事务执行期间，多次读取同一数据会得到相同结果，即其他事务对数据修改不可见
● 序列化：事务之间的并发执行效果和串行效果相同
读已提交和可重复读通过Read View实现，读已提交是在每个语句执行前生成一个Read View，可重复读是启动事务时生成一个Read View
Read View在MVCC（多版本并发控制）中使用，如果一个事务去访问记录，事务id小于min事务id，可见，大于max事务id，不可见，在min和max之间，在事务id列表中，表示依旧活跃，所以不可见，不在id列表中，表示已被提交，所以可见。
锁种类
● 全局锁：对整个数据库加锁，全库逻辑备份场景
● 表级锁：
  ○ 表锁：每次操作锁住整张表
  ○ 元数据锁（MDL）：不需要显式使用，对一张表CRUD加读锁，表结构变更加写锁
  ○ 意向锁：一个事务在未来可能会请求对资源的锁定
● 行级锁：
  ○ Record Lock：记录锁，把一条记录锁上，记录锁分为排他锁和共享锁
  ○ Gap Lock：间隙锁，锁定一个范围，用于可重复读的级别，解决可重复读级别下的幻读
  ○ Next-Key Lock：临键锁，锁定一个范围，锁定记录本身
日志
● undo log（回滚日志）：保证了原子性。实现MVCC时，如果对事务不可见，就会在undo log版本里找到可见的记录。
● redo log（物理日志）：保证了持久性。记录某个数据页做了什么修改，事务提交时需要先将redo log持久化到磁盘，当系统崩溃，虽然脏页数据没持久化，但redo log已经持久化，重启后可以恢复到最新状态。写入redo log的方式用了追加操作，是顺序写，写入数据是随机写，速度快了很多。
● bin log：记录所有数据库表结构变更和表数据修改，是循环谢，日志空间固定，全部写满就从头开始，用于备份恢复，主从复制
两阶段提交
1. prepare阶段：写入redo log，然后持久化到磁盘
2. commit状态：写入到binlog，持久化到磁盘，将redo log状态设置为commit，binlog写盘成功，就算redo log状态还是prepare也没关系
3. 当binlog内部没有id，则证明binlog还没刷盘，事务回滚，当binlog内部有id，则提交事务
慢查询优化
● 对搜索字段建索引
● 垂直分表
● 使用复合索引并遵循最左匹配
● 不使用select *
● 不在where条件字段上使用函数，这会导致索引失效而全盘扫描
● 尽量避免使用!=或not in 或<>等否定符号
● 使用覆盖索引可以回避回表操作

设计模式
单例模式
一个类只有一个实例，并提供一个全局访问点来访问创建模式。
1. 一个私有构造函数（确保只能单例类自己创造实力）
2. 一个私有静态变量（确保只有一个实例）
3. 一个共有静态函数（给使用者提供调用方法）

你在开发中使用哪些设计模式
1. 单例模式： ⽤于确保系统中某个类只有⼀个实例。在数据库连接、⽇志管理等场景中使⽤过。
2. ⼯⼚模式： ⽤于创建对象，将对象的创建过程封装在⼀个⼯⼚类中。在创建复杂对象、实现类的选择时使⽤过。
3. 观察者模式： ⽤于实现对象之间的⼀对多依赖关系，当⼀个对象的状态发⽣变化时，其所有依赖对象都会得到通知。实现⽤户界⾯和数据模型之间的通信、事件处理等场景。
4. 代理模式：主要⽬的是控制对对象的访问，可以添加额外的操作，⽽不改变原始对象的结构。
5.  适配器模式：主要⽬的是使得原本由于接⼝不兼容⽽不能⼀起⼯作的类可以⼀起⼯作。
单例模式，工厂，适配器，观察者模式分别属于设计模式的哪一类？
三类：创建型模式、结构型模式 和 行为型模式
单例模式：创建型模式    确保一个类只有一个实例，提供全局访问点
工厂模式：创建型  主要封装了对象的创建，而不关注其实现细节。
代理模式：结构型，通过代理类来控制实际对象的访问权限
适配器模式：结构型  可使不兼容的接口可以在一起工作。
观察者模式：行为型模式 定义对象一对多依赖关系，当一个对象状态改变时，所有依赖他的对象自动收到通知并更新。
小林coding--Redis
1.缓存雪崩，击穿，穿透？

2.如何确保数据库和缓存的一致性？
https://blog.csdn.net/zhizhengguan/article/details/122972503
3.高并发怎么优化？
https://www.zhihu.com/question/421237964/answer/1795200233?share_code=1buoPQW4dxt9a&utm_psn=1908100755254149856

redis常见数据结构以及使用场景
● String：简单的key-value类型，value不仅是string，也可以是数字，
● Hash：string类型的field和value的映射表，hash适合用于存储对象，后续操作时，可以仅仅修改这个对象中某个字段的值，比如存储用户信息
● List：实现为双向链表，支持反向查找和遍历，比如关注列表、消息列表等
● Set：与list类似，但是set可以自动去重，访客列表等
为什么需要Redis
● 高性能：直接操作内存，访问速度快
● 高并发：直接操作缓存能承受请求远超访问数据库，一些高热点请求可以转移到缓存中
● 支持事物：Redis操作都是原子性
redis的持久化策略
AOF日志+RDB快照 的混合模式。
定期删除策略
惰性删除+ 定期删除 混合。默认10s取20个，超过25%，则重复操作。
哨兵工作原理，脑裂
哨兵定期向redis服务器发送ping，检测活跃状态，之后通过复制偏移量、连接质量、优先级等投票选举，再向客户端通知。
为什么要有redis集群模式？

缓存雪崩、缓存穿透、缓存击穿
缓存雪崩
同一时间大面积的失效，后面的请求都会落到数据库上，造成数据库段时间内承受大量请求
缓存穿透
查找缓存和数据库中不存在的数据，这样每个查询都会去请求数据库，造成缓存穿透
1. 布隆过滤器：将所有可能存在的数据哈希到一个足够大的bitmap中，一般用于在大数据量大集合中判定某元素是否存在 ，适用于数据相对固定且实时性较低
2. 缓存空对象：当存储层不命中后，即使返回的空对象也缓存起来，同时设置一个过期时间，适用于数据频繁变化且实时性较高
缓存击穿
一个key非常热点，并发量很大，在这个key失效的瞬间，持续的高并发就穿透缓存，打到数据库

如何保持缓存与数据库双写的数据一致性
一般来说将读请求和写请求串行化。经典的缓存+数据库读写模式：
● 读的时候先读缓存，缓存没有读数据库，取出数据后放入缓存，同时返回响应
● 更新的时候，先更新数据库，再删除缓存，这样读的时候就会发现缓存中没有数据而直接去数据库中拿数据
https://blog.csdn.net/zhizhengguan/article/details/122972503
（1）对于读写缓存来说，如果我们采用同写回策略，就可以保证缓存和数据库中的数据一致
（2）对于只读缓存
缓存和数据库的数据不一致一般是由两个原因导致的。其解决方案总结如下：
● 删除缓冲值和更新数据库失败而导致数据不一致，可以使用重试机制确保删除或者更新操作成功
● 在删除缓存值、更新数据库的这两步操作中，有其他线程的并发读操作，导致其他线程读取到旧值，应对方案是延迟双删

另外，在大部分业务场景下，我们会把redis作为只读缓存使用。针对只读缓存来说，我们既可以先删除缓存值再更新数据库，也可以先更新数据库再删除缓存。建议是，优先使用先更新数据库再删除缓存的方法，原因主要有两个：
● 先删除缓存值在更新数据库，有可能导致请求因为缓存缺失而访问数据库，给数据库带来压力
● 如果业务应用中读取数据库和写缓存的时间不好估算，那么，延时双删中的等待时间就不好设置
不过，当使用先更新数据库再删除缓存时，也有个地方需要注意，如果业务层要求必须读取一致的数据，那么，我们就需要在更新数据库时，先在 Redis 缓存客户端暂存并发读请求，等数据库更新完、缓存值删除后，再读取数据，从而保证数据一致性。
为什么会出现数据不一致
主从同步、读写分离的情况下，读从库产生脏数据，A写了主库，B读缓存因为被A淘汰，读从库，此时还未主从同步，读出脏数据量。


海量数据处理
从大量URL中找出相同URL
● 分治：把一个文件中的URL进行哈希取余，分到多个小文件中，这样所有相同URL都在对应小文件中
● 前缀树：一般而言，URL的前面几个字符相同，这个时候适合使用字典树提高查询效率
大量数据找出高频词
分治，进行哈希取余，得到很多小文件，统计每个小文件出现的高频词，使用hashmap，最后使用小顶堆找出频数最高的100个
在大量数据中找到不重复整数
● 分治法：先将2.5亿个数分到多个小文件，用HashSet/HashMap找出小文件中不重复的整数，再合并每个子结果
● 位图法：用一个或多个bit来标记某个元素对应的值
在大量数据中判断一个数是否存在
● 分治法：与前面类似
● 位图法：先读取数据，将对应的bit设置为1，读取要查询的数所对应的bit位是否位1
毒药毒白鼠问题
1. 用10位二进制表示每个瓶子编号
2. 用每个瓶子的二进制表示对应的每一位决定哪只小白鼠要喝那瓶水
3. 观察哪些小白鼠死了，根据死亡的小白鼠形成一个新的10位二进制，就是有毒的瓶子编号
4. 最多可以检测2^ （小鼠个数）的瓶子
查询最热门的查询串
● 分治法：进行哈希取余，找出每个小文件最热门，再用小顶堆找出最热门
● 前缀树：
统计不同电话号码的个数
位图法：8位电话表示号码个数为10^8个，申请一个长度1亿的位图，遍历所有电话号码，把对应的位置置1，统计bit值为1的数量
5亿个数中找出中位数
● 双堆法：一个大顶堆一个小顶堆，大顶堆最大的数小于等于小顶堆最小的数，保证两个堆堆元素个数差不超过1，总数为偶数就是堆顶平均值，奇数就是较大的堆堆堆顶
● 分治法：对于读取到的数字，读取二进制最高位，区分出0和1的两部分，这时候就能确定是在f0的还是在f1中，再从对应的二进制次高位将文件一分为二，直到能被加载到内存中
找出排名前500的数
有20个数组，每个数组500个数，并且有序排列
首先建立大顶堆，堆大小为数组个数，把每个数组最大的值存到堆中，紧接着删除堆顶元素，保存到结果数组中，再向大顶堆插入删除数组的下一个元素，直到删除完第500个元素，也就找到了最大的前500
C++
基础语法
C++和Java
Java 和 C++ 都是面向对象的语言，都支持封装、继承和多态
语言特性
● Java语言给开发人员提供了更为简洁的语法；完全面向对象，由于JVM可以安装到任何的操作系统上，所以说它的可移植性强
● Java语言中没有指针的概念，引入了真正的数组。不同于C++中利用指针实现的“伪数组”，Jave引入了真正的数组，同时将容易造成麻烦的指针从语言中去掉，这将有利于防止在C++程序中常见的因为数组操作越界等指针操作而对系统数据进行非法读写带来的不安全问题
● C++也可以在其他系统运行，但是需要不同的编码（这一点不如Java，只编写一次代码，到处运行），例如对一个数字，在windows下是大端存储，在unix中则为小端存储。Java程序一般都是生成字节码，在JVM里面运行得到结果
● Java 的类是单继承的，C++ 支持多重继承；虽然 Java 的类不可以多继承，但是接口可以多继承。
● C ++同时支持方法重载和操作符重载，但是 Java 只支持方法重载（操作符重载增加了复杂性，这与 Java 最初的设计思想不符）
垃圾回收
● C++用析构函数回收垃圾，写C和C++程序时要注意内存的申请和释放
● Java语言不使用指针，内存的分配和回收都是自动进行的，程序员无须考虑内存碎片的问题
应用场景
● Java在桌面程序上不如C++实用，C++可以直接编译成exe文件，指针是c++的优势，可以直接对内存的操作，但同时具有危险性。（操作内存的确是一项非常危险的事情，一旦指针指向的位置发生错误，或者误删除了内存中某个地址单元存放的重要数据，后果是可想而知的）
● Java在Web 应用上具有C++ 无可比拟的优势，具有丰富多样的框架
● 对于底层程序的编程以及控制方面的编程，C++很灵活，因为有句柄的存在
为什么C++没有垃圾回收
● 实现垃圾回收会带来额外的空间和时间开销，需要开辟一个空间保存指针的引用计数，然后开辟一个线程在空闲的时候释放内存
● 垃圾回收会使得C++不适合进行很多底层操作
智能指针
● Shared_ptr：共享指针，采用引用计数，允许多个智能指针指向同一个对象，每当多一个指针指向该对象，引用计数+1，当计数为0时会自动释放动态分配的资源
● unique_ptr：独享指针，总是拥有他所指向的资源，转移一个unique_ptr将会把所有权全部从源指针转移给目标指针，源指针被置空
● weak_ptr：弱引用，如果循环引用，那么两个指针指向的内存都无法释放，需要使用weak_ptr，为了配合shared_ptr使用，指向一个shared_ptr对象而不影响所指对象的生命周期，只引用不计数
左值引用与右值引用
https://blog.csdn.net/m0_59938453/article/details/125858335?ops_request_misc=elastic_search_misc&request_id=417ad850345c773ac1d779fbb6367279&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~top_positive~default-1-125858335-null-null.142^v102^pc_search_result_base9&utm_term=c%2B%2B%E5%8F%B3%E5%80%BC%E5%BC%95%E7%94%A8%E4%B8%8E%E5%B7%A6%E5%80%BC%E5%BC%95%E7%94%A8&spm=1018.2226.3001.4187
vector与list
● vector和数组类似，有一段连续空间，并且起始地址不变，查看的时间复杂度为o(1)，插入删除1️⃣内存块的拷贝，时间复杂度为o(n)
● list由双向链表实现，内存空间不连续，只能通过指针访问，查看的时间复杂度为o(n)，但由于链表的特点，能高效的插入删除
常见数据结构
数据结构	访问/查找最值	搜索	插入	删除	空间复杂度	备注
数组 (Array)	O(1)	O(n)	O(n)	O(n)	O(n)	随机访问，插入删除需移动元素
动态数组 (Vector)	O(1)	O(n)	O(1)	O(n)	O(n)	末尾插入为O(1)
链表 (Linked List)	O(n)	O(n)	O(1)	O(1)	O(n)	已知位置时插入删除为O(1)
双向链表	O(n)	O(n)	O(1)	O(1)	O(n)	支持双向遍历
栈 (Stack)	O(1)栈顶	-	O(1)	O(1)	O(n)	LIFO，只能操作栈顶
队列 (Queue)	O(1)队首/队尾	-	O(1)	O(1)	O(n)	FIFO，队尾入队，队首出队
双端队列 (Deque)	O(1)两端	O(n)	O(1)两端	O(1)两端	O(n)	两端都可插入删除
哈希表 (Hash Table)	-	O(1)平均
O(n)最坏	O(1)平均
O(n)最坏	O(1)平均
O(n)最坏	O(n)	哈希冲突影响性能
解决哈希冲突
● 开放寻址法：1. 线性探测：发生冲突时，依次检查下一个位置 2. 二次探测：使用二次函数计算，负载因子较低时，内存使用效率要求高，缓存性能重要
● 链地址法：将哈希到同一位置的元素存储在链表中，适合不确定数据量大小的场景，内存充足
● 再哈希法：使用多个哈希函数，当第一个产生冲突时使用第二个
● 公共溢出区：将所有冲突的元素存放在单独的溢出区域
面向对象三大特性
1. 继承：使用现有类的功能，并可以对这些功能进行扩展
2. 封装：将客观事物封装成抽象类，类可以吧自己的数据和方法只让可信类和对象操作，比如使用public、private修饰
3. 多态：同一事物表现不同事物的能力，重载实现编译时多态，需函数实现运行时多态
C++的多态如何实现
在基类的函数前加上virtual关键字，在派生类中重写该函数，运行时会根据对象的实际类型来调用相应的函数。
实现多态的过程：
1. 编译器发现基类有需函数，自动为每个有需函数的类生成一份虚表，是一个一位数组，虚表里保存了虚函数的入口地址
2. 编译器会在每个对象的前四个字节中保存一个虚表指针，即vptr，指向对象所属类的虚表。在构造时，根据对象的类型去初始化虚表指针，从而让虚表指针指向正确的虚表，从而能调用正确的虚函数
3. 在派生类定义对象时，程序运行会自动调用构造函数，在构造函数中创建并初始化虚表。
4. 当派生类对基类的虚函数没有重写，虚表指针指向基类的虚表，重写时，指向自身的虚表，这样就可以根据重写情况进行动态调用，从而实现多态性。
虚表存在只读数据段(.rodata)，虚函数位于代码段(.text)
为什么析构函数写成虚函数
基类指针可以指向派生类对象，如果删除基类的指针，就会调用指向的派生类的析构函数，而派生类析构函数又会自动调用基类析构函数，如果析构函数不被声明为虚函数，实施静态绑定，在删除基类指针时，只会调用基类析构函数，派生类对象析构不完全，造成内存泄露。
构造函数能否声明为虚函数或者纯虚函数
● 创建一个对象时需要确定对象类型，而虚函数是运行时动态确定类型的，构造对象时，对象还未创建成功，编译器是无法知道对象的实际类型
● 虚函数对应一个虚表，类中存一个虚表指针，如果构造函数是虚函数，就需要通过虚表调用，但是对象未初始化没有虚表指针，找不到虚表，所以构造函数不能是虚函数
● 构造函数是创建对象时调用的，不可能通过父类或者引用去调用，使用不会是虚函数
构造函数和析构函数能调用虚函数吗
● 构造函数：父类在子类之前进行构造，此时子类还未完全初始化，调用虚函数是不安全的
● 析构函数：用来销毁对象，先调用子类析构，再调用基类，调用基类析构函数时，子类对象已经销毁，再调用虚函数没有意义
构造函数执行顺序
1. 虚拟基类的构造函数（多个虚拟基类则按照继承的顺序执行构造函数）。
2. 基类的构造函数（多个普通基类也按照继承的顺序执行构造函数）。
3. 类类型的成员对象的构造函数（按照成员对象在类中的声明顺序）
4. 派生类自己的构造函数。
析构函数执行顺序
1. 派生类自己的析构函数
2. 类类型的成员对象的析构函数
3. 基类的析构函数
4. 虚拟基类的析构函数
构造函数和析构函数能否抛异常
● 构造函数：构造函数中发生异常，控制权转出构造函数之外，析构函数不会调用，会造成内存泄露（采用智能指针，初始化列表构造）
● 析构函数：如果日常从析构函数抛出，那析构函数执行不全，会存在内存泄露问题
构造函数、拷贝构造函数和赋值操作符
● 构造函数：对象不存在，创建一个新的对象时调用构造函数
● 拷贝构造函数：对象不存在，使用别的已存在对象初始化
● 赋值运算符：对象存在，用别的对象给他赋值
拷贝构造函数和赋值运算符
● 拷贝构造函数是函数，赋值运算符是运算符重载
● 拷贝构造函数会生成新的对象，赋值运算符不行
拷贝构造函数必须传引用而不能传值
用传值的方式传参数，构造实参需要调用拷贝构造函数，而拷贝构造函数需要传递实参，会无限递归
虚函数的代价
1. 会产生一个虚函数表，用来存储指向虚函数的指针
2. 每一个对象会有一个指向虚表的虚表指针，增加对象的空间大小
3. 不能再是内联函数，内联函数在编译阶段替代，而虚函数需要等运行阶段确定
哪些函数不能是虚函数
1. 构造函数。
2. 内联函数：内联函数表示在编译阶段进行函数体的替换操作，虚函数意味着在运行期间动态确定类型
3. 静态函数：静态函数不属于对象属于类，没有this指针，设置为虚函数没有意义
4. 友元函数：不属于类的成员函数，不能被继承
5. 普通函数：不属于类的成员函数，没有继承特性
移动构造函数
场景：使用对象a初始化对象b后对象a不再使用，单对象a的空间还在，拷贝构造函数是将a的内容复制一份到b中，这时候想直接使用a的空间，就要用到移动构造函数。
当移动值的对象是临时变量，或者直接使用move将左值转化为右值，触发移动语义
C++内存分区
● 栈：执行函数时，存储局部变量，函数执行结束时自动被释放
● 堆：需要new出来的内存块，他们的释放由程序控制
● 全局/静态存储区：全局变量和静态变量被分到同一块内存中
● 常量存储区：存放常量字符串
● 代码区：存放函数体的二进制代码
this指针
● this指针是类的指针，指向对象首地址
● this指针只能在成员函数中使用，在全局函数、静态成员函数中不能使用
● this指针只有在成员函数中才有定义
● 使用delete this时，类对象的内存空间被释放，之后的其他函数调用，只要不涉及到this指针内容，都能正常运行，一旦涉及到this指针，如调用虚函数等，就会出现不可预期问题
● 如果在析构函数中调用delete this，delete的本质就是调用析构函数，这样就会无限递归，堆栈溢出
类对象的大小受哪些因素影响
1. 类的非静态成员变量大小，静态成员和成员函数不占据类空间大小
2. 内存对齐另外分配的空间大小
3. 虚函数的话，会在类对象插入vptr指针，加上指针大小
4. 当该类是某类的派生类，那么派生类继承的基类部分的数据成员也会存在在派生类的空间中，也会对派生类进行扩展
在main执行之前和之后执行
执行之前，主要是初始化系统相关资源
● 设置栈指针
● 初始化静态和全局变量，即.data内容
● 将为初始化部分的全局变量赋初值，即.bss内容
● 全局对象初始化，在main之前调用构造函数
执行之后
● 全局对象的析构函数
内存对齐
● 分配内存的顺序按照声明的顺序
● 每个变量相对于起始位置的偏移量必须是变量类型大小的整数倍
● 整个结构体大小必须是变量类型最大值的整数倍
struct Info {
  uint8_t a;   // 1 byte
  uint16_t b;  // 2 bytes (需2字节对齐)
  uint8_t c;   // 1 byte
};

Offset 0: a (1 byte)
Offset 1: [padding] (1 byte)  // 填充，确保 b 从 Offset 2 开始
Offset 2: b (2 bytes)
Offset 4: c (1 byte)
Offset 5: [padding] (1 byte)  // 填充，使结构体大小为对齐值的整数倍
指针和引用
● 指针是一个变量，存的是一个地址，引用和原来变量本质上是一个东西，是原变量别名
● 指针可以有多级，引用只能一级
● 指针可以为空，引用不能为NULL且定义时必须初始化
● 指针初始化后可以改变指向，引用不可变
● 指针作为参数传递，是将实参的拷贝给行参，指向地址相同但不是一个变量，不影响实参，而引用可以
常量指针和指针常量
● 常量指针是一个指针，指向一个只读变量，int const *p或const int *p，const修饰 *p
● 指针常量是一个不能改变方向的指针，即int *const p，const修饰 p（指针本身）
堆和栈
● 栈由系统自动分配，速度快，不会有碎片，是一块连续的内存区域
● 堆是自己申请和释放，速度慢，会有碎片，是不连续的内存区域
指针数组
int *p[10] //一个包含 10 个 int*（整型指针）的数组，存储多个指针（如字符串数组）
int (*p)[10]//一个指向 int[10]（10 个整型的数组）的指针，操作整个数组（如二维数组）
int *p(int)//一个函数声明，函数名为 p，接受一个 int 参数，返回 int*（整型指针），函数返回指针（需谨慎）
int (*p)(int)//一个函数指针，指向一个接受 int 参数并返回 int 的函数，动态调用函数（回调机制）

new/delete和malloc/free
● 前者是C++运算符，后者是标准库函数
● new要自动计算分配空间大小，malloc需要手工计算
● new是类型安全的，操作成功返回的是对象类型的指针，malloc不是，操作成功返回的是void *
● malloc和free分配和回收内存空间，new和delete还会调用构造函数和析构函数
● new封装了malloc，直接free不会报错，但这只是释放内存，没有析构对象
strlen和sizeof
特性	strlen	sizeof
作用	计算字符串长度（不含 \0）	计算变量/类型的内存大小
适用对象	仅 C 风格字符串（char* 或 char[]）	任何变量或类型
是否计算 \0	不计算	计算（如果是字符串）
计算时机	运行时（遍历字符串）	编译时（直接替换为常量）
  int main(int argc, char const *argv[]){
      
      const char* str = "name";

      sizeof(str); // 取的是指针str的长度，是8(64位)
      strlen(str); // 取的是这个字符串的长度，不包含结尾的 \0。大小是4
      return 0;
  }
a和&a
    int a[10] = {10, 20, 30, 40, 50, 60, 70, 80, 90, 100};
    int (*p)[10] = &a;  // p 是指向数组 a 的指针

    // 1. 验证 a 和 &a 的地址
    printf("a = %p\n", a);         // 输出 a[0] 的地址（如 0x00000001）
    printf("a + 1 = %p\n", a + 1); // 输出 a[1] 的地址（如 0x00000005）
    printf("&a = %p\n", &a);       // 输出数组 a 的起始地址（同 a[0]）
    printf("&a + 1 = %p\n", &a + 1); // 输出数组末尾的下一个地址（如 0x00000029）

    // 2. 通过 p 访问数组元素
    printf("(*p)[0] = %d\n", (*p)[0]); // 输出 a[0]（10）
    printf("(*p)[1] = %d\n", (*p)[1]); // 输出 a[1]（20）

    // 3. 强制转换 p 为 int*
    int *ptr = (int *)p;
    printf("*ptr = %d\n", *ptr);       // 输出 a[0]（10）
    printf("*(ptr + 1) = %d\n", *(ptr + 1)); // 输出 a[1]（20）
数组名和指针
● 都可以通过增减偏移量来访问数组中的元素
● 数组名不是真正意义上的指针，可以理解为常指针，无自增自减
● 当数组名当做形参传递给调用函数后，就失去原有特性，退化为一般指针，sizeof不能得到原数组大小
野指针和悬空指针
● 野指针：没有被初始化的指针
● 悬空指针：指向的内存已经被释放的指针
重载和重写
● 重载：函数名相同，参数类型和数目不同，根据参数类型来选择函数体
● 重写：在派生类覆盖基类中的同名函数，重写函数体，有相同的参数个数，参数类型，返回值类型，根据对象类型选择函数体
C++构造函数
#include <iostream>
using namespace std;

class Student{
public:
    Student(){//默认构造函数，没有参数
        this->age = 20;
        this->num = 1000;
    };  
    Student(int a, int n):age(a), num(n){}; //初始化构造函数，有参数和参数列表
    Student(const Student& s){//拷贝构造函数，这里与编译器生成的一致
        this->age = s.age;
        this->num = s.num;
    }; 
    Student(int r){   //转换构造函数,形参是其他类型变量，且只有一个形参
        this->age = r;
        this->num = 1002;
    };
    Student(const char* name, double score)// 接受任意类型指定参数的构造函数，
    {
        this->age = 0;
        this->num = (int)score;
    }
    Student(double r){   //转换构造函数,形参是其他类型变量，且只有一个形参
        this->age = (int)r * 10;
        this->num = 1003;
    };
    ~Student(){}
public:
    int age;
    int num;
};

int main(){
    Student s1;
    Student s2(18,1001);//初始化构造函数调用
    int a = 10;
    Student s3(a);//重载构造函数调用,传参数形式
    Student s4(s3);
    Student s5("Demo",56.45);//重载构造函数调用
    Student s6 = 85.63;//证明为转换构造函数调用
    float b = 5.2;
    Student s7 = b;//为转换构造函数调用，带有隐式类型转换
    
    
    printf("s1 age:%d, num:%d\n", s1.age, s1.num);
    printf("s2 age:%d, num:%d\n", s2.age, s2.num);
    printf("s3 age:%d, num:%d\n", s3.age, s3.num);
    printf("s4 age:%d, num:%d\n", s4.age, s4.num);
    printf("s5 age:%d, num:%d\n", s5.age, s5.num);
    printf("s6 age:%d, num:%d\n", s6.age, s6.num);
    printf("s7 age:%d, num:%d\n", s7.age, s7.num);
    return 0;
}
//运行结果
//s1 age:20, num:1000
//s2 age:18, num:1001
//s3 age:10, num:1002
//s4 age:10, num:1002
//s5 age:0, num:56
//s6 age:850, num:1003
//s7 age:50, num:1003

深拷贝与浅拷贝
● 浅拷贝：拷贝一个指针，并没有开辟新地址，如果原来指针指向资源被释放，那么再释放浅拷贝指针的资源就会报错
● 深拷贝：不仅拷贝值，还开辟一块新的空间用来存放新值，有指针变量的话需要自己实现深拷贝
public，protected和private访问和继承权限
● public的变量和函数在类的内部外部都可以访问，公有继承的特点是基类的公有成员和保护成员作为派生类的成员时，都保持原有的状态，而基类的私有成员任然是私有的，不能被这个派生类的子类所访问
● protected的变量和函数只能在类的内部和派生类中访问，保护继承的特点是基类的所有公有成员和保护成员都成为派生类的保护成员，并且只能被它的派生类成员函数或友元函数访问，基类的私有成员仍然是私有的
● private修饰的元素只能在类内访问，私有继承的特点是基类的所有公有成员和保护成员都成为派生类的私有成员，并不被它的派生类的子类所访问，基类的成员只能由自己派生类访问，无法再往下继承
大小端存储
● 大端存储：高字节存储在低地址（socket）
● 小端存储：低字节存储在低地址（操作系统）
#include <iostream>
using namespace std;
int main()
{
    int a = 0x1234;
    //由于int和char的长度不同，借助int型转换成char型，只会留下低地址的部分
    char c = (char)(a);
    if (c == 0x12)
        cout << "big endian" << endl;
    else if(c == 0x34)
        cout << "little endian" << endl;
}

值传递、指针传递和引用传递
● 值传递：有一个形参向函数所属的栈拷贝数据的过程
● 指针传递，有一个形参向函数所属的栈拷贝四字节地址的过程，传的是地址值
● 引用传递，为该数据所在地址取了个别名，传地址，不能返回局部变量的引用
内存泄露
一般是指堆内存的泄漏，分配了内存后，必须相应的调用delete或free释放内存块，不然就会内存泄漏
指针加减
#include <iostream>
using namespace std;

int main()
{
    int *a, *b, c;
    a = (int*)0x500;
    b = (int*)0x520;
    c = b - a;//两个指针之间的元素个数，而不是直接的地址差值
    printf("%d\n", c); // 8
    a += 0x020;//指针移动的单位是 类型大小，而不是字节，实际为0x020 * sizeof(int)
    c = b - a;
    printf("%d\n", c); // -24
    return 0;
}

函数调用过程栈的变化
1. 参数按从右向左的顺序压栈，为了支持可变参数函数（如 printf），第一个参数（格式字符串）最后压栈，便于定位
2. 执行call命令，将返回地址压栈
3. 保存当前的栈帧的基址ebp，再标记栈顶esp
4. 开始存放被调函数的变量
定义和声明
● 变量：声明就是告诉编译器有个类型的变量会被使用，但不会分配内存，定义就是分配了内存
● 函数：声明一般在头文件里，就是告诉编译器有这么个函数的存在，定义在源文件中，就是写明函数体
static变量和全局变量
● static：static全局变量只在定义该变量的源文件内有效，static函数作用域只在本文件中，static函数在内存中只有一份，普通函数在每个调用中都会拷贝一份
● 全局变量：用extern就可跨文件使用
C++从代码到可执行程序经历了什么
1. 预编译：展开头文件，处理宏定义，删除注释
2. 编译：语法语义分析，优化，生成汇编代码
3. 汇编：把汇编代码转变为机器码
4. 链接：将不同源文件产生的目标文件进行链接，形成可执行程序
  ○ 动态链接：把程序按照模块拆分成各个独立部分，程序运行时才链接到一起
  ○ 静态链接：把所有程序模块都链接成一个单独的可执行文件

施磊二刷
oop实现顺序栈
#include <iostream>
#include <string>  // 为了使用 std::string
using namespace std;

template <typename T>
class SeqStack {
public:
    SeqStack(int size = 10) {
        _pstack = new T[size];
        _top = -1;
        _size = size;
    }

    ~SeqStack() {
        delete[] _pstack;
        _pstack = nullptr;
    }

    void push(T val) {
        if (full()) {
            resize();
        }
        _pstack[++_top] = val;
    }

    void pop() {
        if (empty()) return;
        --_top;
    }

    T top() {
        return _pstack[_top];
    }

    bool empty() { return _top == -1; }
    bool full() { return _top == _size - 1; }

    void show() const {
        cout << _size << endl;
    }

private:
    T* _pstack;
    int _top;
    int _size;

    void resize() {
        T* ptmp = new T[_size * 2];
        for (int i = 0; i < _size; ++i) {
            ptmp[i] = _pstack[i];
        }
        delete[] _pstack;
        _pstack = ptmp;
        _size *= 2;
    }
};

int main() {
    SeqStack<int> s(25);  // 使用 int 类型的栈
    for (int i = 0; i < 30; ++i) {
        cout << i << " ";
        s.push(i);
    }
    for (int i = 0; i < 30; ++i) {
        cout << endl << s.top();
        s.pop();
    }
    s.show();

    cout << "Double type stack:" << endl;
    SeqStack<double> s2(10);  // 使用 double 类型的栈
    for (int i = 0; i < 5; ++i) {
        s2.push(i * 0.5);
        cout << "Pushed: " << i * 0.5 << endl;
    }
    for (int i = 0; i < 5; ++i) {
        cout << "Top: " << s2.top() << endl;
        s2.pop();
    }

    // 添加 string 类型的栈操作
    cout << "String type stack:" << endl;
    SeqStack<string> s3(10);  // 使用 string 类型的栈
    s3.push("Hello");
    s3.push("World");
    s3.push("C++ Templates");
    
    for (int i = 0; i < 3; ++i) {
        cout << "Top: " << s3.top() << endl;
        s3.pop();
    }

    return 0;
}

#include <iostream>
using namespace std;
class SeqStack
{
public:
    SeqStack(int size = 10) {
        _pstack = new int[size];
        _top = -1;
        _size = size;

    }

    ~SeqStack() {
        delete[]_pstack;
        _pstack = nullptr;
    }
    
    void push(int val) {
        if (full())
        {
            resize();
        }
        _pstack[++_top] = val;
    }
    void pop()
    {
        if (empty()) return;
        --_top;
    }
    int top()
    {
        return _pstack[_top];
    }

    bool empty() { return _top == -1; }
    bool full() { return _top == _size - 1; }
    void show() const
    {
        cout << _size << endl;
    }


private:
    int* _pstack;
    int _top;
    int _size;
    void resize()
    {
        int* ptmp = new int[_size * 2];
        for (int i = 0; i < _size; ++i)  //不要用memcpy(ptmp,_psatck,sizeof(int)*_size);以及realloc
                                         //内存的简单拷贝，要是是对象或指针会涉及到深浅拷贝问题！！！
        {
            ptmp[i] = _pstack[i];
        }
        delete[]_pstack;
        _pstack = ptmp;
        _size *= 2;
    }

};
int main()
{
    SeqStack s(25);
    for (int i = 0; i < 30; ++i)
    {
        cout << i << " "  ;
        s.push(i);
        //s.push(rand() % 100);
    }
    for (int i = 0; i < 30; ++i)
    {
        cout << endl<< s.top() ;
        s.pop();
    }
    s.show();


    return 0;
}

oop实现vector（无空间配置器）
重要！！！：当vector<test>  vec;时，用new时，开辟内存为10时，会自动进行对对象的10次构造（因为默认vector起始大小为10），而实际存放的对象数量可能只有几个，所以空间配置器allocator的作用是将内存开辟跟构造析构分开！！！
//定义自己的容器空间配置器，与C++标准库的allocator实现一样（小写）
template<typename T>
class Allocator
{
public:
    T* allocate(size_t size)  //开辟内存，但不构造
    {
        cout << "nihao " << endl;
        return (T*)malloc(sizeof(T) * size);
    }

    T* deallocate(void *p)  //内存释放
    {
        free(p);
    }

    void construct(T* p, const T& val)//负责对象构造
    {
        new (p) T(val);     //定位new，在开辟好的p上进行构造对象！
    }

    void destroy(T* p)    //析构对象
    {
        p->~T();//~T()代表T类型的析构函数
    }
};
#include <iostream>
#include <stdexcept> // for exceptions

template <typename T>
class Vector {
private:
    T* _first;   // 指向数据的开始
    T* _last;    // 指向当前存储的最后一个元素的后一个位置
    T* _end;     // 指向已分配空间的末尾

    // 扩容函数，使用 for 循环来迁移数据
    void resize(size_t newCapacity) {
        size_t currentSize = size();      // 获取当前元素个数
        T* newData = new T[newCapacity];  // 分配新空间

        // 使用 for 循环手动复制数据
        for (size_t i = 0; i < currentSize; ++i) {
            newData[i] = _first[i];
        }

        delete[] _first;                  // 释放旧空间
        _first = newData;                 // 更新指针
        _last = _first + currentSize;     // 更新当前大小
        _end = _first + newCapacity;      // 更新容量指针
    }

public:
    // 默认构造函数
    Vector() : _first(nullptr), _last(nullptr), _end(nullptr) {}

    // 拷贝构造函数，使用 for 循环来复制数据
    Vector(const Vector<T> & other) {
        size_t otherSize = other.size();
        _first = new T[otherSize];       // 分配与原 vector 大小相同的空间
        _last = _first + otherSize;
        _end = _last;

        // 使用 for 循环手动复制数据
        for (size_t i = 0; i < otherSize; ++i) {
            _first[i] = other._first[i];
        }
    }

    // 拷贝赋值操作符，使用 for 循环来复制数据
    Vector<T>& operator=(const Vector<T>& other) {
        if (this != &other) {  // 避免自赋值
            delete[] _first;   // 释放已有数据

            size_t otherSize = other.size();
            _first = new T[otherSize];   // 分配新空间
            _last = _first + otherSize;
            _end = _last;

            // 使用 for 循环手动复制数据
            for (size_t i = 0; i < otherSize; ++i) {
                _first[i] = other._first[i];
            }
        }
        return *this;
    }

    // 析构函数
    ~Vector() {
        delete[] _first;  // 释放内存
    }

    // 获取当前元素个数
    size_t size() const {
        return _last - _first;
    }

    // 获取容量
    size_t capacity() const {
        return _end - _first;
    }

    // 添加元素
    void push_back(const T& value) {
        if (_last == _end) {
            // 容量不够时扩容，初始时容量为 1，然后翻倍扩展
            size_t newCapacity = capacity() == 0 ? 1 : capacity() * 2;
            resize(newCapacity);
        }
        *_last = value;  // 插入元素
        ++_last;         // 增加元素个数
    }

    // 删除最后一个元素
    void pop_back() {
        if (_last > _first) {
            --_last;  // 减少元素个数
        } else {
            throw std::out_of_range("Vector is empty");
        }
    }

    // 下标访问运算符
    T& operator[](size_t index) {
        if (index >= size()) {
            throw std::out_of_range("Index out of bounds");
        }
        return _first[index];
    }

    // 常量版本的下标访问运算符
    const T& operator[](size_t index) const {
        if (index >= size()) {
            throw std::out_of_range("Index out of bounds");
        }
        return _first[index];
    }

    // 返回第一个元素
    T& front() {
        if (size() > 0) {
            return *_first;
        } else {
            throw std::out_of_range("Vector is empty");
        }
    }

    // 返回最后一个元素
    T& back() {
        if (size() > 0) {
            return *(_last - 1);
        } else {
            throw std::out_of_range("Vector is empty");
        }
    }

    // 清空容器
    void clear() {
        _last = _first;  // 不释放内存，只将大小置为 0
    }
};

int main() {
    Vector<int> vec;
    vec.push_back(1);
    vec.push_back(2);
    vec.push_back(3);

    std::cout << "Size: " << vec.size() << "\n";
    std::cout << "Capacity: " << vec.capacity() << "\n";

    for (size_t i = 0; i < vec.size(); ++i) {
        std::cout << "Element at " << i << ": " << vec[i] << "\n";
    }

    vec.pop_back();
    std::cout << "After pop_back, size: " << vec.size() << "\n";

    // 使用拷贝构造函数
    Vector<int> vecCopy(vec);
    std::cout << "Copy Size: " << vecCopy.size() << "\n";

    // 使用赋值操作符
    Vector<int> vecAssign;
    vecAssign = vec;
    std::cout << "Assign Size: " << vecAssign.size() << "\n";

    return 0;
}

#include <iostream>
#include <stdexcept> // for exceptions
#include <memory>  // for std::allocator
using namespace std;

template <typename T, typename Allocator = std::allocator<T>>
class Vector {
private:
    T* _first;   // 指向数据的开始
    T* _last;    // 指向当前存储的最后一个元素的后一个位置
    T* _end;     // 指向已分配空间的末尾
    Allocator alloc;  // 空间配置器

    // 扩容函数，使用 for 循环来迁移数据
    void resize(size_t newCapacity) {
        size_t currentSize = size();      // 获取当前元素个数
        T* newData = alloc.allocate(newCapacity);  // 分配新空间

        // 使用 for 循环手动复制数据
        for (size_t i = 0; i < currentSize; ++i) {
            alloc.construct(&newData[i], _first[i]);  // 使用分配器构造元素
        }

        // 销毁旧数据并释放内存
        for (size_t i = 0; i < currentSize; ++i) {
            alloc.destroy(&_first[i]);
        }
        alloc.deallocate(_first, capacity());

        _first = newData;                 // 更新指针
        _last = _first + currentSize;     // 更新当前大小
        _end = _first + newCapacity;      // 更新容量指针
    }

public:
    // 默认构造函数，初始化容量为 10
    Vector(int size = 10) : _first(nullptr), _last(nullptr), _end(nullptr) {
        _first = alloc.allocate(size);  // 分配初始容量为 10 的空间
        _last = _first;
        _end = _first + size;
    }

    // 拷贝构造函数，使用 for 循环来复制数据
    Vector(const Vector& other) {
        size_t otherSize = other.size();
        _first = alloc.allocate(otherSize);  // 分配与原 vector 大小相同的空间
        _last = _first + otherSize;
        _end = _last;

        // 使用 for 循环手动复制数据
        for (size_t i = 0; i < otherSize; ++i) {
            alloc.construct(&_first[i], other._first[i]);  // 使用分配器构造元素
        }
    }

    // 拷贝赋值操作符，使用 for 循环来复制数据
    Vector& operator=(const Vector& other) {
        if (this != &other) {  // 避免自赋值
            clear();           // 清空当前的元素
            alloc.deallocate(_first, capacity());  // 释放内存

            size_t otherSize = other.size();
            _first = alloc.allocate(otherSize);  // 分配新空间
            _last = _first + otherSize;
            _end = _last;

            // 使用 for 循环手动复制数据
            for (size_t i = 0; i < otherSize; ++i) {
                alloc.construct(&_first[i], other._first[i]);  // 使用分配器构造元素
            }
        }
        return *this;
    }

    // 析构函数
    ~Vector() {
        clear();  // 清空并销毁所有元素
        alloc.deallocate(_first, capacity());  // 释放内存
    }

    // 获取当前元素个数
    size_t size() const {
        return _last - _first;
    }

    // 获取容量
    size_t capacity() const {
        return _end - _first;
    }

    // 添加元素
    void push_back(const T& value) {
        if (_last == _end) {
            // 容量不够时扩容，初始时容量为 10，然后翻倍扩展
            size_t newCapacity = capacity() == 0 ? 10 : capacity() * 2;
            resize(newCapacity);
        }
        alloc.construct(_last, value);  // 使用分配器构造元素
        ++_last;         // 增加元素个数
    }

    // 删除最后一个元素
    void pop_back() {
        if (_last > _first) {
            --_last;  // 减少元素个数
            alloc.destroy(_last);  // 使用分配器销毁元素
        }
        else {
            throw std::out_of_range("Vector is empty");
        }
    }

    //// 下标访问运算符
    //T& operator[](size_t index) {
    //    if (index >= size()) {
    //        throw std::out_of_range("Index out of bounds");
    //    }
    //    return _first[index];
    //}

    //// 常量版本的下标访问运算符
    //const T& operator[](size_t index) const {
    //    if (index >= size()) {
    //        throw std::out_of_range("Index out of bounds");
    //    }
    //    return _first[index];
    //}

    // 返回第一个元素
    T& front() {
        if (size() > 0) {
            return *_first;
        }
        else {
            throw std::out_of_range("Vector is empty");
        }
    }

    // 返回最后一个元素
    T& back() {
        if (size() > 0) {
            return *(_last - 1);
        }
        else {
            throw std::out_of_range("Vector is empty");
        }
    }

    // 清空容器
    void clear() {
        while (_last != _first) {
            pop_back();  // 销毁所有元素
        }
    }
};


class test
{
private:
public:
    test() { cout << "构造函数" <<endl; }
    ~test() { cout << "析构函数" << endl; }
    test(const test&) { cout << "kaobei构造" << endl; }
};

int main() {

    Vector<test> ve(15);
    test v1,v2,v3;
    cout << "hhhhhhhhhhhhhhhhhhhhhhhhhhhhhh" << endl;
    ve.push_back(v1);
    ve.push_back(v2);
    ve.push_back(v3);
    cout << "hhhhhhhhhhhhhhhhhhhhhhhhhhhhhh" << endl;
    ve.pop_back( );
    cout << "hhhhhhhhhhhhhhhhhhhhhhhhhhhhhh" << endl;
    //Vector<int> vec;
    //for (int i = 1; i < 5; i++)
    //{
    //    vec.push_back(i);
    //}
    ////vec.push_back(1);
    ////vec.push_back(2);
    ////vec.push_back(3);

    //std::cout << "Size: " << vec.size() << "\n";
    //std::cout << "Capacity: " << vec.capacity() << "\n";

    //for (size_t i = 0; i < vec.size(); ++i) {
    //    std::cout << "Element at " << i << ": " << vec[i] << "\n";
    //}

    //vec.pop_back();

    ////std::cout << "After pop_back, size: " << vec.size() << "\n";

    ////// 使用拷贝构造函数
    ////Vector<int> vecCopy(vec);
    ////std::cout << "Copy Size: " << vecCopy.size() << "\n";

    ////// 使用赋值操作符
    ////Vector<int> vecAssign;
    ////vecAssign = vec;
    ////std::cout << "Assign Size: " << vecAssign.size() << "\n";

    return 0;
}

oop实现queue
#include <iostream>
#include <stdexcept> // for exceptions

template <typename T>
class Queue {
private:
    T* _data;        // 动态分配的数组，保存队列中的元素
    size_t _capacity; // 队列的容量
    size_t _size;     // 队列中的实际元素个数
    size_t _front;    // 指向队列头部元素的索引
    size_t _back;     // 指向队列尾部下一个位置的索引

    // 动态扩容函数
    void resize(size_t newCapacity) {
        T* newData = new T[newCapacity];  // 分配新空间
        // 使用 for 循环手动迁移数据，保持 FIFO 顺序
        for (size_t i = 0; i < _size; ++i) {
            newData[i] = _data[(_front + i) % _capacity];
        }
        delete[] _data;                   // 释放旧空间
        _data = newData;                  // 更新指针
        _capacity = newCapacity;          // 更新容量
        _front = 0;                       // 重置 front 索引
        _back = _size;                    // back 指向新的末尾
    }

public:
    // 默认构造函数
    Queue() : _data(nullptr), _capacity(0), _size(0), _front(0), _back(0) {}

    // 拷贝构造函数
    Queue(const Queue& other) {
        _data = new T[other._capacity];   // 分配与源队列相同的容量
        _capacity = other._capacity;
        _size = other._size;
        _front = 0;
        _back = _size;

        // 使用 for 循环手动复制数据，保持 FIFO 顺序
        for (size_t i = 0; i < _size; ++i) {
            _data[i] = other._data[(other._front + i) % other._capacity];
        }
    }

    // 赋值操作符重载
    Queue& operator=(const Queue& other) {
        if (this != &other) {             // 避免自赋值
            delete[] _data;               // 释放已有的资源

            _data = new T[other._capacity];  // 分配新空间
            _capacity = other._capacity;
            _size = other._size;
            _front = 0;
            _back = _size;

            // 使用 for 循环手动复制数据，保持 FIFO 顺序
            for (size_t i = 0; i < _size; ++i) {
                _data[i] = other._data[(other._front + i) % other._capacity];
            }
        }
        return *this;
    }

    // 析构函数
    ~Queue() {
        delete[] _data;  // 释放动态分配的内存
    }

    // 判断队列是否为空
    bool empty() const {
        return _size == 0;
    }

    // 获取队列中元素的个数
    size_t size() const {
        return _size;
    }

    // 返回队列的前部元素
    T& front() {
        if (empty()) {
            throw std::out_of_range("Queue is empty");
        }
        return _data[_front];
    }

    // 返回队列的前部元素（常量版本）
    const T& front() const {
        if (empty()) {
            throw std::out_of_range("Queue is empty");
        }
        return _data[_front];
    }

    // 返回队列的后部元素
    T& back() {
        if (empty()) {
            throw std::out_of_range("Queue is empty");
        }
        return _data[(_back - 1 + _capacity) % _capacity];
    }

    // 返回队列的后部元素（常量版本）
    const T& back() const {
        if (empty()) {
            throw std::out_of_range("Queue is empty");
        }
        return _data[(_back - 1 + _capacity) % _capacity];
    }

    // 向队列的末尾添加元素
    void push(const T& value) {
        if (_size == _capacity) {
            // 如果容量不足，扩容两倍
            size_t newCapacity = _capacity == 0 ? 1 : _capacity * 2;
            resize(newCapacity);
        }
        _data[_back] = value;            // 将元素添加到队列尾部
        _back = (_back + 1) % _capacity; // 循环使用索引
        ++_size;
    }

    // 移除队列头部元素
    void pop() {
        if (empty()) {
            throw std::out_of_range("Queue is empty");
        }
        _front = (_front + 1) % _capacity; // 移动 front 索引
        --_size;
    }

    // 清空队列
    void clear() {
        _size = 0;
        _front = 0;
        _back = 0;
    }
};

int main() {
    Queue<int> q;
    q.push(1);
    q.push(2);
    q.push(3);

    std::cout << "Front: " << q.front() << std::endl; // 输出: 1
    std::cout << "Back: " << q.back() << std::endl;   // 输出: 3

    q.pop();  // 移除 1

    std::cout << "Front after pop: " << q.front() << std::endl; // 输出: 2

    // 使用拷贝构造函数
    Queue<int> qCopy(q);
    std::cout << "Copy Front: " << qCopy.front() << std::endl; // 输出: 2

    // 使用赋值操作符
    Queue<int> qAssign;
    qAssign = q;
    std::cout << "Assign Front: " << qAssign.front() << std::endl; // 输出: 2

    return 0;
}



优先级队列，放map（等自定义类型）
#include <iostream>  
#include <map>  
#include <queue>  
#include <utility> // for std::pair  
#include <functional> // for std::greater (optional, if you want a min-heap)  

// 假设我们有一个 map，它的键是 int，值是 double  
std::map<int, double> myMap = {{1, 10.5}, {2, 20.3}, {3, 5.7}};  

//或者------------------------------------------
clsaa compareMapPairs {
public:
    bool operator() (const pair<int,int> &a , const pair<int,int> &b) {
        return a.first < b.first;
    }
};
priority_queue< pair<int,int>, vector<pair<int,int>>,compareMapPairs > pq;

//--------------------------------------------------


// 自定义比较器，根据 map 中值的属性来排序（这里直接比较值）  
auto compareMapPairs = [](const std::pair<const int, double>& a, const std::pair<const int, double>& b)
{  
    // 创建一个最大堆（默认行为），基于 map 的值  
    return a.second < b.second; // 注意：这里使用 < 来创建一个最大堆，因为 priority_queue 默认是最大堆  
    // 如果你想要一个最小堆，应该使用 >  
};  

// 定义一个优先队列，使用自定义的比较器  
std::priority_queue<std::pair<const int, double>, std::vector<std::pair<const int, double>>, decltype(compareMapPairs)> pq(compareMapPairs);  

int main() {  
    // 将 map 的元素添加到优先队列中  
    for (const auto& pair : myMap) {  
        pq.push(pair);  
    }  

    // 从优先队列中弹出元素，并打印它们（这里会按照值的降序打印）  
    while (!pq.empty()) {  
        std::cout << "Key: " << pq.top().first << ", Value: " << pq.top().second << std::endl;  
        pq.pop();  
    }  

    return 0;  
}
运算符重载
因为成员函数时不能实现 30+ complex，但可以complex+30，但全局重载函数都可以实现（要定义为友元函数）！！
#include <iostream>

class Complex {
private:
    double real; // 实部
    double imag; // 虚部

public:
    // 默认构造函数
    Complex(double r = 0.0, double i = 0.0) : real(r), imag(i) {}

    // 复数的加法运算符重载
    Complex operator+(const Complex& other) const {
        return Complex(real + other.real, imag + other.imag);
    }

    // 复数的减法运算符重载
    Complex operator-(const Complex& other) const {
        return Complex(real - other.real, imag - other.imag);
    }

    // 复数的乘法运算符重载
    Complex operator*(const Complex& other) const {
        return Complex(real * other.real - imag * other.imag, 
                       real * other.imag + imag * other.real);
    }

    // 复数的除法运算符重载
    Complex operator/(const Complex& other) const {
        double denominator = other.real * other.real + other.imag * other.imag;
        if (denominator == 0) {
            throw std::invalid_argument("Divide by zero error.");
        }
        return Complex((real * other.real + imag * other.imag) / denominator,
                       (imag * other.real - real * other.imag) / denominator);
    }

    // 复数的等号运算符重载
    Complex& operator=(const Complex& other) {
        if (this != &other) {
            real = other.real;
            imag = other.imag;
        }
        return *this;
    }

    // 输出运算符重载，用于打印复数
    friend std::ostream& operator<<(std::ostream& os, const Complex& c) {
        os << c.real;
        if (c.imag >= 0) {
            os << " + " << c.imag << "i";
        } else {
            os << " - " << -c.imag << "i";
        }
        return os;
    }

    // 输入运算符重载，用于输入复数
    friend std::istream& operator>>(std::istream& is, Complex& c) {
        std::cout << "Enter real part: ";
        is >> c.real;
        std::cout << "Enter imaginary part: ";
        is >> c.imag;
        return is;
    }
};

int main() {
    Complex c1, c2;
    
    std::cout << "Enter first complex number:\n";
    std::cin >> c1;
    
    std::cout << "Enter second complex number:\n";
    std::cin >> c2;

    std::cout << "c1 = " << c1 << std::endl;
    std::cout << "c2 = " << c2 << std::endl;

    Complex sum = c1 + c2;
    std::cout << "c1 + c2 = " << sum << std::endl;

    Complex diff = c1 - c2;
    std::cout << "c1 - c2 = " << diff << std::endl;

    Complex prod = c1 * c2;
    std::cout << "c1 * c2 = " << prod << std::endl;

    try {
        Complex div = c1 / c2;
        std::cout << "c1 / c2 = " << div << std::endl;
    } catch (const std::invalid_argument& e) {
        std::cout << e.what() << std::endl;
    }

    return 0;
}

#include <iostream>

class Complex {
private:
    double real; // 实部
    double imag; // 虚部

public:
    // 默认构造函数
    Complex(double r = 0.0, double i = 0.0) : real(r), imag(i) {}

    // 访问实部和虚部
    double getReal() const { return real; }
    double getImag() const { return imag; }

    // 设置实部和虚部
    void setReal(double r) { real = r; }
    void setImag(double i) { imag = i; }

    // 输出运算符重载，用于打印复数
    friend std::ostream& operator<<(std::ostream& os, const Complex& c);
    
    // 输入运算符重载，用于输入复数
    friend std::istream& operator>>(std::istream& is, Complex& c);
};

// 全局加法运算符重载
Complex operator+(const Complex& c1, const Complex& c2) {
    return Complex(c1.getReal() + c2.getReal(), c1.getImag() + c2.getImag());
}

// 全局减法运算符重载
Complex operator-(const Complex& c1, const Complex& c2) {
    return Complex(c1.getReal() - c2.getReal(), c1.getImag() - c2.getImag());
}

// 全局乘法运算符重载
Complex operator*(const Complex& c1, const Complex& c2) {
    return Complex(c1.getReal() * c2.getReal() - c1.getImag() * c2.getImag(),
                   c1.getReal() * c2.getImag() + c1.getImag() * c2.getReal());
}

// 全局除法运算符重载
Complex operator/(const Complex& c1, const Complex& c2) {
    double denominator = c2.getReal() * c2.getReal() + c2.getImag() * c2.getImag();
    if (denominator == 0) {
        throw std::invalid_argument("Divide by zero error.");
    }
    return Complex((c1.getReal() * c2.getReal() + c1.getImag() * c2.getImag()) / denominator,
                   (c1.getImag() * c2.getReal() - c1.getReal() * c2.getImag()) / denominator);
}

// 输出运算符重载
std::ostream& operator<<(std::ostream& os, const Complex& c) {
    os << c.real;
    if (c.imag >= 0) {
        os << " + " << c.imag << "i";
    } else {
        os << " - " << -c.imag << "i";
    }
    return os;
}

// 输入运算符重载
std::istream& operator>>(std::istream& is, Complex& c) {
    std::cout << "Enter real part: ";
    is >> c.real;
    std::cout << "Enter imaginary part: ";
    is >> c.imag;
    return is;
}

int main() {
    Complex c1, c2;

    std::cout << "Enter first complex number:\n";
    std::cin >> c1;

    std::cout << "Enter second complex number:\n";
    std::cin >> c2;

    std::cout << "c1 = " << c1 << std::endl;
    std::cout << "c2 = " << c2 << std::endl;

    Complex sum = c1 + c2;
    std::cout << "c1 + c2 = " << sum << std::endl;

    Complex diff = c1 - c2;
    std::cout << "c1 - c2 = " << diff << std::endl;

    Complex prod = c1 * c2;
    std::cout << "c1 * c2 = " << prod << std::endl;

    try {
        Complex div = c1 / c2;
        std::cout << "c1 / c2 = " << div << std::endl;
    } catch (const std::invalid_argument& e) {
        std::cout << e.what() << std::endl;
    }

    return 0;
}

complex operator++(int)
{
    return complex(mreal++,mimage++);
}

complex& operator++()
{
    mreal+=1;
    mimage+=1;
    return *this;
}

// 输出运算符重载
std::ostream& operator<<(std::ostream& os, const Complex& c) {
    os << c.real;
    if (c.imag >= 0) {
        os << " + " << c.imag << "i";
    } else {
        os << " - " << -c.imag << "i";
    }
    return os;
}

// 输入运算符重载
std::istream& operator>>(std::istream& is, Complex& c) {
    std::cout << "Enter real part: ";
    is >> c.real;
    std::cout << "Enter imaginary part: ";
    is >> c.imag;
    return is;
}
#include <iostream>
#include <cstring>  // for strlen, strcpy, etc.

class MyString {
private:
    char* data;    // 指向字符串数据的指针
    size_t length; // 字符串的长度

public:
    // 嵌套的迭代器类
    class Iterator {
    private:
        char* ptr; // 指向当前字符的指针
    public:
        // 构造函数
        Iterator(char* p) : ptr(p) {}

        // 重载解引用运算符，返回当前字符
        char& operator*() const {
            return *ptr;
        }

        // 重载前置++运算符，移动到下一个字符
        Iterator& operator++() {
            ++ptr;
            return *this;
        }

        // 重载后置++运算符，移动到下一个字符
        Iterator operator++(int) {
            Iterator temp = *this;
            ++ptr;
            return temp;
        }

        // 重载相等运算符
        bool operator==(const Iterator& other) const {
            return ptr == other.ptr;
        }

        // 重载不相等运算符
        bool operator!=(const Iterator& other) const {
            return ptr != other.ptr;
        }
    };

    // 默认构造函数
    MyString() : data(nullptr), length(0) {
        data = new char[1];
        data[0] = '\0';
    }

    // 通过 C 风格字符串构造 MyString
    MyString(const char* str) {
        length = std::strlen(str);
        data = new char[length + 1];
        std::strcpy(data, str);
    }

    // 拷贝构造函数
    MyString(const MyString& other) {
        length = other.length;
        data = new char[length + 1];
        std::strcpy(data, other.data);
    }

    // 移动构造函数
    MyString(MyString&& other) noexcept {
        data = other.data;
        length = other.length;
        other.data = nullptr;
        other.length = 0;
    }

    // 赋值运算符重载（深拷贝）
    MyString& operator=(const MyString& other) {
        if (this != &other) {
            delete[] data;  // 释放旧数据

            length = other.length;
            data = new char[length + 1];
            std::strcpy(data, other.data);
        }
        return *this;
    }

    // 移动赋值运算符
    MyString& operator=(MyString&& other) noexcept {
        if (this != &other) {
            delete[] data;  // 释放旧数据

            data = other.data;
            length = other.length;

            other.data = nullptr;
            other.length = 0;
        }
        return *this;
    }

    // 析构函数
    ~MyString() {
        delete[] data;
    }

    // 获取字符串长度
    size_t size() const {
        return length;
    }

    // 获取 C 风格字符串
    const char* c_str() const {
        return data;
    }

    // begin() 函数，返回指向字符串开头的迭代器
    Iterator begin() {
        return Iterator(data);
    }

    // end() 函数，返回指向字符串末尾（\0）的迭代器
    Iterator end() {
        return Iterator(data + length);
    }

    // 输出运算符重载
    friend std::ostream& operator<<(std::ostream& os, const MyString& str) {
        os << str.data;
        return os;
    }

    // 输入运算符重载
    friend std::istream& operator>>(std::istream& is, MyString& str) {
        char buffer[1024];
        is >> buffer;
        str = MyString(buffer);  // 使用赋值运算符
        return is;
    }
};

int main() {
    MyString str("Hello, World!");

    // 使用迭代器遍历字符串
    for (MyString::Iterator it = str.begin(); it != str.end(); ++it) {
        std::cout << *it << " ";
    }
    std::cout << std::endl;

    return 0;
}

#include <iostream>

// 定义 Pool 的项数量
#define POOL_ITEM_SIZE 10

template <typename T>
class QueueItem {
public:
    T _data;               // 队列节点的数据
    QueueItem* _next;      // 指向下一个节点的指针

    // 静态变量，用于对象池的管理
    static QueueItem* _itemPool;

    // 重载 new 运算符，从对象池中分配内存
    static void* operator new(size_t size) {
        // 如果对象池为空，初始化对象池
        if (_itemPool == nullptr) {
            // 分配一块连续的内存
            _itemPool = (QueueItem*)new char[POOL_ITEM_SIZE * sizeof(QueueItem)];

            // 将分配的内存块链接成一个链表，放入对象池
            QueueItem* p = _itemPool;
            for (size_t i = 0; i < POOL_ITEM_SIZE - 1; ++i) {
                p->_next = p + 1; // 指向下一个节点
                p++;
            }
            p->_next = nullptr; // 最后一个节点的 next 指针为 nullptr
        }

        // 从对象池中取出一个节点
        QueueItem* p = _itemPool;
        _itemPool = _itemPool->_next; // 更新对象池的头部
        return p;
    }

    // 重载 delete 运算符，将内存归还到对象池
    static void operator delete(void* ptr) {
        // 将释放的对象放回到对象池
        QueueItem* p = static_cast<QueueItem*>(ptr);
        p->_next = _itemPool;
        _itemPool = p;
    }
};

// 初始化静态变量
template <typename T>
QueueItem<T>* QueueItem<T>::_itemPool = nullptr;

// 链式队列类
template <typename T>
class Queue {
private:
    QueueItem<T>* front; // 指向队列头部
    QueueItem<T>* rear;  // 指向队列尾部

public:
    // 构造函数，初始化空队列
    Queue() : front(nullptr), rear(nullptr) {}

    // 入队操作，插入数据到队列尾部
    void enqueue(const T& value) {
        QueueItem<T>* node = new QueueItem<T>(); // 从对象池分配新节点
        node->_data = value;
        node->_next = nullptr;

        if (rear == nullptr) {
            front = rear = node;
        } else {
            rear->_next = node;
            rear = node;
        }
    }

    // 出队操作，移除队列头部的元素
    T dequeue() {
        if (front == nullptr) {
            throw std::out_of_range("Queue is empty");
        }

        QueueItem<T>* temp = front;
        T value = temp->_data;
        front = front->_next;

        if (front == nullptr) {
            rear = nullptr;
        }

        delete temp; // 归还节点到对象池
        return value;
    }

    // 检查队列是否为空
    bool isEmpty() const {
        return front == nullptr;
    }

    // 析构函数，销毁队列并释放所有节点
    ~Queue() {
        while (!isEmpty()) {
            dequeue();
        }
    }
};

int main() {
    Queue<int> queue;

    // 入队测试
    queue.enqueue(1);
    queue.enqueue(2);
    queue.enqueue(3);

    // 出队测试
    while (!queue.isEmpty()) {
        std::cout << "Dequeued: " << queue.dequeue() << std::endl;
    }

    return 0;
}

这行代码实际上做了以下几件事：
● 第一参数 ObjectPoolItem*：它是指向 ObjectPoolItem 的原始指针，也就是 std::unique_ptr 将要管理的对象。
● 第二参数 ObjectPoolDeleter：std::unique_ptr 的第二个模板参数定义了一个自定义的删除器。这个删除器默认是通过它的默认构造函数来创建的。
● ！！！！！！！！！！！！自定义删除器第二个传入的是类型类型类型类型！！！！！！！！！！！
● 用类名可以是因为类名就代表一个类型，函数需要用decltype（&函数名）出其类型void（*）（int）
ObjectPoolDeleter 是一个类型，在 std::unique_ptr 构造时，C++ 会自动使用 ObjectPoolDeleter 的默认构造函数（即 ObjectPoolDeleter()) 来创建删除器对象。
// 自定义删除器，使用对象池的 delete 运算符
struct ObjectPoolDeleter {
    void operator()(ObjectPoolItem* p) const {
        delete p; // 调用对象池的 delete
    }
};

int main() {
    // 使用 std::unique_ptr，并传入自定义删除器
    std::unique_ptr<ObjectPoolItem, ObjectPoolDeleter> item1(new ObjectPoolItem);
    item1->data = 100;
    std::cout << "Item1 Data: " << item1->data << std::endl;
在 C++ 中，自定义删除器可以是一个函数、函数对象（如 struct 或 class）、或者类的成员函数。标准库中的智能指针（如 std::unique_ptr 和 std::shared_ptr）支持这些不同类型的删除器。
1. 使用普通函数作为自定义删除器
你可以将一个普通的全局函数作为 std::unique_ptr 的删除器，传递给智能指针。
示例：使用全局函数作为删除器
#include <iostream>
#include <memory>

// 定义一个普通函数作为删除器
void customDeleter(int* ptr) {
    std::cout << "Custom delete function called. Deleting int pointer." << std::endl;
    delete ptr;
}

int main() {
    // 创建一个 std::unique_ptr，使用普通函数作为删除器
    std::unique_ptr<int, decltype(&customDeleter)> p(new int(42), customDeleter);

    std::cout << "Value: " << *p << std::endl;

    // 智能指针超出作用域时调用 customDeleter 函数
    return 0;
}
说明：
● decltype(&customDeleter) 用来获取 customDeleter 函数的类型，以作为 std::unique_ptr 的删除器类型。
● 当智能指针 p 超出作用域时，它会自动调用 customDeleter 来释放内存。
2. 使用 struct 或 class 函数对象作为删除器
自定义删除器也可以是一个函数对象（functor），它是一个带有 operator() 的类或结构体。这样可以通过成员变量来存储删除时需要的额外信息。
示例：使用 struct 作为删除器
#include <iostream>
#include <memory>

// 自定义删除器结构体
struct CustomDeleter {
void operator()(int* ptr) const {
    std::cout << "CustomDeleter struct called. Deleting int pointer." << std::endl;
    delete ptr;
}
};

int main() {
    // 使用自定义删除器（函数对象）创建 std::unique_ptr
    std::unique_ptr<int, CustomDeleter> p(new int(42));

    std::cout << "Value: " << *p << std::endl;

    // 智能指针超出作用域时调用 CustomDeleter::operator()
    return 0;
}
说明：
● CustomDeleter 定义了一个 operator()，这使得它可以像函数一样被调用。
● 当 std::unique_ptr 的对象超出作用域时，会自动调用 CustomDeleter 的 operator()，从而释放内存。
3. 使用类的成员函数作为删除器
如果你希望在某个类中定义一个成员函数作为删除器，你可以使用 std::bind 或 Lambda 表达式将该成员函数绑定到智能指针中。
示例：使用成员函数作为删除器
#include <iostream>
#include <memory>
#include <functional>  // For std::bind

// 类定义
class MyClass {
    public:
    // 成员函数作为自定义删除器
    void customDelete(int* ptr) const {
        std::cout << "MyClass::customDelete called. Deleting int pointer." << std::endl;
        delete ptr;
    }
};

int main() {
    MyClass obj;

    // 使用 std::bind 将成员函数绑定到智能指针
    std::unique_ptr<int, std::function<void(int*)>> p(new int(42), 
    std::bind(&MyClass::customDelete, &obj, std::placeholders::_1));

    std::cout << "Value: " << *p << std::endl;

    // 智能指针超出作用域时，调用 MyClass::customDelete 释放内存
    return 0;
}
说明：
● std::bind 用于绑定成员函数 MyClass::customDelete 到 std::unique_ptr 的删除器中。
● std::placeholders::_1 用来占位表示传递给删除器的参数，也就是智能指针管理的 int* 指针。
● 通过这种方式，当智能指针超出作用域时，会调用类的成员函数来释放内存。
4. 使用 Lambda 表达式作为删除器
C++11 引入了 Lambda 表达式，使用 Lambda 作为删除器更加简洁，尤其是在类的成员函数的场景下。
示例：使用 Lambda 表达式作为删除器
#include <iostream>
#include <memory>

int main() {
    // 使用 Lambda 表达式作为自定义删除器
    auto deleter = [](int* ptr) {
        std::cout << "Lambda deleter called. Deleting int pointer." << std::endl;
        delete ptr;
    };

    std::unique_ptr<int, decltype(deleter)> p(new int(42), deleter);

    std::cout << "Value: " << *p << std::endl;

    // 智能指针超出作用域时调用 Lambda 表达式
    return 0;
}

top-K问题，自定义priority_queue
！！！！！！！！！！！！！！同上节的智能指针自定义删除器的方法，要传入类型！！！！！！！！！！！！
class compare
    {
    public:
        bool operator()(pair<int,int>&a,pair<int,int>&b)
        {
            return a.second < b.second;  //表示小的在下面，大的值在堆顶，为大根堆
        }
    };
priority_queue< pair<int,int> , vector<pair<int,int>>,compare> que;

class Solution {
public:
    class compare
    {
    public:
        bool operator()(pair<int,int>&a,pair<int,int>&b)
        {
            return a.second < b.second;  //表示小的在下面，大的值在堆顶，为大根堆
        }
    };

    vector<int> topKFrequent(vector<int>& nums, int k) {
        int n = nums.size()-1;
        unordered_map<int,int> cnt;
        for(int i = 0;i<=n;i++)
        {
            cnt[nums[i]]++;
        }
        priority_queue< pair<int,int> , vector<pair<int,int>>,compare> que;
        for(auto &m : cnt)
        {
            que.push(m);
        }
        vector<int> res(k);
        for(int i = 0;i<k;i++)
        {
            //res.push_back(que.top().first);
            res[i] = que.top().first;
            que.pop();
        }
        return res;
    }
};
继承权限问题


继承影响类大小问题
影响class类大小的因素 为什么静态函数不占用class的大小 类的成员函数 this指针_以下哪个因素会影响类的大小-CSDN博客
静态变量不影响类对象的大小，它不属于对像实例，而是类
 
Lambda 表达式的底层原理
Lambda 表达式的实现依赖于匿名函数对象 (function object) 或 闭包 (closure) 的概念。底层的原理是通过生成一个未命名的类，其中重载了 operator()，使得 Lambda 表达式行为上与函数非常类似。
底层生成的类
● 当编译器遇到一个 Lambda 表达式时，实际上会创建一个对应的匿名类（称为闭包类）。
● 这个闭包类包含了捕获的变量，并定义了一个重载的 operator()，该操作符的定义相当于 Lambda 表达式的函数体。
例如，考虑以下 Lambda 表达式：
int x = 10;
auto lambda = [x](int y) {
    return x + y;
};
编译器会生成一个类似于以下代码的闭包类：
class __lambda_generated {
private:
int x;  // 捕获的变量 x

public:
// 构造函数，初始化捕获的变量
__lambda_generated(int x) : x(x) {}

// 重载的 operator()，实现 Lambda 的行为
int operator()(int y) const {
    return x + y;
}
};

// 使用闭包类创建 Lambda 实例
__lambda_generated lambda = __lambda_generated(10);
int result = lambda(5);  // result = 15
● 捕获的变量存储在闭包类的成员变量中。
● 函数调用通过 operator() 完成，这使得 Lambda 表达式可以像普通函数一样调用。

内存泄漏检测以及野指针检测
【深信服】C++如何检测内存泄漏问题?使用什么工具
Valgrind 是一个流行的内存调试工具，特别是在 Linux 环境下。它的 memcheck 工具能够检测内存泄漏、未初始化内存的使用和非法的内存访问。
  a. Ubuntu
apt update
apt install -y valgrind
  a. 使用要求： 编译程序时使用调试信息选项 -g。
  b. 使用方法：使用 valgrind 运行程序：valgrind --leak-check=full ./your_program
  c. 常用选项：
     --leak-check=full：启用详细的内存泄漏检测。
     --track-origins=yes：在内存未初始化时，报告其来源。
       --log-file=filename：将 Valgrind 的输出写入文件 filename
#include <iostream>

void func(){
    int* p = new int(10);
}

int main(){

    func();
    return 0;
}
验证结果
[root:~/stutest]# valgrind --leak-check=full ./a.out 
    ==1536437== Memcheck, a memory error detector
        ==1536437== Copyright (C) 2002-2017, and GNU GPL'd, by Julian Seward et al.
        ==1536437== Using Valgrind-3.18.1 and LibVEX; rerun with -h for copyright info
        ==1536437== Command: ./a.out
        ==1536437== 
        ==1536437== 
        ==1536437== HEAP SUMMARY:
        ==1536437==     in use at exit: 4 bytes in 1 blocks
        ==1536437==   total heap usage: 2 allocs, 1 frees, 72,708 bytes allocated
        ==1536437== 
        ==1536437== 4 bytes in 1 blocks are definitely lost in loss record 1 of 1
        ==1536437==    at 0x48657B8: operator new(unsigned long) (in /usr/libexec/valgrind/vgpreload_memcheck-arm64-linux.so)
        ==1536437==    by 0x1088E3: func() (test.cpp:4)
==1536437==    by 0x108907: main (test.cpp:9)
        ==1536437== 
        ==1536437== LEAK SUMMARY:
        ==1536437==    definitely lost: 4 bytes in 1 blocks
==1536437==    indirectly lost: 0 bytes in 0 blocks
==1536437==      possibly lost: 0 bytes in 0 blocks
==1536437==    still reachable: 0 bytes in 0 blocks
==1536437==         suppressed: 0 bytes in 0 blocks
==1536437== 
        ==1536437== For lists of detected and suppressed errors, rerun with: -s
        ==1536437== ERROR SUMMARY: 1 errors from 1 contexts (suppressed: 0 from 0)
结果解释：
==1536437== HEAP SUMMARY:
    ==1536437==     in use at exit: 4 bytes in 1 blocks
    ==1536437==   total heap usage: 2 allocs, 1 frees, 72,708 bytes allocated
堆摘要：
  in use at exit: 4 bytes in 1 blocks：在程序结束时，有 4 字节的内存仍然在使用，这意味着有一块 4 字节的内存没有被释放。
   total heap usage: 2 allocs, 1 frees, 72,708 bytes allocated：程序总共进行了 2 次内存分配操作（allocs），但是只进行了 1 次内存释放操作（frees），总共分配了 72,708 字节的内存。
泄漏摘要
   4 bytes in 1 blocks are definitely lost in loss record 1 of 1：Valgrind 确认有 4 字节内存泄漏，这次泄漏的详细信息如下：
   at 0x486578B: operator new(unsigned long) (in /usr/libexec/valgrind/vgpreload_memcheck-arm64-linux.so)：内存是在调用 operator new 时分配的，这通常表示你使用了 new 操作符分配了内存。
   by 0x1088E3: func() (in /root/stutest/a.out)：func() 函数中进行了内存分配，这是导致内存泄漏的地方。
   by 0x108907: main (in /root/stutest/a.out)：main 函数调用了 func()，导致了内存泄漏。
错误摘要
    1 errors from 1 contexts (suppressed: 0 from 0)：总共检测到 1 个内存泄漏错误，且没有任何错误被抑制。
懒汉饿汉单例模式
1. 懒汉模式 (Lazy Initialization)
懒汉模式是在第一次使用单例实例时才进行实例化，也称为延迟初始化。这种模式可以节省内存，并且在需要时才进行实例化。
实现特点：
● 延迟初始化：实例在第一次调用 getInstance() 时才被创建。
● 线程安全：在多线程场景下，需要特别处理以保证实例化过程是线程安全的。
实现方式：
可以用双重检查锁（Double-Checked Locking）来实现懒汉模式，并确保线程安全：
#include <iostream>
#include <mutex>

class LazySingleton {
    public:
    static LazySingleton* getInstance() {
        if (instance == nullptr) {  // 第一次检查
            std::lock_guard<std::mutex> lock(mtx);  // 加锁，保证线程安全
            if (instance == nullptr) {  // 第二次检查
                instance = new LazySingleton();
            }
        }
        return instance;
    }

    LazySingleton(const LazySingleton&) = delete;
    LazySingleton& operator=(const LazySingleton&) = delete;

    void doSomething() {
        std::cout << "Doing something in LazySingleton instance." << std::endl;
    }

    private:
    LazySingleton() {
        std::cout << "LazySingleton instance created." << std::endl;
    }

    ~LazySingleton() {
        std::cout << "LazySingleton instance destroyed." << std::endl;
    }

    static LazySingleton* instance;  // 静态指针成员
    static std::mutex mtx;           // 静态互斥锁，保证线程安全
};

// 初始化静态成员
LazySingleton* LazySingleton::instance = nullptr;
std::mutex LazySingleton::mtx;

int main() {
    LazySingleton* singleton = LazySingleton::getInstance();
    singleton->doSomething();

    return 0;
}
代码解析：
● 双重检查锁：
  ○ 在 getInstance() 中，使用双重检查锁确保实例的创建是线程安全的，但又不会在每次调用时加锁，从而提高了性能。
  ○ 第一次检查确保只有实例为空时才进入锁定代码段，第二次检查确保在多线程环境下，只有一个线程最终创建实例。
● 互斥锁：
  ○ 使用 std::mutex 来实现线程安全的互斥访问，确保只有一个线程可以进行实例化操作。
2. 饿汉模式 (Eager Initialization)
饿汉模式是在类加载时就将单例实例化。它通过静态成员在程序开始时创建单例对象，因此无需考虑线程安全问题。
实现特点：
● 提前初始化：实例在程序启动时就被创建，无需等待第一次调用。
● 线程安全：由于在程序加载时已经创建，天然是线程安全的。
实现方式：
饿汉模式使用静态成员变量直接初始化：
#include <iostream>

class EagerSingleton {
public:
static EagerSingleton& getInstance() {
    return instance;
}

EagerSingleton(const EagerSingleton&) = delete;
EagerSingleton& operator=(const EagerSingleton&) = delete;

void doSomething() {
    std::cout << "Doing something in EagerSingleton instance." << std::endl;
}

private:
EagerSingleton() {
    std::cout << "EagerSingleton instance created." << std::endl;
}

~EagerSingleton() {
    std::cout << "EagerSingleton instance destroyed." << std::endl;
}

static EagerSingleton instance;  // 静态成员变量，在类加载时创建实例
};

// 初始化静态成员变量
EagerSingleton EagerSingleton::instance;

int main() {
    EagerSingleton& singleton = EagerSingleton::getInstance();
    singleton.doSomething();

    return 0;
}
代码解析：
● 静态成员变量：
  ○ 静态成员变量 instance 在类加载时被初始化，这保证了实例的唯一性和线程安全性。
● 提前实例化：
  ○ 实例在程序启动时创建，因此无需任何同步机制来保证线程安全。
懒汉模式 vs 饿汉模式
特性	懒汉模式 (Lazy Initialization)	饿汉模式 (Eager Initialization)
实例化时机	第一次使用时进行实例化	类加载时即进行实例化
内存使用	在需要时才占用内存，节省资源	程序启动时就占用内存
线程安全	需要额外处理（如双重检查锁）来保证线程安全	天生线程安全，类加载时即创建
适用场景	当单例类可能不被使用，节省内存资源	当确保实例会被频繁使用，可以预先创建实例
实现复杂性	相对较复杂，涉及到线程同步和双重检查锁	相对简单，静态成员变量初始化即可
如何选择
● 懒汉模式适用于可能不需要单例实例的场景，这样可以节省系统资源，尤其是在创建单例对象开销较大的情况下使用。
● 饿汉模式适用于在程序生命周期中始终需要一个单例实例的场景。由于实例在类加载时即创建，饿汉模式实现简单且不需要考虑线程安全问题。
在 C++11 之后，局部静态变量的线程安全性已经得到了保证，因此我们可以使用一种简化的懒汉模式，即局部静态变量方式。该方法既能延迟实
● 懒汉模式和饿汉模式的主要区别在于实例的创建时机。
● 懒汉模式延迟创建，节省内存，但需要线程同步来确保安全。
● 饿汉模式提前创建，保证线程安全，但会在程序启动时消耗资源。
● 根据使用场景选择合适的单例模式可以有效地优化程序的性能和资源使用。对于现代 C++，使用局部静态变量实现的单例模式是一种推荐的方式，因其既简单又高效。
虚基类
虚基类主要就是虚继承，主要解决菱形继承等多重继承问题的空间大，重复内容占用空间问题。
所以有vbptr指向虚继承的内容，并且相同内容只有一份！

1.析构函数调用虚函数会发生什么？
在C++中，析构函数调用虚函数会发生以下情况：
● 只会调用当前析构函数所在类的虚函数版本，而不会调用派生类的重写版本。即使对象的实际类型是派生类，虚函数的动态绑定也会失效，行为类似于普通函数的调用
2.调用两次析构函数会发生什么？
如果一个类的对象被调用了两次析构函数，会发生未定义行为（Undefined Behavior, UB），具体表现取决于编译器和运行时环境，但通常会导致程序崩溃或数据损坏。
析构函数的作用是销毁对象，释放资源（如动态分配的内存、关闭文件句柄、释放网络连接等）。如果一个对象的析构函数被调用两次，可能会导致以下问题：
1. 重复释放资源：例如，动态分配的内存被释放两次，导致内存损坏。
2. 重复销毁对象状态：对象的成员变量可能被多次销毁，导致状态不一致。
3. 程序崩溃：访问已经被销毁的对象状态，可能导致程序崩溃。
3.虚函数表存在哪个段？虚函数呢？
虚函数表（vtable）通常存储在程序的 只读数据段（.rodata段） 中。
为什么存储在只读数据段
1. 只读性：
  ○ 虚函数表的内容在程序启动时由编译器初始化，并且在运行时不会被修改。因此，将其存储在只读数据段中可以防止意外修改，提高程序的安全性和稳定性。
2. 共享性：
  ○ 虚函数表是类的静态数据，所有对象共享同一个虚函数表。只读数据段是全局共享的，适合存储这类静态数据。
3. 内存布局优化：
  ○ 将虚函数表放在只读数据段中，
TCP的keepalive和HTTP的keep-alive的区别？
1. TCP Keepalive： 这是 TCP 协议（传输层） 提供的一种机制，由操作系统内核管理，主要目的是检测一个空闲的 TCP 连接是否仍然有效。当连接长时间没有数据传输时，操作系统内核会发送探测报文给对方，以确认对方主机是否仍在运行、网络是否通畅，从而避免连接在对方崩溃或网络中断时无限期地保持“僵尸”状态。
2. HTTP Keep-Alive： 这是 HTTP 协议（应用层） 的一种特性，由客户端和服务器应用程序管理，也称为 HTTP 持久连接 (Persistent Connection)。它的目的是让一个 TCP 连接在一次 HTTP 请求/响应完成后不立即关闭，后续的 HTTP 请求可以复用这个已经建立的 TCP 连接，从而减少重复建立 TCP 连接（和可能的 TLS/SSL 握手）带来的延迟和开销，提高效率。
特性	TCP Keepalive	HTTP Keep-Alive
(持久连接)
协议层	传输层 (TCP)	应用层 (HTTP)
主要目的	检测空闲连接的存活性	复用
 TCP 连接以提高 HTTP 传输效率
触发条件	TCP 连接长时间空闲	HTTP 事务（请求/响应）完成
管理方	操作系统内核	HTTP 客户端和服务器应用程序
控制方式	OS 内核参数, Socket 选项	HTTP Header (Connection), Web服务器配置
传输内容	通常是空的探测报文 (ACK)	实际的 HTTP 请求和响应数据
虚表跟虚函数指针?
虚函数表
每一个类最多只有一个虚函数表，在类中如果有虚函数，在编译的时候系统会生成一个虚函数表，存放在只读数据段.rodata。
虚函数指针
每一个对象都会有一个虚函数指针，虚函数指针的地址不一样，但是均指向同一个虚函数表。这里要注意，
虚函数指针的创建时间
虚函数指针是在调用构造函数的时候创建完成的。
继承的时候的创建过程
通过分析构造函数的调用顺序来进行理解。
先调用基类的构造函数，创建虚函数指针指向基类的虚函数表
调用派生类的构造函数，虚函数指针指向派生类自身的虚函数表
子类 Child 新增的虚函数 bar() 的存储位置取决于编译器的具体实现，但遵循主流编译器（如 GCC/Clang/MSVC）的通用规则，它的处理方式如下：
1. 多继承下的虚函数表（vtable）布局
● Child 类会继承 两个 vfptr（分别来自 Parent1 和 Parent2）。
● 新增的虚函数 bar() 会被追加到第一个父类（Parent1）的虚函数表中，而 Parent2 的虚函数表保持不变。
虚函数表的具体结构：
● Parent1 的虚函数表（由 Child 继承并扩展）：
 [0] Parent1::foo1()  // 继承自 Parent1
 [1] Child::bar()     // 子类新增的虚函数
● Parent2 的虚函数表（直接继承，未扩展）：
 [0] Parent2::foo2()  // 继承自 Parent2

2. 为什么选择追加到第一个父类的虚函数表？
● 效率优化：
子类只需通过第一个父类（Parent1）的 vfptr 即可访问所有子类新增的虚函数，无需额外查找。
● 兼容性：
保持 Parent2 的虚函数表不变，确保通过 Parent2* 指针调用 foo2() 时无需调整偏移量

虚析构函数
将析构函数声明为虚函数（virtual ~ClassName()）是为了解决通过基类指针删除派生类对象时的资源泄漏问题。这是多态场景下的关键设计，以下是详细分析：
1. 核心问题：非虚析构函数导致的内存泄漏
1. 动态绑定的本质
动态绑定（Dynamic Binding）是指通过基类指针或引用调用虚函数时，实际执行的是对象实际类型的函数版本。析构函数作为虚函数时，同样遵循这一规则：
2. 析构函数动态绑定的特殊性
与其他虚函数的区别
特性	普通虚函数	虚析构函数
调用时机	显式调用（如 obj->foo()
）	隐式调用（通过 delete
 触发）
调用顺序	仅调用最终覆盖版本	先调用派生类，再自动调用基类
编译器扩展行为	无特殊处理	编译器自动插入基类析构调用
1. 析构函数的“链式调用”：
虚析构函数的动态绑定不仅会调用派生类的析构函数，编译器还会在派生类析构函数执行完毕后，自动插入对基类析构函数的调用（递归直到最顶层基类）。

PB压缩存库和普通字段类型的区别？
对比维度	PB 压缩数据	传统字段类型（STRING/INT）
存储形式	二进制大对象（BLOB/Binary）	直接映射到数据库的字段类型（如 VARCHAR
、INT
）。
数据解析	需反序列化（ParseFromString()
）才能读取原始结构化数据	数据库可直接解析（如 SELECT name FROM table
 直接返回字符串）。
存储效率	更高压缩率（尤其对结构化数据），尤其是重复字段或嵌套结构	取决于数据类型：INT
 高效，STRING
 可能因文本冗余占用更多空间。
查询能力	无法直接查询内部字段（需全量读取后反序列化）	支持索引和高效查询（如 WHERE age > 30
）。
灵活性	Schema 灵活（可动态增减字段，兼容性强）	字段需预先定义，修改 schema 可能需迁移数据。
适用场景	复杂结构化数据（如配置、日志、嵌套对象）	简单数据类型（如用户姓名、年龄）。
性能开销	序列化/反序列化需要 CPU 计算，但 I/O 更高效（二进制体积小）	简单类型读写快，但
热更新原理？

知识拓展：Lua的“require（模块名）”方法会加载一个Lua模 块，并缓存到package.loaded[modelname]中。如果对同一个模块重复调 用require方法，那么程序将会从缓存中取值，而不再加载Lua文件。因 此，热更新前需要先清空缓存，再调用require方法。
集群聊天服务器项目
1.介绍一下你的项目
epoll+边缘触发+非阻塞
我这个项目是一个集群聊天服务器的项目，它分为了4个模块。
首先第一个它是网络模块儿啊，采用了开源的Muduo 网络库，核心在于单线程事件循环 （Reactor模式）通过它的 EventLoop、TcpServer/TcpClient 和回调机制来实现网络IO。这样网络层只负责接收连接、读取数据和发送数据，而所有具体业务逻辑则通过回调函数传递给上层处理，实现了网络代码和业务代码的彻底解耦，开发者可以专注于业务逻辑的实现。
服务层这块儿呢我用了一些c++11的技术，比如说像map啊，像这个绑定器bind啊，网络层收到数据后，调用业务层的消息回调函数，将json格式的数据反序列化后提取对应的消息ID，查找绑定的处理函数，进行业务处理。只需要添加新的消息ID和对应的处理函数，就可以支持新的业务功能，而不必修改底层的网络 IO 代码。
数据存储层我用了这个MySQL存储，用户账号信息，离线消息，好友列表和群组关系。
单个服务器的并发处理能力是有限的，为了提升整个项目的一个并发处理能力，项目部署了多台网络服务器，并配置nginx的TCP负载均衡，客户端发起的连接请求由 Nginx 均匀分发到各个服务器节点，实现负载均衡，每个服务器节点依然采用Muduo 处理 TCP 通信，保证了每台服务器的高并发能力。实现聊天服务器的集群功能，提高后端服务的并发能力。
多台服务器中，不同服务器上的用户可能需要互相通信，在这里引入了redis作为一个轻量级的MQ消息队列，利用它的发布订阅在这里边儿实现了一个跨服务器的一个通信。当某台服务器处理某个用户的消息后，根据业务逻辑判断是否需要将该消息广播到其他服务器节点。此时，该服务器将消息发布到Redis 中的一个频道。其他服务器节点订阅相应频道，实时接收到消息，然后再根据需要将消息转发给相应的在线用户。

2.Valgrind进行内存泄漏检查，
3.以及Wairshark网络抓包操作！
2.分布式集群的介绍
 基于 C/S 架构开发的分布式集群聊天服务器，采用模块化设计，分为网络、服务、数据存储及分布式协同四大模块：
网络层基于开源 Muduo 网络库，通过单线程事件循环（Reactor 模式）与 EventLoop、TcpServer/TcpClient 组件实现高效网络 I/O，利用回调机制将连接管理、数据收发等底层操作与上层业务逻辑解耦；
服务层运用 是基于Muduo网络库实现了一个API网关的服务器，C++11 特性（如 std::map、std::bind）构建消息路由框架，统一处理客户端连接以及rpc调用，接收客户端的数据后，通过 protobuf 反序列化提取消息 ID，动态路由至后端对应的RPC服务，比如注册注销登入等业务；
分布式协同模块，通过引入 MpRPC 框架替代原有本地调用，将注册登录、好友管理、群组服务、聊天服务拆分为独立分布式服务部署，服务间通过高效远程过程调用（RPC）实现跨节点协作，同时结合 ZooKeeper 完成服务注册与动态发现，并且zookeeper有心跳和wtcher机制，能实时感知节点服务器状态，并更新服务列表，提高了能力；
为支撑大规模并发连接，采用 Nginx 作为 TCP 负载均衡器，将客户端请求均匀分发至多台网络服务器，每台服务器仍基于 Muduo 实现高并发通信；
针对跨服务器消息同步需求，利用 Redis 发布-订阅机制构建轻量级消息总线，当用户消息需跨节点广播时，源服务器将消息发布至指定频道，其他订阅节点实时接收并转发至目标用户。
数据存储层依托 MySQL 集群持久化用户账号、离线消息、好友关系及群组信息，结合连接池优化高频访问性能；
最终实现支持单聊、群聊的高可用、可扩展分布式集群聊天系统。  
时间戳跟序列号来实现排序可靠传输的区别？
1.时间戳无法得知前面到底有多少条消息，可以定义一个1s的周期显示，来对这一秒的数据进行排序，但不能全局有序的，只能对udp改进一点点。
而用序列号则可以全局保证数据有序的。
TTL最大为64
序列号还有其他功能：消息撤回等
发送的消息有考虑数据安全吗？
是可以实现的，也是需要实现的额！
对称加密：
非对称加密：
历史消息存储？
本地消息存储：
可以按文件按天来存储（好友的QQ号作为文件夹）存储，比如200M存满则存下一个文件。可以存到SQLite嵌入式数据库。
云消息存储：MYSQL，超过时间过久的（不经常访问的）可以存入dump-》fileserver文件服务器上
要是网络拥塞，server怎么感知客户端状态？
业务层：心跳机制：
TCP协议-传输层：Keepalive的保活功能
一般长连接的业务不依赖TCP的保活功能，而是需要自己实现，要是应用层死锁等，不影响内核的TCP连接。
redis要是只有发布，但是没有订阅怎么办？
数据会丢失？那怎么实现离线消息缓存？
为什么要用redis，而不是让各个服务器直接进行通信？
epoll+边缘触发非阻塞模式
1️⃣ 你们这个聊天系统的整体架构是怎么样的？
我们实现了一个基于 C/S 架构的集群聊天系统。
整体结构如下：
· 客户端：用户通过客户端（PC 端 / 移动端）与服务器建立 TCP 长连接，进行消息的收发。
· 接入层（Nginx）：做四层或七层负载均衡，分发用户请求到后端不同业务服务器，实现压力分担和高可用。
· 业务层（Chat Server）： 
o 每个 ChatServer 进程基于 muduo 框架实现，负责维护客户端 TCP 长连接，转发消息。
o ChatServer 内部通过 多 Reactor + 线程池 支持高并发连接处理。
o 跨服务器之间通过 Redis 的 发布订阅 实现消息同步。
· 存储层（MySQL + Redis）： 
o MySQL 持久化存储用户信息、好友列表、聊天记录等。
o Redis 存储在线用户状态，以及实现跨服务器消息同步。

2️⃣ 为什么选择 muduo 网络库？多 Reactor 模型怎么理解？
选择 muduo 是因为：
· 它是基于 Reactor 模式和非阻塞 IO 的高性能 C++ 网络库。
· 支持One Loop Per Thread 模式，充分利用多核 CPU 并行处理。
· 提供了事件循环 + 线程池 机制，简化了多线程并发处理编程。
多 Reactor 模型：
· 主线程（Acceptor）负责监听 socket 连接请求，分发给子线程处理。
· 每个子线程都有一个独立的 EventLoop（Reactor），负责自己线程内所有 IO 事件，互不干扰。
· 实现了连接分离 和事件并发处理，提升了系统吞吐能力。

3️⃣ 高并发处理时，线程池是怎么调度的？如何避免阻塞？
· muduo 自带线程池，线程池负责调度不同的 EventLoop 来管理各自的客户端连接。
· 每个线程通过事件循环模型非阻塞处理 socket 读写事件。
· 耗时任务（比如数据库操作）通常使用异步执行，或者放入另一个工作线程池中处理，避免阻塞 IO 线程。
· 避免竞态条件主要通过：
o 线程内无锁（一个 EventLoop 只在单线程内操作）。
o 跨线程通信通过任务投递（runInLoop/post） 机制，将任务加入目标线程的事件队列。

4️⃣ Redis 发布订阅怎么保证消息可靠性？会不会丢消息？
Redis pub/sub 不具备消息持久化机制：
· 订阅者离线时，发布的消息会丢失。
为了解决：
· 我们通过 Redis 消息队列（List 或 Stream）来补充 pub/sub，做到消息持久化和可靠投递。
· 可以设计 ack 机制（客户端确认收到后再删除消息）。
· 如果切换 Kafka，可以获得更强的一致性、消息重放和分布式消费支持，但部署复杂度和延迟增加。

5️⃣ Nginx 负载均衡怎么配置的？如何实现会话保持？
· Nginx 在四层使用 TCP 负载均衡，采用轮询（Round Robin） 分发连接请求。
· 为实现用户会话保持（session persistence）： 
o 采用IP Hash 策略，让同一个用户总是连接到同一台服务器，减少跨服务器通信。
o 如果用的是 WebSocket 或 TCP 长连接，通常依靠连接维持会话状态，不需要 sticky session。
· 用户断线重连时，通过 Redis 查询用户在线状态和未读消息，支持消息同步和离线补发。

6️⃣ 数据存储优化方面，你们数据库存了什么？连接池怎么实现的？
存储内容：
· MySQL 存储用户信息、好友关系、群聊、聊天记录等。
· Redis 存储用户在线状态和临时会话信息。
数据库优化：
· 实现了连接池，减少频繁创建和销毁数据库连接的开销。
· 连接池原理：
o 初始化一定数量的连接，空闲时归还池中。
o 支持最大连接数限制，避免资源耗尽。
· 聊天记录多时优化：
o 聊天记录按用户分表或分库。
o 查询时分页加载，结合缓存减少数据库压力。

7️⃣ 为什么用 JSON 协议？和 protobuf 比如何选择？
· 选择 JSON 是因为： 
o 格式清晰，方便调试和开发，易于扩展。
o 客户端跨平台支持好，特别是 Web 和移动端。
· Protobuf 比 JSON 更轻量，二进制格式更小、解析更快，但不便于调试。
· 如果传输大文件或对性能极端敏感的系统，建议用 Protobuf + 分片传输机制。
· 大文件传输（如图片、视频）：
o 文件用 HTTP 或 FTP 上传，返回文件地址，通过 JSON 或 Protobuf 通知文件 URL。

8️⃣ 如何保证高可用？Redis 和 MySQL 挂了怎么办？
高可用设计：
· Redis：
o 使用主从复制 + 哨兵（Sentinel）模式，自动故障转移。
o 也可以部署 Redis Cluster 实现高可用和分布式存储。
· MySQL：
o 主从同步 + 读写分离，主备切换用 MHA 或 GTID。
· 服务无状态，支持水平扩展，单台服务器挂掉用户自动切到其他服务。
· 定期备份 MySQL 和 Redis 数据，恢复机制完善。

9️⃣ 并发和性能测试怎么做？你们系统支撑多少连接？
压测工具：
· 使用wrk 或Apache Benchmark 压测接口。
· 自研脚本模拟多用户长连接发送消息。
性能表现：
· 单台 ChatServer 支持 上万 TCP 长连接，主要瓶颈在网络 IO 和 CPU。
· Redis 跨服务器通信带来的延迟较小，MySQL 高并发写时瓶颈更明显。
优化措施：
· 增加缓存、异步写、分布式部署。
· ChatServer 采用多线程 + Reactor 模型充分利用多核 CPU。
如何确保redis和MySQL数据一致性？
https://blog.csdn.net/zhizhengguan/article/details/122972503
 分布式事务一致性？新功能如何扩展？
一致性问题：
· Redis pub/sub 和 MySQL 写操作之间有可能出现不一致。
· 常用解决方案：
o 利用消息队列（RocketMQ、Kafka）支持事务消息，确保消息和数据库一致提交。
o 采用 TCC（Try-Confirm-Cancel）模式确保分布式事务一致性。
新功能扩展：
· 已读回执：
o 客户端发送 ack，服务端更新数据库，广播回执状态。
· 消息撤回：
o 消息加撤回标志，服务端通知客户端删除消息。
· @提醒： 
o 消息存带 mention 用户 ID，推送提醒，客户端特殊展示。
1️⃣ 离线消息的存储和推送是如何实现的？
离线消息保证“不断线、不丢失”，通常在 IM 系统中有两部分：
· 消息存储
· 消息推送
1. 存储层
o 离线消息写入 MySQL（主存）+ Redis（缓存）
o 在线用户消息走长连接直接推送
o 离线用户收到消息时：
§ 将消息写入离线消息表（MySQL 或 Redis List）
§ 记录未读消息状态
2. 推送流程
o 用户上线后：
§ 通过 Redis 在线状态判断是否在线
§ 不在线就查询离线消息表
§ 批量推送离线消息给客户端
§ 用户接收到消息后客户端发 ack
§ ack 确认后删除离线消息
3. 持久性保障
o 离线消息定时清理（7天或30天自动过期）
o 使用 Redis 缓存加快读取速度，MySQL 作为长期存储和备份
4. 重试机制
o 如果客户端未确认收到（ack timeout），服务端支持重试投递
o 可以基于消息 ID 实现消息幂等性

2️⃣ Redis 发布订阅模型的性能瓶颈在哪？如何优化？
Redis pub/sub 是简单的消息分发系统，适合轻量通信，但有缺陷。
Redis pub/sub 模型的瓶颈
1. 单线程限制 
o Redis 单线程处理命令，pub/sub 高并发下性能瓶颈明显
2. 无持久化 
o 发布消息不存储，客户端如果断开连接就丢消息
3. 慢客户端问题 
o 某些订阅者处理慢，阻塞推送队列，影响整体性能
优化方案
1. 分 Topic 分 Redis 实例 
o 群聊/私聊按 hash 分不同 Redis 实例分担压力
2. 引入消息队列 
o Kafka、RabbitMQ 替代 Redis pub/sub，解决可靠性和扩展性问题
3. 慢客户端处理 
o 限制客户端读取超时，剔除异常慢客户端
4. Redis Cluster 
o 水平扩展 Redis，按 Key 分片存储消息（不支持 pub/sub 但能结合 List 实现）
3️⃣ 多客户端同时登录同一个账号，怎么处理消息同步和一致性？
IM 系统中多端登录（PC+手机+平板）是常见需求，重点是状态同步、消息一致性、并发控制。
多端登录实现
1. 连接管理
o 用户登录时生成 session ID，记录多个设备连接（fd映射）
o 服务端维护一组连接，每条连接绑定设备标识
2. 消息推送
o 消息分发到所有终端（广播）
o 每个终端单独维护已读状态（未读消息表）
3. 已读状态同步
o 一个终端已读，服务端同步状态并推送通知到其他终端
o 保证其他终端的“已读/未读”一致
并发与一致性控制
1. 消息顺序
o 服务端维护全局递增的 message_id
o 客户端按 message_id 排序重组
2. 幂等性设计
o 每条消息带 message_id
o 收到相同 ID 的消息直接丢弃，避免重复推送
3. 异常处理
o 客户端断连重连时，查询消息 gap，进行消息补偿
4️⃣ 群聊功能是如何实现的？大群（上万人）时怎么优化？
群聊比单聊复杂，尤其是超大群（万人群），要解决分发效率、推送风暴、消息一致性等问题。
基础实现
1. 小群聊（几百人） 
o 群成员全在线时：
§ 服务端通过 Redis pub/sub 跨节点广播消息
o 群成员离线：
§ 写入离线消息表
§ 用户上线后主动拉取离线消息

大群（上万人）优化
1. 分批推送（推拉结合）
o 核心用户（VIP）优先推送
o 其他用户采用客户端轮询或增量拉取（减少瞬时压力）
2. 消息广播优化
o 使用 Kafka 进行消息分发，解耦发送端和消费端
o 服务端通过消费者分组实现并行推送
3. 消息分发缓存
o 消息先缓存 Redis，用户在线时从缓存拉取
o 异步持久化 MySQL
4. 一致性和顺序保证
o 单分区顺序投递
o 客户端按消息ID合并排序

5️⃣ 如何防止恶意攻击？（刷接口、刷消息、连接攻击）
IM 系统容易成为攻击目标，安全防护需做到防护+限流+监控+隔离。
1. 登录安全
o 登录接口加频率限制（滑动窗口/令牌桶）
o 异常登录（IP、设备）触发验证码/风控验证
o 异常账号封禁或限制登录时间
2. 消息发送限流
o 每个用户/设备的消息发送限流（qps限制+消息内容合法性校验）
o Redis 计数器记录用户发送频率，超限直接封禁
3. 长连接保护
o TCP 连接数上限控制
o 僵尸连接定期检测（心跳机制）及时断开
o Nginx 四层负载均衡配置超时、最大连接数
o 客户端超时不活跃踢下线
4. 防刷/风控
o IP 黑白名单
o 防止恶意刷接口：Nginx+WAF+限流中间件
o 安全传输：SSL/TLS加密、敏感数据传输加密
5. 监控报警
o 接入 Prometheus + Grafana 监控系统
o 实时告警，异常流量、失败率激增自动报警
总结思路
场景	核心思路
离线消息	存Redis+MySQL，推送ack确认，消息过期清理
Redis pub/sub优化	单线程瓶颈，分实例、Kafka替代、慢客户端处理
多端同步	连接绑定、状态同步、幂等消息ID、顺序控制
大群优化	推拉结合、分批推送、消息队列+缓存、顺序一致性
防刷防攻击	登录频控、限流限连、WAF+黑名单、SSL加密、监控

如果你想，我们可以做一个实战演练，比如「限流算法」「Redis消息队列」等场景深入到代码层面，或者一起画架构图更清晰！
1️⃣ 你的 chatserver 如何实现高可用？宕机时会发生什么？
· Nginx 负载均衡：所有请求都通过 Nginx 进行分发，某个 ChatServer 崩溃后，Nginx 自动将流量转移到健康的服务器。
· Redis 在线状态管理：用户在线状态存储在 Redis，如果某个 ChatServer 挂了，新请求会重新路由到其他节点，并从 Redis 获取在线信息。
· 数据库主从架构：MySQL 采用主从复制 + 读写分离，防止单点故障，MySQL 挂掉时可以切换到从库。
· 消息持久化：离线消息存储在 Redis + MySQL，确保即使服务器宕机，用户仍然可以收到未读消息。
2️⃣ 你的 TCP 连接如何保持？心跳机制是如何设计的？
· 由于 IM 需要长连接，TCP 连接需要定期维护，防止 NAT 超时导致连接断开。
· 心跳包设计： 
o 客户端每 30 秒发送一次心跳（PING）。
o 服务器收到后回复 PONG，并更新该连接的活动时间。
o 如果 3 次心跳未收到 PONG，则断开连接，认为客户端掉线。
· 优化： 
o 自适应心跳：如果客户端网络不稳定，可以调整心跳间隔（比如 WiFi/4G 网络心跳不同）。
o WebSocket 连接兼容：对于 Web 端，采用 WebSocket 保持长连接。
3️⃣ 你们的系统支持多少并发连接？主要瓶颈在哪？
· 单台服务器支持几万 TCP 长连接，瓶颈主要是：
o 文件描述符限制（默认 1024，需要调高 ulimit -n）
o 内存占用（每个连接约 4KB，10 万连接约 400MB）
o CPU 开销（Reactor 线程调度、网络 IO）
o Redis/数据库写入压力
· 优化方式： 
o epoll + 多 Reactor 处理高并发事件。
o TCP 连接池：减少连接建立的开销。
o Redis 读缓存：减少数据库压力。
o 异步 I/O（AIO）+ 零拷贝（mmap/sendfile）。
4️⃣ 消息存储策略是怎样的？如何防止数据库成为瓶颈？
· 存储策略： 
o 消息写 Redis（短期缓存）+ MySQL（长期存储）。
o 在线用户：消息优先写入 Redis，推送给在线用户后删除。
o 离线用户：存 MySQL，用户上线后再读取。
· 数据库优化： 
o 分表存储：按用户 ID 或时间范围进行水平拆分，防止单表数据过大。
o 索引优化：使用 B+Tree 索引加速查询，避免全表扫描。
o MySQL 连接池：减少频繁创建连接的开销。
5️⃣ 你的系统是如何保证消息顺序的？
· 单个用户的消息顺序：
o 采用自增 message_id，确保同一会话内消息按 ID 递增。
o 服务器按 ID 排序后推送，客户端按 ID 重排，确保顺序一致。
· 群聊消息顺序：
o 通过Kafka 分区 解决大群消息顺序问题（每个群聊一个 partition）。
o Redis Stream 结构 作为消息队列，按 XADD 记录顺序。
· 网络传输乱序解决方案：
o 采用TCP 传输（可靠、有序），避免 UDP 乱序问题。
o 客户端收到消息后，如果 message_id 不是连续的，就等待缺失的消息重传。
6️⃣ Redis 断电丢数据怎么办？如何提升 Redis 可靠性？
o Redis 默认 仅内存存储，断电后数据丢失。
o AOF 方式虽然可恢复数据，但性能损耗较大。
· 解决方案： 
o 主从复制（Redis Replication）：如果主节点宕机，自动切换到从节点。
o 持久化：
§ RDB 快照：定期持久化 Redis 数据（但可能丢失部分数据）。
§ AOF 日志：追加写日志，支持数据恢复。
o Redis Sentinel：自动故障转移，确保高可用。
7️⃣ 如何处理 IM 系统中的大文件（图片、语音、视频）传输？
· 直接在 chatserver 传输文件不现实（占用带宽、影响性能）。
· 解决方案： 
1. 客户端上传文件到对象存储（OSS、MinIO）。
2. 获取文件 URL 后，仅传输 URL 而非文件。
3. 服务器端将 URL 存入数据库或 Redis，客户端请求时拉取 URL。
· 优化措施： 
o CDN 加速：让用户从就近的服务器下载文件。
o 断点续传：大文件支持断点续传，减少重复上传带来的流量浪费。
8️⃣ 你们系统如何进行压力测试？
· 工具： 
o wrk（HTTP 并发测试）
o ab（Apache Benchmark）
o JMeter（模拟多用户并发）
· 测试内容： 
0. 并发连接数（单服务器支持多少 TCP 连接）。
1. QPS（每秒请求数），统计服务器吞吐量。
2. 数据库负载（SQL 查询优化）。
3. Redis 读写性能（缓存命中率）。
· 结果优化： 
o 提高 epoll 处理能力（优化 max_conn）。
o 降低数据库查询次数（缓存+连接池）。
o 使用分布式架构（多服务器拆分负载）。
9️⃣ 如何防止消息被篡改或伪造？
· 数据加密：
o 客户端RSA 公钥加密，服务器用私钥解密，防止中间人攻击。
o 消息传输使用AES 加密，防止截取明文消息。
· 消息签名：
o 服务器对消息生成 HMAC-SHA256 签名，客户端校验签名，防止篡改。
· 反篡改存储：
o 重要聊天记录采用区块链存储（不可篡改）。
如果你要重构这个 chatserver，有哪些改进点？
· 协议优化：从 JSON 切换到 Protobuf，减少数据传输量。
· 持久化优化：使用 TiDB 取代 MySQL，支持分布式扩展。
· 消息系统优化：Kafka 替代 Redis pub/sub，保证消息可靠性和顺序。
· 容器化部署：迁移到 K8s + Istio，自动扩容，提高高可用性。
数据库主从架构 + PB压缩后存储消息+redis缓存


分布式集群chatserver项目
介绍一下你的分布式集群项目？
 基于 C/S 架构开发的分布式集群聊天服务器，采用模块化设计，分为网络、API网关服务、数据存储及分布式协同四大模块：
网络层基于开源 Muduo 网络库，通过单线程事件循环（Reactor 模式）与 EventLoop、TcpServer/TcpClient 组件实现高效网络 I/O，利用回调机制将连接管理、数据收发等底层操作与上层业务逻辑解耦；
服务层运用 是基于Muduo网络库实现了一个API网关的服务器，C++11 特性（如 std::map、std::bind）构建消息路由框架，统一处理客户端连接以及rpc调用，接收客户端的数据后，通过 protobuf 反序列化提取消息 ID，动态路由至后端对应的RPC服务，比如注册注销登入等业务；
分布式协同模块，通过引入 MpRPC 框架替代原有本地调用，将注册登录、好友管理、群组服务、聊天服务拆分为独立分布式服务部署，服务间通过高效远程过程调用（RPC）实现跨节点协作，同时结合 ZooKeeper 完成服务注册与动态发现，并且zookeeper有心跳和wtcher机制，能实时感知节点服务器状态，并更新服务列表，提高了能力；
为支撑大规模并发连接，采用 Nginx 作为 TCP 负载均衡器，将客户端请求均匀分发至多台网络服务器，每台服务器仍基于 Muduo 实现高并发通信；
针对跨服务器消息同步需求，利用 Redis 发布-订阅机制构建轻量级消息总线，当用户消息需跨节点广播时，源服务器将消息发布至指定频道，其他订阅节点实时接收并转发至目标用户。
数据存储层依托 MySQL 持久化用户账号、离线消息、好友关系及群组信息，结合连接池优化高频访问性能；
最终实现支持单聊、群聊的高可用、可扩展分布式集群聊天系统。  
介绍一下你的重构的mpRPC框架
1.首先这个mpRPC框架，是基于Muduo网络库和Protobuf来实现的，一共包含了三个模块，1是服务的提供方，2是Zookeeper服务配置中心，负责服务的注册和发现，然后就是调用方。
利用的Protobuf的message ，定义了相关的消息类型，使用service （关键字）定义描述rpc方法的类型，Protoc编译后会生成的UserServiceRpc类(服务提供方使用)和 UserServiceRpc_Stub类（服务调用方使用）都是抽象类，
先启动服务提供的节点，先与ZK创建一个会话，


为什么做RPC，分布式项目？rpc如何工作的？
自己在学习的时候，了解到分布式，就好奇，不同机器之间是如何通信
的，然后了解到了RPC，发现可以像本地调用函数一样方便，调用其他服务器的函数。感觉很神奇，就像自己实现一遍。

Rpc是一种通过网络从远程计算机请求服务的协议。它的核心思想是，客
户端通过代理调用服务端的方法，像调用本地方法一样，透明的隐藏了网
络通信的细节。RPC的工作过程通常包括：
1.客户端发起请求，调用服务端的代理，序列化请求数据
2.通过网络传输到服务端。  
3.服务端通过客户端的代理，进行反序列化数据。
4.处理请求方法生成响应，在通过客户端代理序列化返回客户端。
项目难点是什么？项目遇到什么难点？
1.沾包/拆包问题：通过自定义通信协议(消息头+消息体)解决，确保数据
完整性。
2.Zookeeper的学习与使用：
·学习Wathcher机制，监听节点变化，实现动态服务注册与发现。
·将Zookeeper作为注册中序，提供高可用性和实时更新能力
3.Protobuf的序列化和反序列化：熟悉Protobuf的定义文件、编译工具和
API使用，确保高效传输数据。
4.高并发网络处理：通过Muduo网络库提供事件循环与线程池，实现高性
能并发。
5.在思考zookeeper要是挂了那不是全崩了？（后来学习到zookeeper可以直接配置为集群模式）
6.如何实现会话保持，可以采用ip哈希让他一直连在一个服务器上
7.不知道怎么找到对应调用的方法，后来学习到protobuf里注册方法可以取出来进行建立表，
8.合理划分服务边界，避免服务间过度调用

一致性问题：如何在多个节点之间保持数据的一致性，是分布式系统的核心挑战之一。CAP理论描述了在分布式系统中，如何在一致性、可用性和分区容忍性之间权衡。
网络延迟和故障：分布式系统依赖网络进行通信，因此网络延迟、数据包丢失或节点间的网络分区都会对系统的性能和稳定性产生影响。
数据复制和同步：在多个节点上分布存储数据时，需要考虑如何同步和复制数据，以确保所有节点上数据的一致性和完整性。
负载均衡：如何将任务和数据均匀分配到各个节点，避免某些节点过载也是一个重要的设计问题。


TCP粘包和拆包问题你具体怎么解决的？
TCP是流式协议，数据是按字节流传输的，没有明确的消息边界可能会导
致：
应用层会发送数据过于频繁或者来不及接收：多个小包被TCP缓冲区合
并，就会导致粘包。
Nagle算法：Nagle算法将小数据包合并后再发送，进一步导致粘包。
例如：发送方连续发送两条消息msg1="hello"和msg2="world"接
收方可能一次性接收到helloworld.
2.TCP拆包的成因：
由于TCP传输是分段发送，可能出现以下情况：
消息过大：一条消息的长度超过TCP缓冲区的大小，分多个包传输。
网络拥塞或延迟：导致分包后不同时间接收到数据。 代码随想录知识星球
解决：
通过自定义的协议和编码器/解码器，这一部分可以看看channel和
provider(OnMessage)中如何做的。
**先读固定 4 字节的 header_size**
根据 header_size 知道 rpc_header_str 的长度
**读取 rpc_header_str**
**解析 rpc_header_str 得到 args_size**
最后读取 args_str（即实际的函数参数数据）
性能测试？
#include <iostream>
#include <vector>
#include <thread>
#include <atomic>
#include <chrono>
#include "user.pb.h"         // 假定这是 protobuf 生成的头文件，包含 LoginRequest/LoginResponse
#include "krpc_application.h" // 假定是你 RPC 框架的初始化类
#include "krpc_channel.h"     // 假定是你封装的 Channel 类
#include "kuser_rpc.pb.h"     // 假定包含 UserServiceRpc_Stub 定义

using namespace std;
using namespace std::chrono;

// 全局统计变量
atomic<int> success_count{0};
atomic<int> fail_count{0};

// 每个线程执行的函数：发送若干次 Login 请求
void send_request(int request_count) {
    // 创建 RPC Channel 和 Stub
    Kuser::UserServiceRpc_Stub stub(new KrpcChannel(false));

    for (int i = 0; i < request_count; ++i) {
        // 构造请求：固定用户名和密码，可根据需要修改
        Kuser::LoginRequest request;
        request.set_name("zhangsan");
        request.set_pwd("123456");

        // 构造响应和控制器
        Kuser::LoginResponse response;
        KrpcController controller;

        // 调用远程 Login 方法
        stub.Login(&controller, &request, &response, nullptr);

        if (controller.Failed()) {
            // RPC 调用失败（网络/连接等问题）
            cerr << "RPC调用失败: " << controller.ErrorText() << endl;
            fail_count++;
        } else {
            // RPC 调用成功，再判断业务逻辑是否成功
            if (response.result().errcode() == 0) {
                success_count++;
            } else {
                // 业务逻辑失败（比如用户名或密码错误）
                cerr << "业务失败，错误码: " << response.result().errcode()
                    << ", 错误信息: " << response.result().errmsg() << endl;
                fail_count++;
            }
        }
    }
}

int main(int argc, char* argv[]) {
// 初始化 RPC 框架（可能是 gRPC 或自研框架的初始化）
KrpcApplication::Init(argc, argv);

// 设置日志标识（可选）
cout << "MyRPC 性能测试客户端启动..." << endl;

// 配置并发参数
const int thread_count = 1000;           // 并发线程数
const int requests_per_thread = 2;       // 每个线程发送请求数
// 注意：thread_count * requests_per_thread = 总请求数
// 如果你要测 2000 次，则可以是 1000 * 2 或 200 * 10 等

// 总请求数
const int total_requests = thread_count * requests_per_thread;

cout << "开始性能测试..." << endl;
cout << "线程数: " << thread_count 
    << ", 每个线程请求数: " << requests_per_thread 
    << ", 总请求数: " << total_requests << endl;

// 记录开始时间
auto start_time = high_resolution_clock::now();

// 创建并启动多个线程
vector<thread> threads;
for (int i = 0; i < thread_count; ++i) {
    threads.emplace_back(send_request, requests_per_thread);
}

// 等待所有线程执行完毕
for (auto& t : threads) {
    t.join();
}

// 记录结束时间
auto end_time = high_resolution_clock::now();
duration<double> elapsed_seconds = end_time - start_time;

// 输出统计结果
cout << "===== 性能测试结果 =====" << endl;
cout << "总请求数: " << total_requests << endl;
cout << "成功数: " << success_count << endl;
cout << "失败数: " << fail_count << endl;
cout << "耗时: " << elapsed_seconds.count() << " 秒" << endl;

if (elapsed_seconds.count() > 0) {
double qps = total_requests / elapsed_seconds.count();
cout << "QPS: " << qps << endl;
    } else {
        cout << "QPS: 计算异常（耗时为0）" << endl;
    }

    return 0;
}
I1219 11:51:02.398522 70647 Kclient.cc:75] Total requests: 2000
I1219 11:51:02.398566 70647 Kclient.cc:76] Success count: 2000
I1219 11:51:02.398576 70647 Kclient.cc:77] Fail count: 0
I1219 11:51:02.398615 70647 Kclient.cc:78] Elapsed time: 4.65042 seconds
I1219 11:51:02.398677 70647 Kclient.cc:79] QPS: 430.069
最终计算并打印：
总请求数
成功数 / 失败数
总耗时（秒）
QPS = 总请求数 / 耗时
分布式锁？mysql、redis、zookeeper分别怎么实现分布式锁？
一个高可用的分布式锁6点要求：不光是set nx ex
1.互斥性：加锁后其他进程无法获取
redis天然支持
2.可重入性：持有锁的进程可再次获取锁
request ID+重入计数：加锁时生成唯一的ID，并存入锁的val，再次加锁检查request id是否匹配，匹配则增加重入计数，解锁时先将重入计数减一，只有当计数归0时才真正释放锁。（唯一标识和锁计数：redisson）
3.死锁检测和避免：防止锁无法释放
加过期时间的TTL
4.释放的正确性：只有持有者能解锁
业务执行时间超过锁的过期时间，锁提前过期了，B进程也进入，A后面错误释放了B的锁，验证request id是不是自己的
5.续期机制：业务执行时间超过锁解锁时间
1.续期机制，检测线程是否还在，还在则续期
6.容错性：分布式环境下可靠性
主节点获取了锁，然后挂了，切到从节点，锁没了。 relock，保证5个拿下3个才算加锁成功。
mysql方式：利用数据库的唯一索引特性，比如创建一张锁表，获取锁时向其中插入一条数据，插入失败说明锁已经被其他线程获取。
Redis 实现分布式锁，是最复杂的，但是也是性能最高的。
加锁： SETNX key value 如果键不存在时，对键设值，返回1。如果键存在，不做任何操作,返回0。setnx全称是set if not exist。
完整 SET key value NX EX 600 后面为过期时间
解锁： DEL key，通过删除key释放锁，删除键之后，其他线程可以争夺锁。

为什么要使用zookeeper作为服务注册与发现中心？
Zookeeper是一个分布式协调工具，特别适用于分布式环境中的服务注
册与发现。它的优点是高可用性和一致性，通过Wathcer机制可以实时感
知服务的上线和下线。Zookeeper使用ZAB协议保证数据的一致性，确保
每个节点的数据更新都说线性化的。
不过，它的缺点是：对于写操作吞吐量不高，可能会成为拼接，尤其在大规模集群中。
zk是什么？用来干嘛的？他的wtcher机制怎么实现？
1.主要用来作为服务配置中心，组织节点管理对应的IP和端口号
2.watcher机制
解释Zookeeper的Watcher机制的工作原理。在您的项目中，如何利用Watcher机制实现服务的动态感知(如服务上线/下线)？请举例说明
Watcher事件的处理流程。
回答：
在回答之前你不妨思考一下Wathcer是什么？按中文的意思是一个观察者，欧克这个观察者做了什么？在本项目中使用zookeeper的目的是为了等到zookeeper客户端连接成到服务端来通知，初始化成功，然后client客户端就可以从zk的服务器上获取服务器对象和方法名。
但是具体是怎么做？
Wathcher主要是用来监视服务端，如果服务端发生了什么变化就要通知给客户端。不过你要想服务端通知客户端，客户端必须先往上面注册一个对某个节点的watch事件，服务端发给watch事件通知，但这个通知是不会返回节点数据，只是告知客户端你要我监听的节点发生变化了，具体的处理逻辑可以通过捕获告知的事件类型进行相应的操作，但是Wathcer事件只能用一次，也就是用完就没不过3.6.0版本后增加了永久递归wathcher，这个我没去了解。客户端向服务端注册了wathcer事件之外，还需要将这个wathcer回调事件保存在watcherManager上，这样服务端通知就会通知watcherManager执行保存在wathcerManager的回调函数。
https://www.cnblogs.com/xinyonghu/p/11031729.html
在一个 RPC 分布式服务架构中，如果 某个服务的方法（或服务本身）被删除/下线了（比如服务提供者节点宕机、服务被卸载等），那么：
1. ZooKeeper（或其他注册中心）会感知到这个变化（比如某个子节点被删除）
2. 然后触发一个 Watcher 监听回调函数
3. 在这个 Watcher 回调里，RPC 框架检测到某个服务或方法失效了
4. 然后通知网关服务器（比如 API Gateway、服务网关等）
5. 网关收到通知后，更新它内部维护的 “服务方法映射表”（或路由表、服务列表等）
6. 从而保证网关不会再把请求路由到已经失效的服务方法

如何处理分布式系统的故障？你项目采用了那些措施？
分布式系统中，高可用性比较重要，我采用了：
1.服务注册与发现：通过Zookeeper实现服务的动态注册与发现，当某
个服务岩机时，客户端可以自动从Zookeeper获取新的服务节点信息。
2.超时重试：客户端调用服务时设置超时，如果服务未响应，则会重试
一定次数。
3.负载均衡：使用负载均衡策略，保证请求均匀分配到多个服务实例上，避免单点故障。
4.故障熔断与降级：当某个服务连续失败时，启动熔断机制，停止调用该服务，避免影响整个系统。“
如何看待微服务架构和传统单体应用架构的区别？
主要是展示你对微服务架构和传统单体架构的理解。
答： 微服务架构通过将一个大型应用拆分为多个独立、自治的服务，能够提升系统的灵活性、可扩展性和可维护性。微服务算是分布式应用的一个重要基础，相较于传统单体架构，微服务具有以下优势：
1.独立部署与扩展：每个服务都可以独立部署，单个服务出现故障，并不
会影响整个系统。       
2.高可用性：服务之间的低耦合涉及，使服务出现故障时可以快速的离。
3.技术栈的灵活：不同服务可以使用不同技术栈，适应各自业务的需求。
但微服务架构也带来了一些挑战，如服务间通信、分布式事务处理和数据
一致性等问题。
如何实现SSL加密传输消息？
在C++中，可以使用各种库来实现SSL/TLS加密通信，其中最常用的是OpenSSL库。以下是一个简单的示例代码，展示了如何在C++中使用OpenSSL进行SSL/TLS加密通信：
#include <openssl/ssl.h>
#include <openssl/bio.h>

int main() {
    // 初始化 OpenSSL 库
    SSL_library_init();
    SSL_load_error_strings();

    // 创建 SSL 上下文
    SSL_CTX* ctx = SSL_CTX_new(SSLv23_method());

    // 加载证书和私钥（可选）
    SSL_CTX_use_certificate_file(ctx, "server.crt", SSL_FILETYPE_PEM);
    SSL_CTX_use_PrivateKey_file(ctx, "server.key", SSL_FILETYPE_PEM);

    // 创建 TCP 连接并将其包装为 BIO 对象
    int sockfd = ...;  // 替换为真实的套接字文件描述符
    BIO* bio = BIO_new_socket(sockfd, BIO_NOCLOSE);

    // 将 BIO 对象与 SSL 上下文关联
    SSL* ssl = SSL_new(ctx);
    SSL_set_bio(ssl, bio, bio);

    // 建立安全连接
    if (SSL_accept(ssl) <= 0) {
        // 错误处理...
        return -1;
    }

    // 发送数据
   const char* data = "Hello, World!";
   int len = strlen(data);
   int ret = SSL_write(ssl, data, len);

   // 接收数据
   char buffer[1024];
   ret = SSL_read(ssl, buffer, sizeof(buffer)-1);
   buffer[ret] = '\0';

   // 关闭连接和清理资源
   SSL_shutdown(ssl);
   SSL_free(ssl);
   SSL_CTX_free(ctx);

   return 0;
}
1. ZooKeeper 高可用架构：集群模式
● 多节点组成集群：ZooKeeper 通过部署 3/5/7 台机器（奇数台，避免脑裂）组成一个集群，每台机器称为一个 ZNode（注意区分：这里的 ZNode 是集群中的服务器节点，不是数据模型中的节点）。
● 客户端连接任意节点：客户端可以连接集群中的任意一台机器，如果连接的机器宕机，客户端会自动重连到其他存活节点（客户端内置了重试机制）。
2. 核心机制：ZAB 协议（ZooKeeper Atomic Broadcast）
ZAB 是 ZooKeeper 专属的分布式一致性协议，类似于 Paxos/Raft，但更专注于 崩溃恢复 和 原子广播，保证数据在集群中强一致。
它分为两个阶段：
(1) 崩溃恢复模式（Leader 选举）
● Leader 选举：集群启动或 Leader 宕机时，所有 Follower 节点会通过 投票机制 选举出一个新的 Leader（基于 zxid（事务ID）和 myid（节点ID）的规则）。
● 数据同步：新 Leader 会强制其他 Follower 同步自己的最新数据，确保所有节点数据一致后，再进入 消息广播模式。
(2) 消息广播模式（正常服务）
● 写请求由 Leader 处理：所有写操作（如注册服务、更新节点数据）必须由 Leader 接收，Leader 会将写请求封装成事务提案（Proposal），广播给所有 Follower。
● Follower 确认后提交：当超过半数（N/2+1）的 Follower 确认收到提案后，Leader 才会提交事务，并通知所有节点执行，保证 多数派一致性（CP 系统特性）。
3. 如何解决树形结构同步问题？
ZooKeeper 的数据模型是 树形结构的 ZNode 树，集群通过以下方式保证树形结构的强一致性：
● 原子性操作：所有对 ZNode 的增删改操作（如注册服务、更新节点状态）都是原子的，要么全部成功，要么全部失败。
● 版本控制：每个 ZNode 有 version 版本号，客户端修改数据时需携带版本号，避免并发冲突（类似乐观锁）。
● Watch 机制：客户端可以监听 ZNode 的变化（如服务上下线），Leader 会确保 Watch 事件按顺序广播到所有节点，客户端收到事件后能感知最新状态。
4. 通信超时怎么办？
ZooKeeper 通过 心跳检测 + 超时重试 机制应对网络问题：
● Leader-Follower 心跳：Leader 会定期向 Follower 发送心跳包（默认 2 秒一次），如果 Follower 长时间（默认 10 秒）未收到心跳，会认为 Leader 宕机，触发重新选举。
● 客户端重连：客户端与 ZooKeeper 服务器的连接如果断开，会自动尝试重连其他存活节点（客户端库内置了重试逻辑）。
5. 如何保证强一致性？
ZooKeeper 的设计目标是 CP 系统（一致性 + 分区容错性），牺牲部分可用性（A）来保证强一致性：
● 写操作强一致：所有写请求必须由 Leader 处理，并通过多数派确认后才生效，确保所有节点数据一致。
● 读操作可本地化：读请求可以由任意节点直接响应（无需经过 Leader），因此读性能很高，但默认情况下读可能读到旧数据（可通过 sync() 接口强制同步最新数据）。
CAP权衡策略：妥协一致性，AP优先
1.消息的存储与同步：
2.用户在线状态管理：A在节点1，B在节点2，如何实时状态同步？
每个节点维护本地的在线链表，通过redis的发布订阅协议异步广播状态的变更（允许短暂延迟）
3.群聊消息的广播：消息由群主节点所在接收后，再发给其他成员节点，可能导致收到的顺序不一样，
一致性妥协：通过消息ID+时间戳解决乱序问题，客户端本地排序保证最终一致性
分布式聊天服务器的CAP实践
维度	优先级	实现策略
分区容忍性（P）	必须保证	多节点部署、心跳检测、自动故障转移
可用性（A）	最高优先级	异步复制、消息队列、降级策略（如返回旧数据）
一致性（C）	妥协	最终一致性、版本号冲突解决、客户端本地排序
动态相机项目 
1.介绍一下你动态相机的项目
该项目是我们所流片的DVA芯片，为实现动态视觉（DVS）芯片的功能实现和成像应用开发。DVS一种生物启发相机，与传统相机不同，传统是（通过快门控制，光累集，生成一副完成并以固定帧率输出图像）。而他是异步测量每像素的亮度变化，并输出编码亮度变化的时间、位置和标志的事件流。
我的任务是从芯片到PC端构建完整的数据处理（流程）pipeline，实现动态图像显示及后续应用。
在硬件层面，我基于芯片设计手册完成了电路原理图设计，以及12层（高速信号层）和6层（电源/地平面）PCB主板及子板的设计与实现，重点解决了500MHz数据总线的信号完整性问题，确保芯片与处理系统间的稳定通信。
软件层面，我在完成的硬件Zynq-7010 SoC上进行了开发：PL端使用Verilog实现了精确的时序控制模块，接收DVS芯片输出的原始事件流；PS端则开发了网络传输模块，并在应用层基于UDP实现可靠传输。
之后在PC端，使用了多线程进行数据接收与处理，首先C++模板类设计了通用的线程安全的数据队列结构，结合条件变量和互斥锁保证多线程环境下的数据安全，并采用智能指针管理buffer、event和packet等资源，实现event和packet的双缓冲区（用于组织接收到的事件，以及组合哪些事件为一帧进行显示）。系统采用4线程：接收线程、解码线程、数据处理显示线程，进行并行处理，
在数据解码方面，一开始是基于固定时间窗口（30ms）的批量处理，当大量事件触发的时候图像轮廓会十分不清晰，后续是进行了改进实现了基于事件计数（5000事件）的触发式处理，可根据场景需求灵活切换。最终系统实现了清晰稳定的动态事物的轮廓图像显示，目前已应用于人体活动识别研究并有产出相关论文。
针对问题优化方面：
在PL是FIFO利用读写指针确保数据不会溢出，PL到PS是肯定不会的，因为是每次ps端向pl请求一次固定字长的数据如2000字节，DMA从pl搬运2000字节的数据到PS后给出一个中断告知PS，PS就开始处理这2000字节的数据，处理完成后，就可以再次向pl请求2000字节数据，这样的话PS端肯定不会出现数据溢出，只有在pl端才会出现数据溢出的可能（比如pl端数据更新很快，但是ps端数据处理的特别慢，ps还没处理完这2000个自己的数据，pl端就已经开始数据溢出了，这种情况是可能存在的），对pl端出现数据溢出检测方法比较简单，只需要pl侧数据到DMA之间加一个fifo，如果fifo的写满标志拉高，则认为数据溢出。
1.重点是实现数据的完整传输流程：1.我采用的是双缓冲机制，以及对UDP在应用层实现可靠传输。
2.数据处理部分由于之前的根据简单标记事件坐标，会有很多噪声点的问题，后续是利用c++的多态，创新性地实现了RSES方法，通过降采样和卷积分析事件的时间空间分布模式，动态调节事件率阈值过滤噪声和异常事件（如闪光灯干扰）。
3.一开始是基于固定时间窗口（30ms）的批量处理，当大量事件触发的时候图像轮廓会十分不清晰，后续是进行了改进实现了基于事件计数（5000事件）的触发式处理，可根据场景需求灵活切换。最终系统实现了清晰稳定的动态事物的轮廓图像显示，目前已应用于人体活动识别研究并有产出相关论文。
2.解释一下DMA
DMA是一种数据传输技术，用于在外设和内存之间直接进行数据传输无需CPU的干预。减轻CPU的负担。
DMA通常由一个专门的控制器或硬件模块管理。它具有自己的地址寄存器、计数器和状态寄存器，并能够与主存储器和外设进行直接交互。
DMA的操作流程如下：
配置DMA控制器：设置源地址、目标地址、数据长度等参数。
请求DMA传输：外设向DMA控制器发送请求信号，启动数据传输。
DMA传输：DMA控制器根据配置信息自动从源地址读取数据，并将其写入目标地址。
完成中断：当DMA传输完成后，DMA控制器会触发一个中断信号给CPU，通知传输完成。
通过使用DMA，在某些场景下可以实现高速、高效的数据传输，并且减少了对CPU资源的
3.与传统相机的区别是什么，传统相机是如何成像的？
无帧概念：不输出完整图像，仅输出亮度变化的事件。
传统是通过快门控制，光累集。生成一副完成的图像，以固定帧率输出图像。
4.说一下你的滤波算法，为什么不用传统滤波算法
我的事件相机数据是稀疏事件流，每一帧只有部分有数据，是在针对收到一批的事件中，利用事件坐标和时间戳上操作，而传统是对整个图像操作。
(1) 计算复杂度低，内存占用少，实时性高
核心操作是对event事件进行两个3×3 卷积和简单的像素统计，计算量极小。事件数据本身是 稀疏的（每帧只有少量像素有事件），进一步降低了计算负担。
传统图像滤波：高斯滤波、中值滤波等需要对所有像素进行卷积或排序，计算量大。（500倍差距）
我的算法：我是基于时间-空间联合（时间累积 + 空间卷积）通过事件批次和时间戳差值累积，形成动态时间窗口，记录局部区域的历史事件时间总和，再进行空间卷积，动态平衡时间密度与空间变化强度，实现噪声抑制与运动保留。
具体：基于时间操作：
通过初始化改事件缓冲矩阵，通过时间戳记录经过下采样后的与这一批次4096个event（帧frame）第一个到达的事件的时间差值的归一化数据（除以总的时间窗口），并通过动态加权归一化时间到全局的缓冲区，最终是一个320x240的矩阵，每个位置的值会随着时间推移不断累积，形成长时间窗口内的事件时间总和，可以表示历史事件密度（活跃度）。
基于空间操作：两个3×3卷积核用于计算像素中心与（上下左右）的时间累计差异，用于检测事件是否显著，通过计算总事件数比上显著事件发生的数量，与阈值1.5进行比较，小于的话才会添加最终要输出的帧数据中。如果时间累积在空间上随机分布，两个卷积和的结果响应较弱或相互抵消，
因为噪声点时间累积随机分布，卷积响应微弱；而真实事件（如运动物体）会因时间累积的定向变化触发显著响应，需多个相邻像素协同满足条件才会被保留，从而过滤孤立噪声。

5.遇到过什么问题
1.硬件方面：晶振型号。。。（无源有源晶振）导致短路。
2.软件方面：
1.确保了整个硬件系统能正常工作后，包括电压电流高低电平信号等，在pc端压根没有图像数据输出，里也没有数据传过来，用工具进行信号检查，比如用示波器抓取芯片req应答信号的跳变等。
1.图像显示图像样式的跟实际差很多，由于忘记字节序转换了，导致时间戳xy坐标等计算异常，显示异常，打印数据，发现不满符合T+A+数据+B+数据。
2.有遇到死锁，就是运行一下就卡住不动了，就是条件变量的notify 
3.刚开始成功有图像了，但是噪声点太多。。。
4.设计算法有遇到奇异值，需要防御性编程，计算rate阈值的时候，可能mask为0，通过加上0.000001，当不为0是对结果影响较小，且可以防止奇异值。
6.说一下你的UDP可靠传输
一开始是采样了UDP+时间戳（插排）排序解决乱序的部分可靠性增强，
后面是采用了KCP在应用层实现可靠传输，具体设计：
有哪些配置：窗口大小：32(包） 重传次数：2  RTO时间 ：1.5倍  MTU：1400字节  最小RTO:30ms
拥塞控制： 0不启动
1.创建KCP对象，初始化一个会话编号（相同数据才被认可），然后传入回调函数的指针
2. 创建 KCP 对象，user 参数传入 socket
    ikcpcb *kcp1 = ikcp_create(0x11223344, (void*)(intptr_t)udp_socket);
 3. 设置 KCP 输出回调
    kcp1->output = udp_output;
4. 其他 KCP 配置（如窗口大小、延迟控制等）
    ikcp_wndsize(kcp1, 1024, 1024);
    ikcp_nodelay(kcp1, 1, 10, 2, 1);

# 基本使用

1. 创建 KCP对象：

   ```cpp
   // 初始化 kcp对象，conv为一个表示会话编号的整数，和tcp的 conv一样，通信双
   // 方需保证 conv相同，相互的数据包才能够被认可，user是一个给回调函数的指针
   ikcpcb *kcp = ikcp_create(conv, user);
   ```

2. 设置回调函数：

   ```cpp
   // KCP的下层协议输出函数，KCP需要发送数据时会调用它
   // buf/len 表示缓存和长度
   // user指针为 kcp对象创建时传入的值，用于区别多个 KCP对象
   int udp_output(const char *buf, int len, ikcpcb *kcp, void *user)
   {
     ....
   }
   // 设置回调函数
   kcp->output = udp_output;
   ```

3. 循环调用 update：

   ```cpp
   // 以一定频率调用 ikcp_update来更新 kcp状态，并且传入当前时钟（毫秒单位）
   // 如 10ms调用一次，或用 ikcp_check确定下次调用 update的时间不必每次调用
   ikcp_update(kcp, millisec);
       
   ```

4. 输入一个下层数据包：

   ```cpp
   // 收到一个下层数据包（比如UDP包）时需要调用：
   ikcp_input(kcp, received_udp_packet, received_udp_size);
   ```
   处理了下层协议的输出/输入后 KCP协议就可以正常工作了，使用 ikcp_send 来向
   远端发送数据。而另一端使用 ikcp_recv(kcp, ptr, size)来接收数据。


# 协议配置

协议默认模式是一个标准的 ARQ，需要通过配置打开各项加速开关：

1. 工作模式：
   ```cpp
   int ikcp_nodelay(ikcpcb *kcp, int nodelay, int interval, int resend, int nc)
   ```

   - nodelay ：是否启用 nodelay模式，0不启用；1启用。
   - interval ：协议内部工作的 interval，单位毫秒，比如 10ms或者 20ms
   - resend ：快速重传模式，默认0关闭，可以设置2（2次ACK跨越将会直接重传）
   - nc ：是否关闭流控，默认是0代表不关闭，1代表关闭。
   - 普通模式： ikcp_nodelay(kcp, 0, 40, 0, 0);
   - 极速模式： ikcp_nodelay(kcp, 1, 10, 2, 1);

2. 最大窗口：
   ```cpp
   int ikcp_wndsize(ikcpcb *kcp, int sndwnd, int rcvwnd);
   ```
   该调用将会设置协议的最大发送窗口和最大接收窗口大小，默认为32. 这个可以理解为 TCP的 SND_BUF 和 RCV_BUF，只不过单位不一样 SND/RCV_BUF 单位是字节，这个单位是包。

3. 最大传输单元：

   纯算法协议并不负责探测 MTU，默认 mtu是1400字节，可以使用ikcp_setmtu来设置该值。该值将会影响数据包归并及分片时候的最大传输单元。

4. 最小RTO：

   不管是 TCP还是 KCP计算 RTO时都有最小 RTO的限制，即便计算出来RTO为40ms，由于默认的 RTO是100ms，协议只有在100ms后才能检测到丢包，快速模式下为30ms，可以手动更改该值：
   ```cpp
   kcp->rx_minrto = 10;
   ```
7.具体流程
步骤1：PL读取DVS数据
LVDS Receiver IP核：若DVS输出差分信号，需实例化Xilinx的LVDS接收IP核，转换为并行数据。
SPI/I2C控制器：若需配置DVS寄存器（如曝光时间），通过PL的SPI/I2C控制器实现。
FIFO缓冲：使用PL的BRAM或URAM构建FIFO，解决数据速率波动问题。
步骤2：
步骤3：PL → PS数据传输
传输方式：AXI DMA：PL通过DMA将数据直接写入PS的DDR内存，PS通过CPU读取DDR数据。
关键配置：设置AXI总线宽度（如64位）和时钟频率（如100MHz），确保带宽满足DVS数据速率（如1Gbps需至少125MHz时钟）。
步骤4：PS网络传输UDP：低延迟，适合实时显示，需在PC端处理丢包。
步骤5：PC端接收与显示
接收工具：TCP/UDP Socket：
专用软件：OpenCV实时显示事件流。
数据处理：解析数据包（如提取时间戳、事件坐标）。
8.可能造成丢包的原因
1. 缓冲区溢出：设计了双缓冲区，多线程分离：独立线程处理网络接收（recvfrom）和数据处理（RSES算法），避免阻塞
2. 包过大，UDP不会分段,IP层会分片，重组时丢失
3. 过快
4. 网络拥塞：我使用的是有线千兆以太网，
独占带宽：有线连接避免了无线网络的信道竞争和干扰，带宽利用率更高。
稳定的物理层：网线传输受外界干扰极小（如无WiFi信号冲突、无蓝牙设备干扰）。
低延迟和抖动：有线网络的延迟通常在微秒级，且波动极小，不易因延迟突变导致拥塞控制机制触发。

9.如何检测UDP没有丢包
 PS端（Linux C++）的丢包检测
应用层序列号：在UDP数据包中嵌入递增序列号，接收端检测序号连续性。
统计输出：定期（如每秒）打印丢包率到日志文件或通过额外UDP控制通道上报。
网络层辅助工具：tcpdump抓包分析：在PC端抓包验证丢包是否发生在传输层。
(1) 降低丢包率的设计
用双缓冲机制。
多线程分离：独立线程处理网络接收（recvfrom）和数据处理（RSES算法），避免阻塞。
传输大小控制：MTU最大传输字节数一般是1500字节，超过了会在IP层进行分片传输以及重组，也可能导致丢包。我们是用了800字节一次。但分片丢失会导致整个UDP包丢失（因为接收端必须收到所有分片才能重组）。
实习项目
1.说一下你具体的实习项目？
幽游白书，以前比较火的一部日本动漫，公司是拿到了授权，围绕这部动漫剧情设计的一款游戏，
项目背景：这个是作为开服新玩家引导的核心活动，通过角色收集与升星激励提升玩家留存率。
我主要是在游戏逻辑服负责这主角团集结的模块开发，端午节日活动，以及一些商城广告的内容与客户端进行联调。
数据结构与协议设计：
首先是在c++层制设计相关的数据结构来进行封装一些进度信息，任务信息，其中包括一些id号，进度，以及领取状态。再与客户端制定相关的通信协议，利用protobuf的数据格式传输以进行数据的同步。
Lua业务逻辑实现：
之后在lua层设计玩家活动状态存储结构，包含活动状态、积分、已激活角色、任务进度奖励领取等字段表并通过PB压缩，定期进行数据落盘。之后就是一些相关业务逻辑功能实现，其中包括(活动状态管理,任务与奖励系统,跨天与持久化),一些任务条件判断通过遍历配置表实现多类型任务自动化校验，以减少硬编码，也方便后续迭代，如(判断等级条件主角卡类型数目等等)，进行升星奖励发放以及抽奖SSR全服广播展示。
难点：与其他模块结合，比如VIP加成，资源回收，时间戳计算跨天，状态刷新和奖励倍率计算等等。设置事件ID记录，当客户端领取奖励时，将该事件ID放入队列中，下一轮会遍历该队列对其触发时间戳，计算倍率刷新。
功能测试：
1.代码编写后，同步代码到自己的服务器进行热更新，并通过异步日志，进行调试。
2.设计实现GM测试链，在Unity游戏引擎，进入自己的测试服进行功能测试，模拟协议收发验证功能完整性
性能优化与代码完善：
1.通过缓存(如userDV)提高性能，减少DB查询，2.相关的防外挂措施.3.协议收发一些异常值的过滤3.代码规范以及命名规范等等。我的MT会帮检查。
联调验收：
进行与客户端联调成功后，测试验收，代码提交上传。
2.难点是什么？
1.复杂状态联动 业务逻辑判断需要周密吧，防止外挂，需要设置比较多的一些校验机制，跨天补发，vip加成等，与客户端联调，活动状态（未开启/进行中/已结束）、卡牌激活状态、任务进度需实时联动。例如跨天补发奖励时，需同时校验玩家创建天数、活动状态、卡牌激活数量、积分进度等多维条件，任一环节出错可能导致奖励重复发放或遗漏。
2.数据一致性风险，关键操作（如跨天补发、任务领奖）依赖服务器与客户端数据同步。若玩家在异常网络环境下重复提交请求，或客户端本地缓存状态与服务器不一致，可能导致重复领取奖励或状态错乱，需通过唯一状态标记
3. 为什么需要这些协议号？
定义通信协议：每个协议号对应一种特定的客户端请求或服务端响应类型，相当于“通信暗号”。服务端和客户端通过协议号快速识别消息内容，确保正确解析和处理数据
解耦通信逻辑：客户端和服务端通过预定义的协议号交互，无需关心具体实现细节，只需按约定发送/解析数据。
4.你制定的协议是怎么样的？是怎么进行通信的？
1. 协议号的定义与分工
(1) C++ 层：协议号的底层定义
在你的 hCmdClient.h 中，协议号（如 86）是网络通信的基础标识，是二进制通信的基础，直接关联到网络数据包的编解码。
(2) Lua 层：协议号的逻辑映射
在 Lua 中，协议号（如 86）被映射到具体的业务逻辑函数，通过协议号识别业务类型，调用对应的 Lua 函数处理游戏逻辑（如检查任务状态、发放奖励）。
协议号在Lua 层是业务逻辑的路由标识，与 C++ 的底层协议号数值一致，但由 Lua 脚本动态管理映射关系。
我定义了112-86 +消息内容发送到服务器，服务器通过解析协议号进行调用相关的回调函数以及传参，这里涉及到C++和lua框架交互，c++层负责网络模块的连接管理以及收发，而通过tolua++工具，将C++的网络接口代码绑定给Lua，使lua可以调用网络功能，协议的处理，以及后续业务逻辑判断，调用相应的回调。实现业务逻辑和底层代码的解耦，支持热更新动态调整协议处理逻辑。
2. 协议处理的完整流程
(1) 客户端发起请求
玩家点击“领取任务”按钮，客户端构造协议包：数据通过 TCP 发送到服务端。
(2) 服务端 C++ 层处理
网络模块接收数据：解析协议头，获取协议号=86 和参数 {taskId=101}。
调用 C++ 处理函数：根据 86 找到对应的 C++ 函数（如 HandleCardCollectGetTask），解析参数并执行基础校验（如协议格式是否正确）。
转发到 Lua 层：通过 tolua++ 绑定的接口（如 SEND_USER_CMD_TO_LUA），将协议号和参数传递给 Lua。
(3) 服务端 Lua 层处理
Lua 接收协议：Lua 的全局事件分发器根据协议号 86 查找注册的回调函数。
执行业务逻辑：检查玩家任务状态、发放奖励，收集进度并更新静态表，用于后续落盘。
返回响应：Lua 构造响应协议（如 s_cCardCollectGetTask），通过 C++ 绑定的接口（如SEND_RESPONSE_TO_CLIENT）返回给客户端。
协议注册系统：核心协议注册函数，建立协议类型+协议号+参数组合与回调函数的映射关系，当服务端收到客户端请求时，先由dispatch函数接收，再根据协议号分发给具体的回调函数。
协议注册：通过register_v2将协议号与回调函数绑定，建立路由表。
请求分发：客户端请求→dispatch总入口→根据协议号查找回调→执行业务逻辑。
事件驱动：跨天、登录等事件通过gUserEventDispatcher触发自动化处理。
多协议分类分发架构：
| 协议头（协议类型+协议号） | 协议体（具体数据） |
5. c++和Lua具体如何分工？
(1) 网络通信模块（C++ 实现，Lua 调用）
C++ 负责：
底层网络通信（TCP/UDP 连接、数据包收发、协议编解码）。
高性能数据处理（如加密、压缩、心跳包管理）。
Lua 负责：
协议逻辑（如解析客户端请求、构造服务端响应）。
业务规则（如任务领取条件、奖励计算）。
tolua++ 的作用：
tolua++ 本质上是一个代码生成工具（Tool）。它的核心功能是通过自动化生成绑定代码，将 C/C++ 的接口暴露给 Lua 脚本调用。
6.GM测试链的原理是啥？
Unity 客户端连接游戏服务器的 GM 管理接口（TCP 协议），发送 GM 指令到服务器。
是游戏服务器中提供的管理工具，允许通过特定指令直接干预游戏运行，用于调试、维护、紧急修复或特殊操作。
GM 测试的核心原理分析
1. GM 指令注册与执行的流程
(1) GM 指令注册
注册入口：注册 GM 指令的名称、描述、示例和回调函数。
该函数由 C++ 通过 tolua++ 暴露给 Lua，最终将指令存储到 C++ 的 GmMgr 管理器中。
(2) GM 指令执行
Unity 客户端输入 GM 指令（如“重置主角团数据”）。
C++ 通过socket网络模块接收指令，并解析。C++的 GmMgr会根据指令名称查找对应的 Lua 回调函数。通过 tolua++ 绑定调用 的Lua 函数 GM.gmResetData，执行具体的业务逻辑（如重置玩家数据）。
C++ 与 Lua 的交互：
GM 指令的回调函数（如 GM.gmResetData）是直接定义在 Lua 中的：
这些函数通过 gGmOpRegister注册到GmMgr中
指令传递：C++ 通过 tolua++暴露的接口将指令注册到 Lua。
执行调用：C++ 通过绑定接口调用 Lua 的 GM 回调函数。
7.全服展示是怎么实现的？
这部分，是已经有相关的API接口，并没有再重新实现，看过其中代码，它主要原理是有个usermag模块专门维护全服的数据统一管理，基于事件驱动+定时合并的策略广播更新，客户端仅负责展示，不修改数据。
广播并非逐条实时推送，而是基于：
事件触发：当usermag检测到新的SSR抽奖记录时，标记“存在待推送数据”。
定时合并：通过一个全局定时器（例如每5秒触发一次），检查缓存中的增量记录，将多条记录合并为一个批次，通过Protobuf协议封装后统一广播，减少网络IO次数。
广播时，usermag会遍历在线玩家列表，向每个客户端下发合并后的消息，确保全服玩家几乎同步接收到更新。
3.要是同时大量触发呢？怎么优化？
① 合并广播（去重 + 节流）
问题：1000人同时抽中最高奖，每秒广播1000次消息。
优化：合并相同事件：短时间内（如1秒）多次最高奖抽中，合并为1次广播（如“XX等10位玩家抽到SSR”）。
节流控制：每秒最多广播N次最高奖通知（如每秒最多5次）。
② 分级广播（精准推送）
问题：全服广播导致所有玩家收到刷屏消息。
优化：仅广播给相关玩家：
全服公告：仅显示“XX玩家抽到SSR”（不重复刷屏）。
好友/公会广播：仅推送给好友或公会成员。
UI优化：客户端本地缓存最近广播，避免重复显示。
③ 消息队列 + 异步推送
问题：直接广播可能导致网络拥塞。
优化：使用消息队列（如Kafka、RabbitMQ）解耦抽奖和广播。
后台服务消费队列，控制推送速率（如每秒最多100条消息）。
如何防外挂
服务器权威：确保抽奖结果由服务器计算，客户端无法篡改。
日志记录：记录所有最高奖抽中事件，便于后续审计。
防刷机制，
(3) 跨服广播（如分区分服架构）
消息转发：通过网关服务器或消息中转服务跨服推送。
不信任客户端	所有关键逻辑与数据由服务器验证，客户端仅做展示
重复检验	服务端多次校验客户端提交的数据合法性
防止重复请求	使用 Token/Nonce、请求限频、操作去重
数据加密与校验	关键数据加密存储、传输加密、签名校验
行为监控	检测异常行为模式，如瞬移、高频攻击、自动挂机等
接口安全	限制 Lua/C++ 接口权限，防止敏感函数被滥用
防调试/内存修改	反调试、内存校验、加密关键数据
日志与追溯	记录关键操作，支持行为回溯与外挂分析
账号安全	设备/IP 绑定、登录保护、防多开/盗号
通信安全	使用 TLS/SSL，关键协议额外加密和签名
8.不同区服是怎么实现的？
公司这边的话是采用的数据镜像的方式，而不是完全独立的物理服务器。
每个地区（如国服、美服、欧服、韩服）部署完全独立的物理服务器集群，包括：
游戏逻辑服务器（负责战斗、任务等核心逻辑）
数据库服务器（存储角色数据、物品信息等）
缓存服务器（如Redis集群加速数据访问）
登录验证服务器（账号安全与区域接入控制）
数据严格隔离：不同地区的数据库完全独立，玩家角色、金币、装备等数据无法跨区访问（如国服角色无法登录美服）。
9.异步日志是怎么实现的？为什么要用这个消息队列？ 日志系统设计为独立线程
在我们项目的游戏后端架构中，Lua 代码的日志输出默认是异步化的。
框架底层通常用 C/C++ 实现高性能日志模块（如 spdlog、自定义日志库），运行在独立线程中：
Lua 层：调用日志接口 logInfo("message")时，仅将日志消息放入内存队列（如环形缓冲区）。
C/C++ 层：后台线程从队列中消费队列消息，执行实际的磁盘写入或网络发送。
优点：Lua 代码无需等待日志落盘，极大减少 I/O 对逻辑线程的影响。支持批量写入和日志压缩，提升吞吐量。
10.你的缓存是怎么设计的？
内存中的变量或Lua表来暂存数据。
(1) 双缓冲设计
静态表（_userStaticSet）：持久化数据，定期落盘。
动态表（_userDynamicSet）：运行时数据，下线释放。

11.你的数据库是怎么存储的？什么时候进行落盘？
在游戏开发中，当需要将 Lua 层的数据（比如玩家状态）存入数据库时，通常会依赖框架封装好的数据管理层。以你提供的代码为例，__G.gUserMgr.getUserDBDataByUserId(userId) 返回的 userVar 并不是一个普通的 Lua table，而是框架封装的、与数据库绑定的数据对象——它内部可能通过缓存机制维护了内存中的用户数据，并在初始化时从数据库加载，或在修改后自动触发保存逻辑。当你通过 userVar.cardCollectSys 添加或修改字段（比如新增活动状态、积分等）时，框架会监听到这些改动（可能通过元方法或代理模式），并在合适的时机（如玩家下线）自动将整个 userVar 结构序列化后存入数据库。因此，即使直接操作 userVar 的子结构（如 cardCollectSys），改动也会被框架“自动”同步到数据库，无需手动逐字段处理或调用保存函数，前提是框架已对 userVar 的所有层级实现了数据绑定和序列化逻辑
内存初始化：在LOC.getOrSetDBVar中初始化子表；并增加到uservar中，
PB压缩：在LOC.userData2pb中将内存数据转换为二进制格式；
落盘到MySQL：通过M.handleUserSaveDB最终写入数据库。
是否新增MySQL字段取决于表结构设计，代码本身不会动态修改表结构，需依赖预先定义的PB协议和数据库迁移脚本。
(2) 技术深度追问准备
“为什么用PB压缩而不是JSON？”	
“PB二进制编码更高效，适合高频存储；且支持向前向后兼容，方便后续新增字段。”
“如何保证落盘时数据不丢失？”	
“1. 落盘前先压缩为PB二进制减少IO时间；2. 失败时记录错误日志并加入重试队列；3. 超大数据自动切换公共存储兜底。”
(3) 性能优化亮点提炼
PB压缩：减少MySQL存储空间和网络传输量。
定时批量落盘：降低IO频率（如每5分钟一次）。
冷热数据分离：高频变更的动态数据不落盘，减少写压力。
5. 潜在改进建议
缓存优化：对高频访问的静态数据（如玩家等级）可增加Lua层缓存，减少PB解压开销。
异步落盘：当前代码未体现是否异步，若同步落盘可能阻塞主线程，建议改用消息队列（如Kafka）解耦。
监控指标：添加落盘耗时、PB压缩率等监控，便于性能调优。
(1) 动态字段扩展性
无需修改表结构：
新增字段只需在userSysProtoInit中配置，并在对应模块的savePbcData/loadPbcData方法中处理PB转换逻辑，无需修改MySQL表结构。
(2) 性能优化
减少IO次数：
通过定时落盘或批量操作合并多次变更，避免频繁写入MySQL。
压缩存储：
PB二进制比JSON/XML节省30%~50%空间，降低存储成本。

12.Lua热更新是什么？他是怎么实现的？他的优势是什么？
热更新（Hot Update）是指在不重启游戏服务器的情况下，动态更新代码或资源，以修复 Bug、调整逻辑或发布新内容。其核心目标是减少停机时间，提升系统的可用性和可维护性。
一、热更新的核心原理
1. 热更新的核心流程（C++与Lua协作）
(1) C++ 层的角色
保持连接与底层稳定：C++ 层负责网络通信、数据库操作、内存管理等底层功能，这些模块不需要热更新，因为它们是系统的“骨架”，频繁变动会导致稳定性风险。
提供接口给 Lua：通过 tolua++绑定暴露给 Lua 的接口也是稳定的，热更新仅替换 Lua 逻辑，不涉及 C++ 代码。
(2) Lua 层的热更新
默认缓存模块：Lua 的 require 机制会缓存已加载的模块（存储一个loaded 表中），这时游戏是可以继续运行的（包括逻辑改变，新增功能，重新配置图片，配置表等等）。
更新 Lua 文件的步骤：
清除旧模块缓存：通过 package.loaded[module_name] = nil 移除旧模块的引用。
重新加载新文件：调用 require(module_name) 读取磁盘上的新 Lua 文件，执行最新代码。
替换旧逻辑：新加载的模块会覆盖旧模块的函数和变量，实现业务逻辑更新。
可能的情况：
**情况 1：热更线程先完成 require("A")
文件加载和执行完毕，模块 A 被缓存到 package.loaded["A"]。
游戏线程调用 require("A") 时，直接返回缓存的模块，无竞争问题。
情况 2：游戏线程先调用 require("A")**
由于热更线程已经调用了 require("A")（但未完成），Lua 的模块加载机制会 阻塞游戏线程，直到热更线程完成加载。
游戏线程会 等待热更线程完成，然后直接使用热更后的新模块，无报错。
根本原因：
Lua 的 require 是 线程安全的（在单线程虚拟机中，协程的切换由开发者控制，不会并发执行 require）。
即使热更和游戏逻辑同时调用 require("A")，后调用的线程会等待先调用的线程完成加载，最终所有调用共享同一个新模块。
13.防外挂是做了哪些操作？你还知道别的吗？
奖励发放防重复：使用状态标记（如 collectAllStatus）控制幂等性，防止玩家重复领取集齐奖励或进度奖励。
防外挂处理：敏感操作CD：限制玩家频繁点亮卡牌请求，通过时间戳比对拒绝异常请求。
数据校验：服务端二次验证客户端上报的角色ID与升星等级，校验卡牌合法性）。
科研项目
介绍一下你的项目/论文？
1. 介绍一下你的论文？
主要研究背景就是在室内，gps导航定位系统失效，比如商场，地下停车场。需要为室内导航定位寻找一个新的方法，而智能手机应用十分广泛内置了多种传感器，基于PDR是一种自主导航定位方法，其主要步骤为4四部分，步数统计，步长估计，航向估计，多源信息融合实现自主的室内导航定位。行人手持手机包括了不同手持模式，不同步态，以及假行走，就是原地不动但是玩手机等依然有信号输出等问题，我提出了一种的多条件约束的联合判别机制的步数检测方法，首先是根据峰谷值以及过零检测统计步数，由于噪声会产生较多的伪峰和虚假的过零点，需要设计阈值算法进行剔除异常值，当跑步转为步行等的过渡状态时会出现一些满足条件的伪峰，因此根据他们在不同的情况组合下需要进行不同的步长估计模型，我是提出一种基于希尔伯特变换的瞬时频率估计方法，通过实验同时携带多台手机，不同的携带方式，在操场以任意步态走了576步，最终结果是提取的频率效果几乎一致，因此适合在任意模式下进行步长估计，误差率仅为1.8%，为了解决蓝牙信号由于多经效应，波动较大，传统三边定位误差大，稳定性低问题，我通过重构传播损耗模型，以及卡尔曼进行信号稳定，并提出了一种加权的最小二乘法的多边定位方法，之后研究集中在解决航向的问题和融合定位问题（pdr短期准，长期不准），通过机器学习方法，利用特征工程，进行模式分类，以及检测上下楼梯，最后实现基于时间或者距离的完整的定位导航系统。
面试非技术类问题
1.自我介绍
面试官您好，很荣幸参加这次面试，我叫敬烽，来自浙江嘉兴，
目前硕士研二就读于西安电子科技大学的新一代电子信息技术专业
本科就读于桂林电子科技大学电子测控技术专业，本科期间努力学习专业知识，拿到了校一等奖学金，社会奖学金等荣誉，同时，我积极参加竞赛做过一些项目，曾获全国大学生电子设计大赛区优胜奖，美斯特科技创新奖，全国大学生数学竞赛一等奖。
硕士期间我也拿到了校一等学业奖学金。
我的研究课题方向是室内导航与定位，目前也已发了两篇一区的SCI，在两个月前均已被录用，自身具备一定的科研能力。
在实验室项目经历上，我主要是负责一个动态相机的项目，其中主要负责芯片功能验证、软件代码的编写与调试。可能与公司的研发业务还是具有一些相关性的。
在个人专业技能上，熟悉C/C++,MATLAB等编程语言，熟悉数据结构和算法计算机网络和操作系统原理，对mySql数据库的原理也有一定的了解，此外我还具备一定的硬件能力，包括独立设计电路，绘制12层高速pcb的以及板子最终软硬件联调的经验，与岗位需求的技术栈较为匹配。4-7月在互爱科技从事c++软件开发的实习，提高了自己的一个开发能力以及与团队合作能力。
除了以上技术技能方面，在平常学习生活中，我也乐于奉献，多次参与志愿者活动，从本科开始到目前研究生阶段就担任学习副班长的职位，也为班级做出自己的一份贡献。也获得了优秀班干部等称号。
同时我英语水平良好，本科期间通过了英语6级。
我后续想留在广东这边发展
以上就是我的自我介绍，谢谢面试官。
2.为什么想应聘嵌入式这个岗位？

3.考虑留在深圳吗？

3.考虑留在深圳吗？

4. 校招进展怎么样，都投了哪些公司，到什么流程当中了

7. 你的实习不考虑转正吗？

5.主要通过什么途径了解到影石的

5.你的职业未来规划

Hr必问的14个问题，你知道几个（一）
Hr面试无非就是问这几个问题 1、自我介绍（必问、准备好） 2、你为什么选择（了解过）我们公司（问到的概率90%，挖坑题哦） 3、你有什么缺点或优点 (85%） 4、你的职业规划是什么 (90%，考察） 5、你对加班怎么看（80%，抗压） 6、你的期望薪资是多少 （95%，试探） 7、离职原因（有过工作经历的话、必问） 8、你还应聘过哪些公司 (90%、试探） 9、如果录用了你，你将怎么展开工作（90%，考察) 10、你是怎么面对自己的失败的 (75%，考察抗压) 11、你希望和什么样的上级共事 （75%，考察) 12、你什么时候到岗？（95%，考察评估) 13、谈谈你空窗期都做了什么？（95%，考察） 14、你还有什么想问的？（90%，挖坑）

7.

你的职业规划

你的优缺点
优点：有较强的驱动力，不喜欢拖延会全身心投入完成这个任务，注重细节
缺点：过于注重细节，会导致花费过多的时间，（这个自己后面也反省过），发表论文时对于写文献调研部分总是改，想写的过于完美，但又总是达不到自己昨晚睡前想的样子，就会导致花费过多时间，后面反省就应该先完成成体大概，然后再站在全局的角度，针对性有关联性的去改进，因为前面一些花费了时间感觉写的比较好的部分最后发现却是并不太需要。
反问环节问题
嵌入式stm32，rtos相关
1.GPIO
模式类型	模式名称	特点	典型用途
输入模式	模拟输入	直接连接 ADC，读取模拟信号	温度传感器、电位器
	浮空输入	无上拉/下拉，高阻态	按键（需外部上拉）
	上拉输入	内部上拉，默认高电平	按键（内部上拉）
	下拉输入	内部下拉，默认低电平	按键（内部下拉）
输出模式	通用推挽输出	主动输出高/低电平，驱动强	LED、继电器
	通用开漏输出	只能输出低电平，高阻态需上拉	I²C、线与逻辑
	复用推挽输出	外设功能 + 推挽输出	UART TX、SPI MOSI
	复用开漏输出	外设功能 + 开漏输出	I²C SDA、CAN TX



2.用过哪些，时钟频率多少？
32f103  72Mhz

3.用过哪些外设？什么通信方式/协议？
c++代码规范笔记
1.const和restrict
const能用则用，无副作用
restrict有利于编译器的性能优化，性能敏感场景建议使用

面试复盘
int_64和long的区别？
类型	是否固定大小	典型大小（常见平台）	头文件	主要区别
**int64_t
**	✅ 固定为 64 位（8 字节）	总是 8 字节	<cstdint>
（C++11 起）	大小确定，跨平台一致，推荐用于精确控制位数
**long
**	❌ 大小由编译器和平台决定	可能是 4 字节 或 8 字节	无（内置类型）	不确定大小，依赖平台，一般不用于精确位宽需求
单reactor和多reactor的区别？
类型	说明	核心思想
单 Reactor	所有的 连接建立、读写事件监听与分发，都由一个 Reactor（一个线程/循环）处理	单线程/单事件循环负责一切
多 Reactor	将连接 accept（接受） 和读写事件的处理 分离到多个 Reactor 上，通常是主从 Reactor 模式，提高并发能力	多线程/多事件循环分工协作
多reactor模式下，read调用是在哪个线程中？
组件	职责	线程模型	是否调用 read()
Main Reactor	监听服务端 listen fd，接收新连接（ACCEPT）	通常是 1个线程	❌ 不调用 read()，只 accept()
Sub Reactor	监听已连接 socket 的可读/可写事件（EPOLLIN / EPOLLOUT）	多个线程（每个线程一个事件循环）	✅ 调用 read()，通常在 handle_read() 中
事件处理器（如 handle_read()）	执行 read()，处理业务数据	和 Sub Reactor 同一个线程	✅ 是 read() 调用的地方
https://mp.weixin.qq.com/s/3AlSEX0m94hmGAWxxeo5zg
Preactor和Reactor的区别？
软链接和硬链接具体实现？ 
对比项	静态链接（Static Linking）	动态链接（Dynamic Linking）
链接时机	编译时（链接阶段）就把库的代码合并进可执行文件	运行时才加载库代码
最终程序	包含库的代码，体积较大	不包含库代码，体积较小，但依赖外部库文件
运行依赖	不依赖任何外部库文件，可独立运行	需要动态库（如 .so / .dll）存在，否则程序无法运行
库文件举例	Linux: .a
，Windows: .lib	Linux: .so
，Windows: .dll
加载速度	启动快（代码已在程序内）	启动稍慢（需动态加载库）
更新维护	更新库需重新编译整个程序	只需替换动态库文件，无需重新编译主程序
多进程共享	每个程序都有一份库代码拷贝，内存占用可能较高	多个程序可共享同一份动态库，节省内存
如何选择？
静态链接：   1.希望独立运行，不依赖外部文件
2.对程序启动速度要求高
动态链接：   1.希望节省磁盘和内存，多个程序共享库
2.希望发布后能单独替换库文件，不用重新编译
3.库频繁更新，希望不重新编译主线程就能升级

软、硬、动态、静态链接的区别？
名称	所属领域	核心概念简述
硬链接	文件系统	多个文件名指向同一个物理数据块（inode）
软链接	文件系统	一个文件存储另一个文件的路径（类似快捷方式）
静态链接	程序构建/编译	把库代码直接编译进可执行文件，不依赖外部库
动态链接	程序构建/运行时	可执行文件运行时才加载共享库，节省资源，更灵活
一些关键constexp和const？
explict：不要隐式类型换
volatile：表示变量经常改变，每次需要从内存进行读取
constexp和const：constexp在编译期时就能计算出结果，为常量；const仅要求为运行时期为常量
final：不允许被继承

delete[]的底层原理？
当你调用 new[] 分配数组时，编译器通常会在分配的内存块头部（前面）隐式存储一个“数组大小”信息（比如元素的个数），delete就能知道需要析构多少个了

mmap机制？以及优缺点
mmap（memory map，内存映射） 是一种由操作系统提供的系统调用（system call），它可以将一个 文件（或匿名内存区域）映射到进程的虚拟地址空间中**，使得进程可以像访问内存一样直接读写文件内容，而不必使用传统的 read() / write() 等系统调用。
mmap 文件映射方式：
mmap() 系统调用 会将文件直接映射到你的进程的虚拟内存地址空间
映射后：
你可以通过 指针直接访问文件的内容，就像它是内存数组一样
操作这块内存，就相当于操作文件
操作系统会在背后自动帮你把数据 按需从磁盘加载到内存（Page Fault 机制）
修改了内存，操作系统也会 按需将脏页写回磁盘
mmap 的优点和缺点
相比传统文件读写方式，mmap 有以下优势：
1. 减少数据拷贝
传统 read/write 需要用户态与内核态之间多次数据拷贝；
mmap 直接将文件映射到进程地址空间，访问时就像访问内存一样，不需要在用户态和内核态之间拷贝；
2. 访问效率高
对文件的随机访问像数组一样高效；因为虚拟地址连续的，适合需要频繁随机访问的场景；
3. 缺页异常的懒加载
可以处理比内存更大的文件，缺页中断时，才发生物理分配
4. 支持进程间共享
使用 MAP_SHARED 标志时，多个进程可以映射同一个文件，从而实现进程间共享内存，修改对其他进程可见，并最终同步回磁盘；
这是实现高效进程通信（IPC）的一种方式；
5.数据一致性，os会自动进行数据写回磁盘，所以要是写的多，磁盘io开销变大
mmap 的缺点与注意事项
❌ 1. 访问未映射/未加载部分会触发缺页中断
如果访问了尚未加载到内存中的页面，会触发 缺页异常，由操作系统负责从磁盘读取，有一定延迟；
对性能敏感的场景要注意访问的局部性；
❌ 2. 写回磁盘的时机不确定
即使你使用了 MAP_SHARED，修改的数据也不是立即写回磁盘，而是由内核异步刷回；
如果需要确保数据落盘，可能需要手动调用 msync()：
❌ 3. 对大文件映射可能占用较多虚拟地址空间
映射非常大的文件时，要注意进程的虚拟内存布局和地址空间是否足够；
32 位系统上地址空间有限（通常 4GB），可能成为瓶颈；
❌ 4. 映射和解除映射有一定开销
mmap() 和 munmap() 调用本身也有一定开销，不适合频繁映射/解除映射小文件；
如何实现特例化只能int或string，别的会直接报错?偏特例化？
偏特例化只特例化部分的数据类型
template <typename T>
class MyType {
    static_assert(std::is_same_v<T, int> || std::is_same_v<T, std::string>,
                  "MyType 只允许 int 或 std::string 类型");
};

继承的内存布局？虚继承的内存布局？
虚继承：
+----------------+
| vbptr1 (4B)    |  <-- Base1 的虚基类表指针
| Base1::b (4B)  |
+----------------+
| vbptr2 (4B)    |  <-- Base2 的虚基类表指针
| Base2::c (4B)  |
+----------------+
| Derived::d (4B)|
+----------------+
| GrandBase::a (4B)|  <-- 虚基类 GrandBase 的成员，只存一份
+----------------+
多继承：
+----------------+
| Base1::b (4B)  |
| GrandBase::a (4B)|  <-- Base1 子对象中的 GrandBase
+----------------+
| Base2::c (4B)  |
| GrandBase::a (4B)|  <-- Base2 子对象中的 GrandBase（重复！）
+----------------+
| Derived::d (4B)|
+----------------+
指针使用需要注意什么？（黄金准则）
1.指针必须初始化   2.要检查空指针 3.释放后置空，避免野指针 4.手动释放，防止内存泄漏，5.前后const  6.智能指针 7.多级解引用  8.函数参数传指针

GDB怎么查看调用栈？怎么定位死锁？

你了解哪些c++14或17的特性？
1.结构化绑定，可以一键解包元组，结构体或者数组
std::pair<int, std::string> p{1, "hello"};
auto [num, str] = p; // 直接解包
std::cout << num << ", " << str; // 输出: 1, hello
2.泛型Lambda以及广义捕获（捕获变量的时候可以定义新变量）
auto lambda = [](auto x, auto y) { return x + y; };
形参不用明确指定类型
4.std::optional：表示可能有值，可能没有
作用：表示可能存在的值，替代 nullptr 或特殊值（如 -1、""）。
面试考点：安全处理可能缺失的值，避免未定义行为。
#include <optional>
std::optional<int> findValue(const std::vector<int>& v, int target) {
    auto it = std::find(v.begin(), v.end(), target);
    if (it != v.end()) return *it;
    return std::nullopt; // 明确表示无值
}

// 使用
if (auto val = findValue(v, 42)) {
    std::cout << *val; // 解引用获取值
}
3.if 和 switch 中的初始化语句
if (auto it = m.find(key); it != m.end()) {
    // it 仅在此块内有效
    std::cout << it->second;
}
5.折叠表达式（Fold Expressions）
作用：简化可变参数模板的展开，一行代码替代递归。
面试考点：元编程中的实用技巧。
template<typename... Args>
auto sum(Args... args) {
    return (args + ...); // 展开为 args1 + args2 + ...
}

std::cout << sum(1, 2, 3, 4); // 输出 10

了解async和future吗？
Linux 查看cpu占用率  查看端口号命令
top指令可以动态查看资源使用情况cpu的占有率
netstat指令查看网络连接和端口占用
● -t：仅显示 TCP 端口。
● -u：仅显示 UDP 端口。
● -l：仅显示监听（LISTEN）状态的端口。
● -n：以数字形式显示端口（不解析服务名称）。
● -p：显示占用端口的进程信息（需 sudo 权限）。
Linux下如何快速查找文件
find /home  -iname "wenjianming"
需求	命令示例
按文件名查找（精确匹配）	find /home -name "filename.txt"
按文件名查找（忽略大小写）	find /home -iname "filename.txt"
查找特定扩展名的文件	find /var/log -name "*.log"
查找大于 100MB 的文件	find / -size +100M
查找最近 7 天修改过的文件	find /etc -mtime -7
查找空文件或空目录	find /tmp -empty
查找并删除文件（谨慎使用）	find /tmp -name "*.tmp" -delete
一个线程大概多大？多少个比较合适？
linux一般为8MB，可以通过ulimit -s查看调整
理论上不超过cpu核心线程数的2-4倍
Valgrind原理是什么？
动态二进制插桩（插入额外代码）：
它在程序运行时，将用户的可执行文件加载到Valgrind 的虚拟环境中。将用户的机器码转换成一种中间表示（VEX IR），然后在这个代码中插入额外的检查代码，最后再转换回机器码并执行。
模拟执行：
Valgrind 模拟了一个虚拟的 CPU 环境，包括寄存器、内存等。
程序的所有内存访问、寄存器操作等，都通过Valgrind 的虚拟环境来进行，而不是直接操作真实的硬件。
这使得Valgrind 可以在程序执行过程中“看到”所有的数据流和内存访问行为，从而进行各种检查。
noncopyable类的作用？
class noncopyable { 
public: noncopyable(const noncopyable&) = delete; 
noncopyable& operator=(const noncopyable&) = delete; 
protected: noncopyable() = default; 
~noncopyable() = default; };

派生类的构造拷贝或者赋值构造会先调用基类的这两个方法。
日志的四个级别？
INFO:打印提示信息
ERROR:
FATAL:
DEBUG:
分布式相关基础问题
介绍一下你的项目？
CAP理论的理解？
为什么分布式系统的一致性和可用性不能同时满足？
怎么理解数据的一致性？一致性有哪几种模型？
系统设计强一致性和弱一致性如何选择？
如何设计分布式事务，实现最终的一致性？
数据库的Binlog和Redolog，怎么实现一致性？

三一重能英语测评
Can you hear me?"
（你能听到我吗？
sorry Let me think for a second  让我想一下
“对于这个问题，我其实不太确定。对于这些专业性的问题，我可能无法用英语很好地表达出来，对此我感到很抱歉。”
"I'm not really sure about this one. For these professional questions, I may not be able to express them well in English,i am sorry
自我介绍(introduce yourself)
晚上好，面试官，很荣幸参加这次面试，我叫敬烽，来自浙江嘉兴，
目前硕士研二就读于西安电子科技大学的电子信息技术专业
本科就读于桂林电子科技大学电子测控技术专业，
本科期间努力学习专业知识，拿到了校一等奖学金，社会奖学金等荣誉，
同时，我积极参加竞赛做过一些项目，曾获全国大学生电子设计大赛区优胜奖，以及全国大学生数学竞赛一等奖等。
硕士期间我也拿到了校一等学业奖学金，
我的科研项目是室内导航与定位，目前也已投出2篇SCI，在两个月前均已被录用
在实验室项目上，我参与了一个关于动态相机的项目，其中主要负责软件代码的编写与其成像功能的开发。
之前也是在北京互爱科技，从事c++软件开发实习生，有三个月多月的实习经历，在自己的空闲时，也做了一些c++相关的项目，与该岗位的技术路线还是比较符合的。
以上就是我的自我介绍，谢谢面试官。
Good evening, interviewer. It's my great honor to attend this interview.My name is Jing Feng. I come from Jiaxing, Zhejiang Province.
I am currently a second-year master's student at Xidian University,
majoring in Electronic Information Technology.
I completed my undergraduate studies at Guilin University of Electronic Technology,
where I majored in Electronic Measurement and Control Technology.
During my undergraduate years, I worked hard on my major,
and I received several honors, such as the University First-Class Scholarship and Social Scholarships.
I also took part in competitions and projects.I won the Regional Merit Award in the National Undergraduate Electronic Design Contest,
and the First Prize in the National Undergraduate Math Competition.
During my master's studies, I also received the University First-Class Academic Scholarship.
My research project is about indoor navigation and positioning.
I have submitted two SCI papers in IEEE journals,
and both have been accepted two months ago.
In a lab project, I worked on a dynamic camera-related project,
where I was mainly responsible for software coding and imaging function development.
adderationally, I also worked as a C++ software development intern at Beijing Huxiang Technology
for more than three months.
In my free time, I also did some C++ projects,
which are quite relevant to the technical requirements of this position.
That’s all for my self-introduction. Thank you.
参加竞赛的收获？
参加竞赛让我提升了自己的专业技能，比如动手实践和解决问题的能力。
另外，也锻炼了我和同学之间的团队合作能力，学会了如何分工与沟通，共同完成任务。
Taking part in those competitions helped me develop my technical skills, especially in hands-on work and problem-solving.
It also improved my ability to work in a team, where I learned how to cooperate, communicate effectively, and divide tasks with my teammates.
详细介绍项目经历
实习项目介绍
感谢您的提问。  
我曾在北京虎翔科技担任 C++ 软件开发实习生，时间从 2025 年 4 月至 8 月。
在实习期间，我参与了游戏“幽游白书”的后端开发工作，
主要负责诸如玩家团体聚集和端午节活动等子模块。
在这个项目中，我主要使用了 C++、Lua 和 Linux 这些技术。
这些技术与贵公司这里的职位非常相关。这次经历使我更深入地理解了 C++ 开发、网络通信以及团队合作的相关知识。

Thank you for the question.
I once worked as a C++ software development intern at Beijing Huxiang Technology, from April to August 2025.
During the internship, I participated in the backend development of the game "Yu Yu Hakusho (幽游白书)",
and was mainly responsible for sub-modules like player group gathering and the Dragon Boat Festival event.
I mainly used C++, Lua, and Linux in this project.
These technologies are quite relevant to the position here at your company.
This experience helped me gain a better understanding of C++ development, network communication, and teamwork
科研论文项目
感谢您的提问。在攻读硕士学位期间，我参与了一个关于利用智能手机传感器进行步态检测和步长估算的研究项目，并以第一作者的身份在《IEEE》期刊上发表了一篇论文。
在这个项目中，我提出了一种名为“MCCIF-SDE”的步态检测算法，该算法结合了：
自适应峰值检测
动态窗口约束
步态连续性和相似性分析
该算法有助于减少误检——例如，当一个人实际上并未行走但传感器数据看起来像是步态时，或者当手机处于不同位置时。
我还提出了一个基于希尔伯特变换的步长估算模型，该模型比传统的基于机器学习的方法更轻便，并且在不同的行走条件下能够更准确地估算步长。
这项研究提高了我在算法设计、信号处理和数据分析方面的技能，还让我获得了技术写作和问题解决方面的经验，这些对于软件开发领域的职业生涯也很有帮助。
Thank you for the question.
During my master's studies, I worked on a research project about step detection and step length estimation using smartphone sensors, and published two papers in IEEE journal two months ago.
In this project, I proposed a gait detection algorithm called MCCIF-SDE, which combines:
adaptive peak detection
dynamic window constraint
gait continuity and similarity analysis
This algorithm helps to reduce false detections — for example, when a person is not actually walking but the sensor data looks like steps, or when the phone is carried in different positions.
I also proposed a step length estimation model based on Hilbert Transform, which is lighter than traditional machine-learning-based methods, and can estimate step length more accurately under different walking conditions.
This research improved my skills in algorithm design, and data analysis, and gave me experience in technical writing and problem-solving, which are also useful for a career in software development
动态相机项目
感谢您的提问。我参与了动态相机项目。该项目的主要目标是为动态相机芯片开发一套完整的成像和数据传输功能，这些功能日后将用于诸如人类活动识别等研究工作。
我负责在 Zynq-7010 SoC 平台上进行图像数据接收和网络传输，然后在 PC 端进行图像接收和数据处理。
该项目的主要技术栈包括 C++、Linux 和网络通信，这些技术与我申请的职位非常相关。
这次经历提高了我在嵌入式开发和通信方面的技能。
Thank you for the question.I worked on the dynamic camera project. The main goal of the project was to develop a complete set of imaging and data transmission for a dynamic camera chip, which would be used for research like human activity recognition. 
I was responsible for image data reception and network transmission on a Zynq-7010 SoC platform, Then, I performed image reception and data processing on the PC side.
The main technical stack of this project included C++, Linux, and network communication, which are quite relevant to the position I applied for.
This experience has improved my skills in embedded development and communication.
动态相机与传统相机的区别
普通相机会通过曝光整个场景来拍摄一张完整的照片，并将这张照片发送出去。而我们的动态相机只会检测移动的物体，并发送事件数据。它所传输的数据较少，因此非常适合捕捉快速移动的物体
A normal camera takes a full picture by exposing the whole scene and then sends this whole picture. But our dynamic camera only detects moving objects and sends out event data. It has less data, so it's good for capturing fast - moving things.
 IT only Outputs the pixels where the brightness changes  

集群聊天服务器
感谢您的提问。这个项目是一个使用 muduo 网络库构建的聊天服务器。它采用（客户端/服务器）模式，并支持集群部署，这意味着它可以由多台服务器协同工作来处理任务。
这款聊天软件允许用户添加好友进行一对一聊天、加入群聊，并保存聊天记录以供日后使用。
在开发过程中，我主要使用 C++ 来编写服务器逻辑，使用 MySQL 来保存聊天记录和用户数据，使用 Redis 来实现快速的数据访问，并使用 mprpc 来协助系统不同部分之间的通信。
这个项目帮助我实践了构建实时网络应用程序以及使用常用工具。
Thank you for the question. This project is a chat server built with the muduo network library. It follows a (C/S) model and supports cluster deployment, meaning it can handle multiple servers working together.
The chat software allows users to add friends for one-on-one chats, join group chats, and stores chat messages for later use.
For development, I mainly used C++ to write the server logic, MySQL to save chat messages and user data, Redis for fast data access , and mprpc to help with communication between different parts of the system.
This project helped me practice building real-time network applications and using common tools. That's all,thank you!
企业文化
对三一的认识
我知道三一集团是一家知名的制造业企业，类似于徐工集团。它的业务范围很广，包括风电，港口机械，工业机械等等。我申请的事业组是智能矿业，主要是使用智能化手段提升矿山机械的感知能力、决策能力。
I know that SANY Group is a well-known manufacturing enterprise, similar to XCMG Group. It has a broad business scope, covering wind power, port machinery, industrial machinery and so on. The business unit I'm applying for is Intelligent Mining, which mainly uses intelligent methods to enhance the perception and decision-making capabilities of mining machinery.
为什么想加入三一
“我申请这个职位是因为我具备 C++、Linux 和网络通信方面的知识，这些技能与该职位的要求十分契合。此外，我更倾向于在制造业领域工作，而非互联网公司，因为看到自己的工作对实际产生影响能给我带来极大的满足感。”
"I applied for this role because my background in C++, Linux, and networking communication well with the position.In addational I prefer working in manufacturing over internet companies, as I find great satisfaction in seeing my work make a real-world impact."
对于加班的看法
我对于加班是能够接受的。从实验室里资深同事的经验来看，加班在我们这个行业是很常见的。与在工作日加班相比，我更看重周末的休息时间。在我看来，休息两天能让我从一周的繁忙工作中抽离出来，恢复精力，并为接下来的工作做好准备。
I’m acceptable with working overtime. From the experience of senior colleagues in the lab, overtime is common in our industry. Compared to working overtime on weekdays, I value weekends off more. In my view, having two days off allows me to get away from the busy work of the week, recharge my energy, and prepare for the work ahead.

兴趣爱好
 我非常喜欢打篮球。我从14岁开始接触这项运动，至今已经坚持了11年。在日常生活中，我经常和朋友们约着一起打球，也会经常观看NBA比赛——斯蒂芬·库里是我最喜欢的偶像，我不仅欣赏他精湛的球技，更钦佩他的人格魅力  
I'm really like playing basketball. I started playing basketball at the age of 14, and it has been 11 years now. In daily life, I often hit the court with friends and love watching NBA games. Stephen Curry is my all-time idol; I admire not just his incredible skills , but also the person he is.  
读过哪些书
My favorite history book is Those Things in the Ming Dynasty—it was actually my first real introduction to history, and its humorous style drew me in. As I read on, the stories of Yu Qian and Zhang Juzheng left me deeply impressed.
职业规划
in the Short-term: I want to quickly learn how things work here, understand the real challenges we face, and get familiar with the actual projects.
for the Long-term: I hope to become really good at my job — skilled enough to handle tasks independently and take on more responsibilities.
优点与缺点
优点与缺点
优点：
我的优点是有较强的自我驱动力，对于日常的任务和安排，我会主动推进并及时完成，即使需要加班熬夜也会优先确保进度；同时我非常注重细节，对已完成的工作会反复检查和完善，力求交付高质量的成果。
缺点：
我的缺点是有时过度追求细节和完美，比如在项目中可能会花费过多时间优化某个非核心模块，或反复调整已满足要求的细节，导致整体效率降低；另外这种倾向也可能让我对他人交付的内容标准过高，需要更注意平衡“追求卓越”和“团队协作效率”的关系。
My strength is having strong self-motivation. For daily tasks, I push them forward and complete them on time — even if it means working overtime or staying up late to ensure progress. At the same time, I pay close attention to details. I repeatedly review and refine completed work to deliver high-quality results.
Weaknesses:
My weakness is sometimes over-pursuing details and perfection. For example, in projects, I might spend too much time improving a non-core module or repeatedly adjusting details that already meet requirements, which reduces overall efficiency. Additionally, this tendency may lead me to hold others to overly high standards for their deliverables. I need to better balance "striving for excellence" with "team collaboration efficiency."
为什么想来北京？

介绍一下你的家乡？
我的家乡在四川的南坝县。这里被誉为‘世界渔业之都’，以盛忠湖和琅中（张飞的故乡）而闻名。这里有很多名胜古迹，而且四川的美食也非常丰富。欢迎大家将来来我的家乡游玩！”
"My hometown is Nanbu County in  Sichuan. It's known as the 'World Fishing City'—famous for Shengzhong Lake and Langzhong, the hometown of Zhang Fei. There are many places of interest, and Sichuan is rich in delicious food. Everyone is welcome to visit my hometown in the future!"
介绍一下你的家庭？家里人支持你来北京吗？
我来自一个温馨的家庭，家里有父母和两个妹妹，她们目前都在上高中。我们的家庭氛围非常融洽。北京提供了很多发展机会，我的家人完全支持我前往那里发展——或者去像上海这样的大城市发展。
I come from a warm family with my parents and two younger sisters, who are currently in high school. We have a very harmonious home environment.
Beijing offers many opportunities, and my family fully supports my plan to develop there—or in other big cities like Shanghai"

